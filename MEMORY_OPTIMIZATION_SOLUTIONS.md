# üõ†Ô∏è –†–ï–®–ï–ù–ò–Ø –î–õ–Ø –û–ì–†–ê–ù–ò–ß–ï–ù–ù–û–ô GPU –ü–ê–ú–Ø–¢–ò

**–ü—Ä–æ–±–ª–µ–º–∞**: `ValueError: Free memory on device cuda:0 (5.81/11.94 GiB) is less than desired GPU memory utilization (0.85)`

**–ü—Ä–∏—á–∏–Ω–∞**: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–≤–æ–±–æ–¥–Ω–æ–π GPU –ø–∞–º—è—Ç–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ dots.ocr —á–µ—Ä–µ–∑ vLLM —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.

## üéØ –ù–ï–ú–ï–î–õ–ï–ù–ù–´–ï –†–ï–®–ï–ù–ò–Ø

### 1. üßπ –û—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏

```bash
# –ó–∞–ø—É—Å–∫ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ GPU –ø–∞–º—è—Ç–∏
python gpu_memory_manager.py

# –ò–ª–∏ –±—ã—Å—Ç—Ä–∞—è –æ—á–∏—Å—Ç–∫–∞:
docker stop $(docker ps -aq)
docker system prune -f
nvidia-smi  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –Ω–∞ GPU
```

### 2. üîß –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ vLLM

```bash
# –ó–∞–ø—É—Å–∫ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∫ –ø–∞–º—è—Ç–∏
python start_dots_ocr_memory_optimized.py
```

**–ö–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
- `gpu-memory-utilization`: 0.35-0.4 (–≤–º–µ—Å—Ç–æ 0.85)
- `max-model-len`: 1024 (–º–∏–Ω–∏–º—É–º)
- `dtype`: bfloat16 (—ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏)
- `max-num-seqs`: 1 (–æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –∑–∞ —Ä–∞–∑)

### 3. üîÑ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: Transformers —Å 8-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install transformers accelerate bitsandbytes flask

# –ó–∞–ø—É—Å–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
python dots_ocr_transformers_8bit.py
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç ~4-6 GB –≤–º–µ—Å—Ç–æ 10+ GB
- –°–æ–≤–º–µ—Å—Ç–∏–º—ã–π OpenAI API
- –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ GPU —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é

## üìä –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–®–ï–ù–ò–ô

| –†–µ—à–µ–Ω–∏–µ | GPU –ø–∞–º—è—Ç—å | –°–∫–æ—Ä–æ—Å—Ç—å | –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å | –°–ª–æ–∂–Ω–æ—Å—Ç—å |
|---------|------------|----------|--------------|-----------|
| vLLM –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π | 6-8 GB | –ë—ã—Å—Ç—Ä–æ | –°—Ä–µ–¥–Ω—è—è | –ù–∏–∑–∫–∞—è |
| Transformers 8-bit | 4-6 GB | –ú–µ–¥–ª–µ–Ω–Ω–æ | –í—ã—Å–æ–∫–∞—è | –°—Ä–µ–¥–Ω—è—è |
| CPU –≤–µ—Ä—Å–∏—è | 0 GB | –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ | –í—ã—Å–æ–∫–∞—è | –ù–∏–∑–∫–∞—è |

## üöÄ –ü–û–®–ê–ì–û–í–ê–Ø –ò–ù–°–¢–†–£–ö–¶–ò–Ø

### –®–∞–≥ 1: –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –ø–∞–º—è—Ç–∏
python gpu_memory_manager.py
# –í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é 1 –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å—Ç–∞—Ç—É—Å–∞
```

### –®–∞–≥ 2: –û—á–∏—Å—Ç–∫–∞ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
```bash
# –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏
python gpu_memory_manager.py
# –í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é 2 –¥–ª—è –ø–æ–ª–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏
```

### –®–∞–≥ 3: –í—ã–±–æ—Ä —Ä–µ—à–µ–Ω–∏—è

**–ï—Å–ª–∏ —Å–≤–æ–±–æ–¥–Ω–æ 6+ GB:**
```bash
python start_dots_ocr_memory_optimized.py
```

**–ï—Å–ª–∏ —Å–≤–æ–±–æ–¥–Ω–æ < 6 GB:**
```bash
python dots_ocr_transformers_8bit.py
```

### –®–∞–≥ 4: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
```bash
python test_memory_optimized_ocr.py
```

## üîß –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò

### vLLM –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
```bash
docker run -d \
    --gpus all \
    --name dots-ocr-memory-opt \
    -p 8000:8000 \
    vllm/vllm-openai:latest \
    --model rednote-hilab/dots.ocr \
    --trust-remote-code \
    --max-model-len 1024 \
    --gpu-memory-utilization 0.4 \
    --dtype bfloat16 \
    --enforce-eager \
    --max-num-seqs 1
```

### Transformers –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
```python
model = AutoModelForCausalLM.from_pretrained(
    "rednote-hilab/dots.ocr",
    torch_dtype=torch.bfloat16,
    device_map="auto",
    load_in_8bit=True,  # 8-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
    trust_remote_code=True,
    max_memory={0: "6GB"}  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
)
```

## ‚ö†Ô∏è –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø –ò –ö–û–ú–ü–†–û–ú–ò–°–°–´

### vLLM –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è:
- ‚úÖ –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
- ‚úÖ –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å API
- ‚ùå –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
- ‚ùå –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ (1024 —Ç–æ–∫–µ–Ω–∞)

### Transformers 8-bit –≤–µ—Ä—Å–∏—è:
- ‚úÖ –ù–∏–∑–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
- ‚úÖ –í—ã—Å–æ–∫–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
- ‚ùå –ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (2-5 –º–∏–Ω—É—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
- ‚ùå –ù–µ—Ç batch processing

## üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ

### –î–ª—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ vLLM –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é** –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ 6+ GB GPU –ø–∞–º—è—Ç–∏
2. **–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–π—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –æ–¥–Ω–æ–º—É** –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
3. **–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ GPU –ø–∞–º—è—Ç—å** —á–µ—Ä–µ–∑ `gpu_memory_manager.py`

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Transformers 8-bit –≤–µ—Ä—Å–∏—é** –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
2. **–°–æ–∑–¥–∞–≤–∞–π—Ç–µ –Ω–µ–±–æ–ª—å—à–∏–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è** –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
3. **–ö–µ—à–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤

## üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú

### –ï—Å–ª–∏ vLLM –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è:
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤
docker logs dots-ocr-memory-opt

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –ø–∞–º—è—Ç–∏
nvidia-smi

# –û—á–∏—Å—Ç–∫–∞ –∏ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞
python gpu_memory_manager.py
```

### –ï—Å–ª–∏ Transformers –º–µ–¥–ª–µ–Ω–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU: `torch.cuda.is_available()`
- –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–æ–º–ø—Ç—ã

### –ï—Å–ª–∏ WSL —Å–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã:
```bash
# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ WSL (–∏–∑ Windows PowerShell)
wsl --shutdown
wsl

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –≤ WSL
nvidia-smi
```

## üìà –ú–û–ù–ò–¢–û–†–ò–ù–ì –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò

### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
- **GPU –ø–∞–º—è—Ç—å**: < 80% –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- **–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏**: < 2 –º–∏–Ω—É—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
- **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: > 90% —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

### –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:
```bash
# –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU
watch -n 1 nvidia-smi

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
python test_memory_optimized_ocr.py
```

## üéâ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï

–ü—Ä–æ–±–ª–µ–º–∞ —Å GPU –ø–∞–º—è—Ç—å—é —Ä–µ—à–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑:

1. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ vLLM** –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
2. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 8-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏** –∫–∞–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
3. **–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ GPU —Ä–µ—Å—É—Ä—Å–∞–º–∏**

–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–µ —Ä–µ—à–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–π GPU –ø–∞–º—è—Ç–∏ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

---
*–°–æ–∑–¥–∞–Ω–æ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π GPU –ø–∞–º—è—Ç—å—é –≤ WSL*