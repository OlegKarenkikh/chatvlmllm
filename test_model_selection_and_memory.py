#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
"""

import time
import json
from PIL import Image, ImageDraw, ImageFont
from vllm_memory_manager import VLLMMemoryManager
from vllm_streamlit_adapter import VLLMStreamlitAdapter

def create_test_image():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    img = Image.new('RGB', (400, 300), color='white')
    draw = ImageDraw.Draw(img)
    
    try:
        font = ImageFont.truetype("arial.ttf", 20)
    except:
        font = ImageFont.load_default()
    
    draw.text((50, 50), "Model Selection Test", fill='black', font=font)
    draw.text((50, 100), "dots.ocr vs Qwen3-VL", fill='blue', font=font)
    draw.text((50, 150), "Memory Management", fill='red', font=font)
    draw.text((50, 200), "GPU Optimization", fill='green', font=font)
    
    return img

def test_model_selection_and_memory():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    memory_manager = VLLMMemoryManager()
    adapter = VLLMStreamlitAdapter()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    test_image = create_test_image()
    test_image.save("test_model_selection.png")
    print("‚úÖ –¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ")
    
    results = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "test_type": "model_selection_and_memory",
        "memory_tests": {},
        "model_tests": {},
        "recommendations": []
    }
    
    # 1. –¢–µ—Å—Ç —Å—Ç–∞—Ç—É—Å–∞ –ø–∞–º—è—Ç–∏
    print("\n1Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏:")
    print("-" * 40)
    
    memory_status = memory_manager.get_memory_status()
    
    print(f"–ê–∫—Ç–∏–≤–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {memory_status['running_containers']}")
    print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU: {memory_status['current_memory_gb']:.1f}/{memory_status['max_memory_gb']} –ì–ë")
    print(f"–ü—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: {memory_status['memory_usage_percent']:.1f}%")
    print(f"–î–æ—Å—Ç—É–ø–Ω–æ –ø–∞–º—è—Ç–∏: {memory_status['available_memory_gb']:.1f} –ì–ë")
    
    results["memory_tests"]["initial_status"] = memory_status
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤ –ø–∞–º—è—Ç–∏
    if memory_status['memory_usage_percent'] > 100:
        print("‚ùå –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç GPU –ø–∞–º—è—Ç–∏!")
        results["recommendations"].append("–ö—Ä–∏—Ç–∏—á–Ω–æ: –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç GPU –ø–∞–º—è—Ç–∏ - —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
    elif memory_status['memory_usage_percent'] > 90:
        print("‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏")
        results["recommendations"].append("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏")
    else:
        print("‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏ –≤ –Ω–æ—Ä–º–µ")
    
    # 2. –¢–µ—Å—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    print("\n2Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:")
    print("-" * 40)
    
    available_models = adapter.get_recommended_models()
    
    for i, model in enumerate(available_models, 1):
        model_name = model.split('/')[-1]
        is_active = model in adapter.healthy_endpoints
        endpoint = adapter.model_endpoints.get(model, "unknown")
        
        status_icon = "‚úÖ" if is_active else "‚ùå"
        print(f"{i}. {status_icon} {model_name} ({endpoint})")
        
        results["model_tests"][model] = {
            "available": is_active,
            "endpoint": endpoint,
            "priority": i
        }
    
    if not available_models:
        print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π!")
        results["recommendations"].append("–ö—Ä–∏—Ç–∏—á–Ω–æ: –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
        return results
    
    # 3. –¢–µ—Å—Ç –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
    print("\n3Ô∏è‚É£ –¢–µ—Å—Ç –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏:")
    print("-" * 40)
    
    test_models = [
        "rednote-hilab/dots.ocr",
        "Qwen/Qwen3-VL-2B-Instruct"
    ]
    
    model_performance = {}
    
    for model in test_models:
        if model not in adapter.model_endpoints:
            continue
            
        print(f"\nüîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model.split('/')[-1]}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
        start_time = time.time()
        is_available = adapter.ensure_model_available(model)
        switch_time = time.time() - start_time
        
        if not is_available:
            print(f"‚ùå –ú–æ–¥–µ–ª—å {model.split('/')[-1]} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            model_performance[model] = {
                "available": False,
                "switch_time": switch_time,
                "error": "Model not available"
            }
            continue
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∞–∫—Ç–∏–≤–Ω–∞ (–≤—Ä–µ–º—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è: {switch_time:.1f}—Å)")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º OCR
        try:
            ocr_start = time.time()
            result = adapter.process_image(
                test_image, 
                "Extract all text from this image", 
                model,
                max_tokens=512
            )
            ocr_time = time.time() - ocr_start
            
            if result and result.get("success"):
                print(f"‚úÖ OCR —É—Å–ø–µ—à–Ω–æ: {len(result['text'])} —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞ {ocr_time:.1f}—Å")
                print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {result['text'][:50]}...")
                
                model_performance[model] = {
                    "available": True,
                    "switch_time": switch_time,
                    "ocr_time": ocr_time,
                    "text_length": len(result['text']),
                    "tokens_used": result.get('tokens_used', 0),
                    "success": True
                }
            else:
                print(f"‚ùå OCR –Ω–µ—É—Å–ø–µ—à–Ω–æ")
                model_performance[model] = {
                    "available": True,
                    "switch_time": switch_time,
                    "ocr_time": ocr_time,
                    "success": False,
                    "error": result.get('error', 'Unknown error') if result else 'No result'
                }
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ OCR: {e}")
            model_performance[model] = {
                "available": True,
                "switch_time": switch_time,
                "success": False,
                "error": str(e)
            }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞
        memory_after = memory_manager.get_memory_status()
        print(f"   –ü–∞–º—è—Ç—å –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞: {memory_after['current_memory_gb']:.1f} –ì–ë")
        
        time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
    
    results["model_tests"]["performance"] = model_performance
    
    # 4. –¢–µ—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏
    print("\n4Ô∏è‚É£ –¢–µ—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏:")
    print("-" * 40)
    
    memory_before = memory_manager.get_memory_status()
    print(f"–ü–∞–º—è—Ç—å –¥–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {memory_before['current_memory_gb']:.1f} –ì–ë")
    
    if memory_before['memory_usage_percent'] > 75:
        print("üîß –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏...")
        success, message = memory_manager.optimize_memory_usage()
        
        if success:
            print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞: {message}")
            
            memory_after = memory_manager.get_memory_status()
            print(f"–ü–∞–º—è—Ç—å –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {memory_after['current_memory_gb']:.1f} –ì–ë")
            
            results["memory_tests"]["optimization"] = {
                "performed": True,
                "success": True,
                "message": message,
                "memory_before": memory_before['current_memory_gb'],
                "memory_after": memory_after['current_memory_gb'],
                "memory_saved": memory_before['current_memory_gb'] - memory_after['current_memory_gb']
            }
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {message}")
            results["memory_tests"]["optimization"] = {
                "performed": True,
                "success": False,
                "message": message
            }
    else:
        print("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è - –ø–∞–º—è—Ç—å –≤ –Ω–æ—Ä–º–µ")
        results["memory_tests"]["optimization"] = {
            "performed": False,
            "reason": "Memory usage below threshold"
        }
    
    # 5. –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\n5Ô∏è‚É£ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("-" * 40)
    
    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
    successful_models = [model for model, perf in model_performance.items() if perf.get("success")]
    
    if successful_models:
        print("‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏:")
        for model in successful_models:
            perf = model_performance[model]
            model_name = model.split('/')[-1]
            print(f"   - {model_name}: OCR {perf['ocr_time']:.1f}—Å, –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ {perf['switch_time']:.1f}—Å")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        best_model = min(successful_models, key=lambda x: model_performance[x]['ocr_time'])
        best_name = best_model.split('/')[-1]
        print(f"üèÜ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {best_name} (—Å–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è)")
        results["recommendations"].append(f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {best_name}")
    else:
        print("‚ùå –ù–µ—Ç —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π!")
        results["recommendations"].append("–ö—Ä–∏—Ç–∏—á–Ω–æ: –ù–µ—Ç —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–∞–º—è—Ç–∏
    final_memory = memory_manager.get_memory_status()
    
    if final_memory['memory_usage_percent'] <= 75:
        print("‚úÖ –ü–∞–º—è—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ - –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π")
        results["recommendations"].append("–ü–∞–º—è—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ - –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π")
    elif final_memory['memory_usage_percent'] <= 90:
        print("‚ö†Ô∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–Ω—É –º–æ–¥–µ–ª—å –∑–∞ —Ä–∞–∑")
        results["recommendations"].append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–Ω—É –º–æ–¥–µ–ª—å –∑–∞ —Ä–∞–∑")
    else:
        print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è - –≤—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
        results["recommendations"].append("–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è - –≤—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏")
    
    # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    results_file = f"model_selection_memory_test_{timestamp}.json"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_file}")
    
    # 7. –ò—Ç–æ–≥–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å
    print(f"\nüìä –ò–¢–û–ì–û–í–´–ô –°–¢–ê–¢–£–°:")
    print("=" * 60)
    
    working_models = len(successful_models)
    total_models = len(test_models)
    memory_ok = final_memory['memory_usage_percent'] <= 90
    
    if working_models > 0 and memory_ok:
        print("üéâ –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê –ö –†–ê–ë–û–¢–ï")
        print(f"   ‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π: {working_models}/{total_models}")
        print(f"   ‚úÖ –ü–∞–º—è—Ç—å –≤ –Ω–æ—Ä–º–µ: {final_memory['current_memory_gb']:.1f}/{final_memory['max_memory_gb']} –ì–ë")
        print("   üí° –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: streamlit run app.py")
    else:
        print("‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢–°–Ø –ù–ê–°–¢–†–û–ô–ö–ê")
        if working_models == 0:
            print("   ‚ùå –ù–µ—Ç —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π")
        if not memory_ok:
            print("   ‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–∞–º—è—Ç—å—é")
        print("   üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞–º—è—Ç–∏")
    
    return results

if __name__ == "__main__":
    test_model_selection_and_memory()