#!/usr/bin/env python3
"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å —Ç–æ–∫–µ–Ω–∞–º–∏ –∏ –º–æ–¥–µ–ª—è–º–∏ –≤ vLLM –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
"""

import json
import requests
from datetime import datetime

def analyze_vllm_model_info():
    """–ê–Ω–∞–ª–∏–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ –≤ vLLM"""
    
    print("üîç –ê–ù–ê–õ–ò–ó –ú–û–î–ï–õ–ò vLLM")
    print("=" * 50)
    
    try:
        response = requests.get("http://localhost:8000/v1/models", timeout=5)
        if response.status_code == 200:
            models_data = response.json()
            
            print("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö:")
            for model in models_data.get("data", []):
                print(f"\nü§ñ –ú–æ–¥–µ–ª—å: {model['id']}")
                print(f"   üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {model.get('max_model_len', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} —Ç–æ–∫–µ–Ω–æ–≤")
                print(f"   üè¢ –í–ª–∞–¥–µ–ª–µ—Ü: {model.get('owned_by', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
                print(f"   üìÖ –°–æ–∑–¥–∞–Ω–∞: {model.get('created', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
                
                # –ü—Ä–æ–±–ª–µ–º–∞: max_model_len —Å–ª–∏—à–∫–æ–º –º–∞–ª
                max_len = model.get('max_model_len', 0)
                if max_len < 2048:
                    print(f"   ‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ {max_len} —Ç–æ–∫–µ–Ω–æ–≤ —Å–ª–∏—à–∫–æ–º –º–∞–ª–∞!")
                    print(f"   üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: –º–∏–Ω–∏–º—É–º 2048 —Ç–æ–∫–µ–Ω–æ–≤")
            
            return models_data
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ vLLM: {e}")
        return None

def create_vllm_fixes():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–ª—è vLLM"""
    
    fixes = {
        "timestamp": datetime.now().isoformat(),
        "problems_identified": [
            {
                "problem": "dots.ocr max_model_len = 1024 —Ç–æ–∫–µ–Ω–æ–≤",
                "severity": "HIGH",
                "impact": "–û—à–∏–±–∫–∏ –ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ",
                "solution": "–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ç–æ–∫–µ–Ω—ã –≤ UI –¥–ª—è vLLM —Ä–µ–∂–∏–º–∞"
            },
            {
                "problem": "–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª–∏ –∏–∑ config.yaml, –∞ –Ω–µ –∏–∑ vLLM",
                "severity": "MEDIUM", 
                "impact": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–∏–¥–∏—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏",
                "solution": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ vLLM API"
            }
        ],
        "fixes_to_apply": [
            {
                "file": "app.py",
                "change": "–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É max_model_len –¥–ª—è vLLM —Ä–µ–∂–∏–º–∞",
                "code_location": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤ –≤ sidebar"
            },
            {
                "file": "vllm_streamlit_adapter.py", 
                "change": "–î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ max_model_len –∏–∑ API",
                "code_location": "get_available_models –º–µ—Ç–æ–¥"
            },
            {
                "file": "app.py",
                "change": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å vLLM –º–æ–¥–µ–ª–∏ –≤–º–µ—Å—Ç–æ config –º–æ–¥–µ–ª–µ–π –≤ vLLM —Ä–µ–∂–∏–º–µ",
                "code_location": "–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –≤ sidebar"
            }
        ]
    }
    
    return fixes

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
    
    print("üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ü–†–û–ë–õ–ï–ú vLLM –¢–û–ö–ï–ù–û–í –ò –ú–û–î–ï–õ–ï–ô")
    print("=" * 60)
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    models_data = analyze_vllm_model_info()
    
    if not models_data:
        print("\n‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª—è—Ö vLLM")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ vLLM —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω:")
        print("   docker-compose -f docker-compose-vllm.yml up -d")
        return
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
    fixes = create_vllm_fixes()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    with open("vllm_token_issues_analysis.json", "w", encoding="utf-8") as f:
        json.dump({
            "models_data": models_data,
            "fixes": fixes
        }, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 60)
    print("üìä –í–´–í–û–î–´ –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
    print("=" * 60)
    
    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º
    for model in models_data.get("data", []):
        max_len = model.get('max_model_len', 0)
        model_id = model.get('id', 'unknown')
        
        if max_len < 2048:
            print(f"\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê:")
            print(f"   –ú–æ–¥–µ–ª—å: {model_id}")
            print(f"   –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤: {max_len}")
            print(f"   –ü—Ä–æ–±–ª–µ–º–∞: –ü—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ >1024 —Ç–æ–∫–µ–Ω–æ–≤ –≤ UI –±—É–¥—É—Ç –æ—à–∏–±–∫–∏")
            print(f"   –†–µ—à–µ–Ω–∏–µ: –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ç–æ–∫–µ–Ω—ã –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ –¥–æ {max_len}")
    
    print(f"\nüí° –ù–ï–û–ë–•–û–î–ò–ú–´–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:")
    for fix in fixes["fixes_to_apply"]:
        print(f"   üìÅ {fix['file']}: {fix['change']}")
    
    print(f"\nüìÑ –ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: vllm_token_issues_analysis.json")

if __name__ == "__main__":
    main()