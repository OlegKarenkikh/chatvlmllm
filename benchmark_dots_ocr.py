#!/usr/bin/env python3
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ dots.ocr —á–µ—Ä–µ–∑ vLLM
"""

import time
import json
import os
from pathlib import Path
from datetime import datetime
from dots_ocr_client import DotsOCRClient
import statistics

class OCRBenchmark:
    def __init__(self):
        self.client = DotsOCRClient()
        self.results = []
        self.test_documents_dir = Path("test_documents")
        
    def run_benchmark(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞"""
        print("üöÄ –ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –ë–ï–ù–ß–ú–ê–†–ö–ê DOTS.OCR")
        print("=" * 60)
        print(f"–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞
        if not self.client.health_check():
            print("‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
            return
        
        print("‚úÖ –°–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
        print()
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        test_files = list(self.test_documents_dir.glob("*.png"))
        if not test_files:
            print("‚ùå –¢–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            print("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python create_test_documents.py")
            return
        
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(test_files)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        print()
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        for i, test_file in enumerate(sorted(test_files), 1):
            print(f"üîÑ –¢–µ—Å—Ç {i}/{len(test_files)}: {test_file.name}")
            self.test_document(test_file)
            print()
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.analyze_results()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        self.save_report()
        
        print("‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    
    def test_document(self, file_path: Path):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        
        # –†–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        prompts = [
            "Extract all text from this image",
            "Transcribe all text content from this document",
            "Read and extract all visible text from this image",
            "Convert this image to text format"
        ]
        
        document_results = {
            "file": file_path.name,
            "file_size_kb": file_path.stat().st_size / 1024,
            "tests": []
        }
        
        for prompt_idx, prompt in enumerate(prompts):
            print(f"   –ü—Ä–æ–º–ø—Ç {prompt_idx + 1}/4: {prompt[:30]}...")
            
            # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
            start_time = time.time()
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ OCR (—É—á–∏—Ç—ã–≤–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ 1024 —Ç–æ–∫–µ–Ω–∞)
            result = self.client.process_image(str(file_path), prompt, max_tokens=800)
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            test_result = {
                "prompt": prompt,
                "processing_time": round(processing_time, 2),
                "success": result["success"],
                "text_length": len(result.get("text", "")) if result["success"] else 0,
                "word_count": len(result.get("text", "").split()) if result["success"] else 0,
                "error": result.get("error") if not result["success"] else None
            }
            
            if result["success"]:
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
                text = result["text"]
                test_result.update({
                    "has_numbers": any(char.isdigit() for char in text),
                    "has_cyrillic": any('\u0400' <= char <= '\u04FF' for char in text),
                    "has_latin": any(char.isascii() and char.isalpha() for char in text),
                    "line_count": len([line for line in text.split('\n') if line.strip()]),
                    "avg_word_length": round(sum(len(word) for word in text.split()) / len(text.split()), 2) if text.split() else 0
                })
                
                print(f"      ‚úÖ –£—Å–ø–µ—Ö: {test_result['word_count']} —Å–ª–æ–≤ –∑–∞ {processing_time:.1f}—Å")
            else:
                print(f"      ‚ùå –û—à–∏–±–∫–∞: {result.get('error', 'Unknown error')}")
            
            document_results["tests"].append(test_result)
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(1)
        
        self.results.append(document_results)
    
    def analyze_results(self):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–Ω—á–º–∞—Ä–∫–∞"""
        print("üìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("=" * 30)
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_tests = sum(len(doc["tests"]) for doc in self.results)
        successful_tests = sum(sum(1 for test in doc["tests"] if test["success"]) for doc in self.results)
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        print(f"–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}")
        print(f"–£—Å–ø–µ—à–Ω—ã—Ö: {successful_tests}")
        print(f"–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%")
        print()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        processing_times = []
        word_counts = []
        
        for doc in self.results:
            for test in doc["tests"]:
                if test["success"]:
                    processing_times.append(test["processing_time"])
                    word_counts.append(test["word_count"])
        
        if processing_times:
            print("‚è±Ô∏è –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {statistics.mean(processing_times):.1f}—Å")
            print(f"   –ú–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è: {statistics.median(processing_times):.1f}—Å")
            print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {min(processing_times):.1f}—Å")
            print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {max(processing_times):.1f}—Å")
            print()
            
            print("üìù –û–ë–™–ï–ú –¢–ï–ö–°–¢–ê:")
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ —Å–ª–æ–≤: {statistics.mean(word_counts):.0f}")
            print(f"   –ú–µ–¥–∏–∞–Ω–Ω–æ–µ –∫–æ–ª-–≤–æ —Å–ª–æ–≤: {statistics.median(word_counts):.0f}")
            print(f"   –ú–∏–Ω–∏–º—É–º —Å–ª–æ–≤: {min(word_counts)}")
            print(f"   –ú–∞–∫—Å–∏–º—É–º —Å–ª–æ–≤: {max(word_counts)}")
            print()
            
            # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Å–ª–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É)
            speeds = [wc / pt for wc, pt in zip(word_counts, processing_times) if pt > 0]
            if speeds:
                print("üöÄ –°–ö–û–†–û–°–¢–¨ –û–ë–†–ê–ë–û–¢–ö–ò:")
                print(f"   –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {statistics.mean(speeds):.1f} —Å–ª–æ–≤/—Å–µ–∫")
                print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å: {max(speeds):.1f} —Å–ª–æ–≤/—Å–µ–∫")
                print()
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        print("üìã –ê–ù–ê–õ–ò–ó –ü–û –¢–ò–ü–ê–ú –î–û–ö–£–ú–ï–ù–¢–û–í:")
        for doc in self.results:
            successful_doc_tests = [test for test in doc["tests"] if test["success"]]
            if successful_doc_tests:
                avg_time = statistics.mean([test["processing_time"] for test in successful_doc_tests])
                avg_words = statistics.mean([test["word_count"] for test in successful_doc_tests])
                success_rate_doc = len(successful_doc_tests) / len(doc["tests"]) * 100
                
                print(f"   {doc['file'][:20]:20} | {success_rate_doc:5.1f}% | {avg_time:5.1f}—Å | {avg_words:5.0f} —Å–ª–æ–≤")
        
        print()
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        print("üéØ –ö–ê–ß–ï–°–¢–í–û –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø:")
        cyrillic_docs = sum(1 for doc in self.results for test in doc["tests"] 
                           if test["success"] and test.get("has_cyrillic", False))
        latin_docs = sum(1 for doc in self.results for test in doc["tests"] 
                        if test["success"] and test.get("has_latin", False))
        number_docs = sum(1 for doc in self.results for test in doc["tests"] 
                         if test["success"] and test.get("has_numbers", False))
        
        print(f"   –î–æ–∫—É–º–µ–Ω—Ç—ã —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π: {cyrillic_docs}")
        print(f"   –î–æ–∫—É–º–µ–Ω—Ç—ã —Å –ª–∞—Ç–∏–Ω–∏—Ü–µ–π: {latin_docs}")
        print(f"   –î–æ–∫—É–º–µ–Ω—Ç—ã —Å —á–∏—Å–ª–∞–º–∏: {number_docs}")
    
    def save_report(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON
        detailed_report = {
            "timestamp": datetime.now().isoformat(),
            "server_url": self.client.base_url,
            "model": self.client.model_name,
            "total_documents": len(self.results),
            "results": self.results
        }
        
        json_file = f"benchmark_results_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_report, f, ensure_ascii=False, indent=2)
        
        # –ö—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        summary_file = f"benchmark_summary_{timestamp}.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("–û–¢–ß–ï–¢ –û –ë–ï–ù–ß–ú–ê–†–ö–ï DOTS.OCR\n")
            f.write("=" * 40 + "\n\n")
            f.write(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–ú–æ–¥–µ–ª—å: {self.client.model_name}\n")
            f.write(f"–°–µ—Ä–≤–µ—Ä: {self.client.base_url}\n\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_tests = sum(len(doc["tests"]) for doc in self.results)
            successful_tests = sum(sum(1 for test in doc["tests"] if test["success"]) for doc in self.results)
            success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
            
            f.write(f"–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}\n")
            f.write(f"–£—Å–ø–µ—à–Ω—ã—Ö: {successful_tests}\n")
            f.write(f"–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%\n\n")
            
            # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            processing_times = [test["processing_time"] for doc in self.results 
                              for test in doc["tests"] if test["success"]]
            if processing_times:
                f.write(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {statistics.mean(processing_times):.1f}—Å\n")
                f.write(f"–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è: {statistics.median(processing_times):.1f}—Å\n")
                f.write(f"–î–∏–∞–ø–∞–∑–æ–Ω –≤—Ä–µ–º–µ–Ω–∏: {min(processing_times):.1f}—Å - {max(processing_times):.1f}—Å\n\n")
        
        print(f"üìÑ –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {json_file}")
        print(f"üìÑ –ö—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {summary_file}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    benchmark = OCRBenchmark()
    benchmark.run_benchmark()

if __name__ == "__main__":
    main()