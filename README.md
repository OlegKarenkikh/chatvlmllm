# ChatVLMLLM - Document OCR & Vision-Language Models

A comprehensive toolkit for document OCR, visual understanding, and multimodal AI applications using state-of-the-art vision-language models.

## âœ¨ Features

### Supported Models

- ğŸ” **GOT-OCR 2.0** - Specialized OCR for complex layouts
- ğŸ¤– **Qwen2-VL** (2B, 7B) - Advanced vision-language understanding
- â­ **Qwen3-VL** (2B, 4B, 8B) - Latest VLM with 32 languages OCR, visual agent, 256K context
- ğŸ“š **dots.ocr** - SOTA multilingual document parser (100+ languages)

### Key Capabilities

- ğŸŒ **Multilingual OCR** - 32+ languages with high accuracy
- ğŸ¤– **Visual Agent** - GUI interaction and automation (Qwen3-VL)
- ğŸ“Š **Document Analysis** - Layout detection, table extraction, structure parsing
- ğŸ§  **Visual Reasoning** - Complex reasoning about images and diagrams
- ğŸ¥ **Video Understanding** - 256K context for long videos (Qwen3-VL)
- ğŸ“¦ **Flexible Quantization** - FP16, INT8, INT4 support
- âš¡ **Flash Attention 2** - Faster inference with lower memory

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/OlegKarenkikh/chatvlmllm.git
cd chatvlmllm

# Install dependencies
pip install -r requirements.txt

# Install latest transformers for Qwen3-VL
pip install git+https://github.com/huggingface/transformers
```

### Check GPU Compatibility

```bash
python scripts/check_gpu.py
```

### Basic Usage

```python
from models import ModelLoader
from PIL import Image

# Load Qwen3-VL 2B
model = ModelLoader.load_model('qwen3_vl_2b')

# Process image
image = Image.open('document.jpg')
result = model.chat(
    image=image,
    prompt="Extract all text from this document"
)

print(result)
```

### Streamlit App

```bash
streamlit run app.py
```

## ğŸ“Š GPU Requirements

| GPU | VRAM | Best Model | Status |
|-----|------|-----------|--------|
| RTX 5090 | 32GB | Qwen3-VL 8B@FP16 | âœ… Perfect |
| RTX 5080 | 16GB | Qwen3-VL 8B@INT8 | âœ… Excellent |
| RTX 5070 | 12GB | Qwen3-VL 4B@FP16 | âœ… Good |
| RTX 5060 Ti | 16GB | Qwen3-VL 8B@INT8 | âœ… Best Value |
| RTX 5060 Ti | 8GB | Qwen3-VL 4B@INT4 | âš ï¸ Limited |

See [GPU Requirements Guide](docs/gpu_requirements.md) for detailed compatibility.

## ğŸ“– Documentation

- [GPU Requirements](docs/gpu_requirements.md) - Comprehensive GPU compatibility guide
- [Qwen3-VL Guide](docs/qwen3_vl_guide.md) - Qwen3-VL usage and optimization
- [Model Cache Guide](docs/model_cache_guide.md) - Managing model downloads

## ğŸ› ï¸ Configuration

### config.yaml

```yaml
models:
  qwen3_vl_8b:
    model_path: "Qwen/Qwen3-VL-8B-Instruct"
    precision: "int8"  # fp16, bf16, int8, int4
    use_flash_attention: true
    device_map: "auto"
```

### INT4 Quantization (66% VRAM Reduction)

```yaml
models:
  qwen3_vl_8b:
    precision: "int4"  # 17.6GB -> 6GB
```

## âœ¨ What's New

### Qwen3-VL (Latest)

- ğŸŒ **32 languages OCR** (vs 19 in Qwen2-VL)
- ğŸ¤– **Visual agent** capabilities
- ğŸ“š **256K context** (expandable to 1M)
- ğŸ¯ **3D grounding** for spatial reasoning
- ğŸ§  **Thinking mode** for complex tasks
- ğŸ“¦ **INT4 support** - 66% less VRAM

## ğŸ’» Usage Examples

### Document OCR

```python
# Extract text from document
text = model.extract_text(image, language="Russian")
```

### Document Analysis

```python
# Analyze document structure
analysis = model.analyze_document(image, focus="layout")
```

### Visual Reasoning

```python
# Complex reasoning
reasoning = model.visual_reasoning(
    image, 
    question="Explain the workflow in this diagram"
)
```

### Visual Agent (Qwen3-VL)

```python
# GUI interaction
actions = model.chat(
    image=screenshot,
    prompt="Find and click the Submit button"
)
```

## ğŸ’¡ Tips & Best Practices

### For 8GB VRAM

```python
# Use INT4 quantization
model = ModelLoader.load_model(
    'qwen3_vl_8b',
    precision='int4'  # 6GB instead of 17.6GB
)
```

### For 12GB VRAM

```python
# Run multiple models
qwen4b = ModelLoader.load_model('qwen3_vl_4b')  # 8.9GB
qwen2b = ModelLoader.load_model('qwen3_vl_2b')  # 4.4GB
# Total: 11.1GB with INT8
```

### For 16GB+ VRAM

```python
# Optimal quality
model = ModelLoader.load_model(
    'qwen3_vl_8b',
    precision='int8',  # 10GB
    use_flash_attention=True
)
```

## ğŸ”§ Development

### Project Structure

```
chatvlmllm/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ got_ocr.py          # GOT-OCR integration
â”‚   â”œâ”€â”€ qwen_vl.py          # Qwen2-VL integration
â”‚   â”œâ”€â”€ qwen3_vl.py         # Qwen3-VL integration
â”‚   â”œâ”€â”€ dots_ocr.py         # dots.ocr integration
â”‚   â””â”€â”€ model_loader.py     # Model factory
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ model_cache.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ check_gpu.py        # GPU compatibility checker
â”‚   â””â”€â”€ check_models.py     # Model cache checker
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ gpu_requirements.md
â”‚   â””â”€â”€ qwen3_vl_guide.md
â”œâ”€â”€ app.py                  # Streamlit app
â””â”€â”€ config.yaml             # Configuration
```

### Testing

```bash
pytest tests/
```

## ğŸ¤ Contributing

Contributions welcome! Please open an issue or PR.

## ğŸ“ License

MIT License

## ğŸ”— Links

- **Qwen3-VL**: https://github.com/QwenLM/Qwen3-VL
- **GOT-OCR**: https://github.com/Ucas-HaoranWei/GOT-OCR2.0
- **dots.ocr**: https://github.com/rednote-hilab/dots.ocr

## â­ Acknowledgments

- Qwen Team for Qwen3-VL
- Stepfun AI for GOT-OCR 2.0
- RedNote for dots.ocr

---

**Star â­ this repo if you find it useful!**