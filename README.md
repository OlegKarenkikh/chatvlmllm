# ChatVLMLLM - Document OCR & Vision Language Models

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

A comprehensive educational research project exploring **Vision Language Models (VLM)** for document OCR tasks. This project provides a production-ready implementation with modern UI, comparing different model architectures and their performance on real-world document processing.

<p align="center">
  <img src="https://img.icons8.com/fluency/96/000000/artificial-intelligence.png" width="100"/>
</p>

## ğŸ¯ Project Goals

This educational project aims to:

1. ğŸ”¬ **Research** - Compare specialized OCR models vs. general VLM models
2. ğŸ“Š **Benchmark** - Measure accuracy, speed, and resource usage
3. ğŸ› ï¸ **Develop** - Build production-quality document processing application
4. ğŸ“š **Learn** - Understand VLM architectures and their applications
5. ğŸŒ **Share** - Provide open-source implementation for community

## âœ¨ Features

### ğŸ¤– Model Support

- **GOT-OCR 2.0** - Specialized OCR for complex layouts
- **Qwen2-VL 2B** - Lightweight vision-language model
- **Qwen2-VL 7B** - Advanced multimodal understanding

### ğŸ“„ Processing Modes

- **OCR Mode** - Extract text and structured data from documents
- **Chat Mode** - Interactive Q&A about document content
- **Batch Processing** - Process multiple documents efficiently
- **Comparison** - Side-by-side model performance analysis

### ğŸ’ Production Features

- âœ… Modern Streamlit UI with custom styling
- âœ… HuggingFace model cache management
- âœ… Automatic model detection and download
- âœ… Export results (JSON, CSV, TXT)
- âœ… Input validation and error handling
- âœ… Comprehensive logging system
- âœ… Docker containerization
- âœ… Jupyter notebooks for exploration

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- CUDA-capable GPU (recommended, 6GB+ VRAM)
- 30GB+ free disk space (for models)

### Installation

```bash
# Clone repository
git clone https://github.com/OlegKarenkikh/chatvlmllm.git
cd chatvlmllm

# Automated setup
bash scripts/setup.sh  # Linux/Mac
# or
scripts\setup.bat      # Windows
```

### Check Environment

```bash
# Verify installation
python scripts/check_setup.py

# Check model cache status
python scripts/check_models.py
```

### Download Models (Optional)

Models download automatically on first use, but you can pre-download:

```bash
python scripts/download_models.py
```

### Run Application

```bash
streamlit run app.py
```

Open browser to: http://localhost:8501

## ğŸ“– Documentation

### Core Documentation

- [**Quick Start Guide**](QUICKSTART.md) - Get started in 5 minutes
- [**Model Documentation**](docs/models.md) - Detailed model information
- [**Architecture Overview**](docs/architecture.md) - System design
- [**Developer Guide**](README_DEV.md) - Development setup and workflow
- [**Model Cache Guide**](docs/model_cache_guide.md) - Cache management

### Additional Resources

- [Research Log Template](docs/research_log.md) - Track your experiments
- [Contributing Guidelines](CONTRIBUTING.md) - How to contribute
- [Project Summary](PROJECT_SUMMARY.md) - Complete project overview
- [Changelog](CHANGELOG.md) - Version history

## ğŸ“ Using the Project

### For Students

1. **Explore Models**
   ```bash
   jupyter notebook notebooks/01_model_exploration.ipynb
   ```

2. **Run Experiments**
   - Process test documents
   - Compare model outputs
   - Measure performance metrics

3. **Document Results**
   - Fill in [research_log.md](docs/research_log.md)
   - Create comparison charts
   - Write analysis report

### For Developers

1. **Extend Functionality**
   ```python
   # Add custom model
   from models.base_model import BaseModel
   
   class MyModel(BaseModel):
       def load_model(self):
           # Your implementation
           pass
   ```

2. **Run Tests**
   ```bash
   pytest
   pytest --cov=models --cov=utils
   ```

3. **Deploy**
   ```bash
   docker-compose -f docker/docker-compose.yml up
   ```

## ğŸ”§ Model Cache Management

### Check Cache Status

```bash
python scripts/check_models.py
```

Output example:
```
âœ… GOT-OCR 2.0: Found in cache (2.8 GB)
âš ï¸  Qwen2-VL 2B: Not cached - will download on first use
âœ… Qwen2-VL 7B: Found in cache (14.2 GB)

Total: 2 models, 17.0 GB
```

### Cache Location

Default: `~/.cache/huggingface/hub/`

Custom location:
```bash
export HF_HOME="/path/to/cache"
```

See [Model Cache Guide](docs/model_cache_guide.md) for details.

## ğŸ“Š Model Comparison

| Model | Parameters | VRAM | Speed | Best For |
|-------|-----------|------|-------|----------|
| GOT-OCR 2.0 | 580M | ~3GB | Fast | Complex layouts, tables, formulas |
| Qwen2-VL 2B | 2B | ~5GB | Fast | General OCR, lightweight deployment |
| Qwen2-VL 7B | 7B | ~14GB | Medium | Advanced analysis, reasoning |

## ğŸ› ï¸ Development

### Project Structure

```
chatvlmllm/
â”œâ”€â”€ app.py                 # Streamlit application
â”œâ”€â”€ config.yaml           # Configuration
â”œâ”€â”€ models/               # Model integrations
â”‚   â”œâ”€â”€ got_ocr.py       # GOT-OCR 2.0
â”‚   â”œâ”€â”€ qwen_vl.py       # Qwen2-VL
â”‚   â””â”€â”€ model_loader.py  # Factory with cache
â”œâ”€â”€ utils/                # Utilities
â”‚   â”œâ”€â”€ model_cache.py   # Cache management
â”‚   â”œâ”€â”€ logger.py        # Logging
â”‚   â””â”€â”€ validators.py    # Validation
â”œâ”€â”€ ui/                   # UI components
â”œâ”€â”€ tests/                # Test suite
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”œâ”€â”€ scripts/              # Utility scripts
â””â”€â”€ docs/                 # Documentation
```

### Testing

```bash
# Run all tests
pytest

# With coverage
pytest --cov=models --cov=utils --cov-report=html

# Specific test
pytest tests/test_models.py::test_model_loading
```

### Code Quality

```bash
# Format code
black .

# Lint
flake8 .

# Type check
mypy models/ utils/
```

## ğŸ³ Docker Deployment

```bash
# Build image
docker build -t chatvlmllm -f docker/Dockerfile .

# Run with GPU
docker-compose -f docker/docker-compose.yml up
```

## ğŸ“ˆ Benchmarking

Run benchmark tests:

```python
from notebooks import run_benchmark

results = run_benchmark(
    models=['got_ocr', 'qwen_vl_2b'],
    test_set='examples/',
    metrics=['cer', 'wer', 'speed']
)
```

## ğŸ¤ Contributing

Contributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Areas for Contribution

- ğŸ› Bug fixes
- âœ¨ New features
- ğŸ“ Documentation improvements
- ğŸ§ª Additional tests
- ğŸ¨ UI enhancements
- ğŸŒ Translations

## ğŸ“ Citation

If you use this project in your research, please cite:

```bibtex
@software{chatvlmllm2026,
  author = {Oleg Karenkikh},
  title = {ChatVLMLLM: Document OCR with Vision Language Models},
  year = {2026},
  url = {https://github.com/OlegKarenkikh/chatvlmllm}
}
```

## ğŸ™ Acknowledgments

### Models

- **GOT-OCR 2.0**: [stepfun-ai/GOT-OCR2_0](https://huggingface.co/stepfun-ai/GOT-OCR2_0)
- **Qwen2-VL**: [Qwen/Qwen2-VL](https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct)

### Frameworks

- [Streamlit](https://streamlit.io/) - Web interface
- [HuggingFace](https://huggingface.co/) - Model hub
- [PyTorch](https://pytorch.org/) - ML framework

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ”— Links

- **Repository**: [github.com/OlegKarenkikh/chatvlmllm](https://github.com/OlegKarenkikh/chatvlmllm)
- **Documentation**: [docs/](docs/)
- **Issues**: [GitHub Issues](https://github.com/OlegKarenkikh/chatvlmllm/issues)
- **Discussions**: [GitHub Discussions](https://github.com/OlegKarenkikh/chatvlmllm/discussions)

## ğŸ“ Support

Need help?

- ğŸ“– Check [documentation](docs/)
- ğŸ› [Report issues](https://github.com/OlegKarenkikh/chatvlmllm/issues)
- ğŸ’¬ [Ask questions](https://github.com/OlegKarenkikh/chatvlmllm/discussions)

---

<p align="center">
  Made with â¤ï¸ for education and research<br>
  <b>ChatVLMLLM</b> - Exploring Vision Language Models for Document OCR
</p>