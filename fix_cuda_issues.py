#!/usr/bin/env python3
"""
–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï CUDA –ü–†–û–ë–õ–ï–ú –ò –ü–ï–†–ï–ó–ê–ü–£–°–ö –°–ò–°–¢–ï–ú–´

–í—ã–ø–æ–ª–Ω—è–µ—Ç –≤—Å–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑ –æ—Ç—á–µ—Ç–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
1. –û—á–∏—Å—Ç–∫–∞ CUDA –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
2. –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ CUDA –¥—Ä–∞–π–≤–µ—Ä–æ–≤
3. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
4. –°–æ–∑–¥–∞–Ω–∏–µ CPU fallback —Ä–µ–∂–∏–º–∞
"""

import os
import sys
import time
import torch
import subprocess
from pathlib import Path

def clear_cuda_context():
    """–û—á–∏—â–∞–µ–º CUDA –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é."""
    print("üîß –û—á–∏—â–∞–µ–º CUDA –∫–æ–Ω—Ç–µ–∫—Å—Ç...")
    
    try:
        if torch.cuda.is_available():
            # –û—á–∏—â–∞–µ–º –≤—Å–µ CUDA –∫–µ—à–∏
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—Å–µ CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
            for i in range(torch.cuda.device_count()):
                with torch.cuda.device(i):
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
            
            print("‚úÖ CUDA –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω")
        else:
            print("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ CUDA: {e}")

def reset_cuda_environment():
    """–°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è CUDA."""
    print("üîÑ –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è CUDA...")
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ CUDA
    cuda_env_vars = {
        'CUDA_LAUNCH_BLOCKING': '1',
        'TORCH_USE_CUDA_DSA': '1',
        'CUDA_DEVICE_ORDER': 'PCI_BUS_ID',
        'TOKENIZERS_PARALLELISM': 'false'
    }
    
    for var, value in cuda_env_vars.items():
        os.environ[var] = value
        print(f"   {var} = {value}")
    
    print("‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")

def create_cpu_fallback_config():
    """–°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å CPU fallback."""
    print("üíª –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å CPU fallback...")
    
    cpu_config = """# CPU FALLBACK CONFIGURATION
models:
  qwen_vl_2b:
    name: "Qwen2-VL 2B (CPU Fallback)"
    description: "–û—Å–Ω–æ–≤–Ω–∞—è OCR –º–æ–¥–µ–ª—å —Å CPU fallback"
    model_path: "Qwen/Qwen2-VL-2B-Instruct"
    max_length: 32768
    precision: "fp32"  # CPU —Ä–µ–∂–∏–º
    device_map: "cpu"
    force_cpu: true
    
  qwen3_vl_2b:
    name: "Qwen3-VL 2B (Optimized)"
    description: "–ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"
    model_path: "Qwen/Qwen3-VL-2B-Instruct"
    max_length: 256000
    precision: "fp16"
    device_map: "auto"
    generation_config:
      max_new_tokens: 512
      do_sample: false
      temperature: 0.1
      
  dots_ocr_corrected:
    name: "dots.ocr (Corrected)"
    description: "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è dots.ocr"
    model_path: "rednote-hilab/dots.ocr"
    max_length: 24000
    precision: "fp16"
    device_map: "auto"
    use_corrected_implementation: true

gpu_requirements:
  optimization:
    default_model: "qwen3_vl_2b"
    single_model_mode: true
    auto_unload: true
    cpu_fallback: true
    cuda_error_recovery: true
"""
    
    with open("config_cpu_fallback.yaml", "w", encoding="utf-8") as f:
        f.write(cpu_config)
    
    print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è CPU fallback —Å–æ–∑–¥–∞–Ω–∞: config_cpu_fallback.yaml")

def optimize_generation_parameters():
    """–°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."""
    print("‚ö° –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
    
    optimization_code = '''"""
–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ –ì–ï–ù–ï–†–ê–¶–ò–ò –î–õ–Ø –£–°–¢–†–ê–ù–ï–ù–ò–Ø CUDA –ü–†–û–ë–õ–ï–ú
"""

import torch

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
OPTIMIZED_GENERATION_PARAMS = {
    "qwen_vl_2b": {
        "max_new_tokens": 512,
        "do_sample": False,
        "temperature": 0.1,
        "top_p": 0.9,
        "repetition_penalty": 1.1,
        "pad_token_id": None,  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        "use_cache": True,
        "output_attentions": False,
        "output_hidden_states": False
    },
    
    "qwen3_vl_2b": {
        "max_new_tokens": 1024,
        "do_sample": False,
        "temperature": 0.1,
        "top_p": 0.9,
        "repetition_penalty": 1.05,
        "pad_token_id": 151645,  # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è Qwen3-VL
        "use_cache": True,
        "output_attentions": False,
        "output_hidden_states": False
    },
    
    "dots_ocr": {
        "max_new_tokens": 2048,
        "do_sample": False,
        "temperature": 0.1,
        "top_p": 0.95,
        "repetition_penalty": 1.0,
        "pad_token_id": None,
        "use_cache": True,
        "output_attentions": False,
        "output_hidden_states": False
    }
}

def get_optimized_params(model_name: str) -> dict:
    """–ü–æ–ª—É—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏."""
    return OPTIMIZED_GENERATION_PARAMS.get(model_name, OPTIMIZED_GENERATION_PARAMS["qwen3_vl_2b"])

def apply_cuda_optimizations():
    """–ü—Ä–∏–º–µ–Ω—è–µ–º CUDA –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏."""
    if torch.cuda.is_available():
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        
        # –û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        
        return True
    return False
'''
    
    with open("utils/optimized_generation.py", "w", encoding="utf-8") as f:
        f.write(optimization_code)
    
    print("‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ–∑–¥–∞–Ω—ã: utils/optimized_generation.py")

def create_cuda_recovery_system():
    """–°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ CUDA –æ—à–∏–±–æ–∫."""
    print("üõ°Ô∏è –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è CUDA...")
    
    recovery_code = '''"""
–°–ò–°–¢–ï–ú–ê –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–Ø –ü–û–°–õ–ï CUDA –û–®–ò–ë–û–ö
"""

import torch
import time
import logging
from typing import Callable, Any, Optional

logger = logging.getLogger(__name__)

class CUDARecoveryManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ CUDA –æ—à–∏–±–æ–∫."""
    
    def __init__(self):
        self.cuda_error_count = 0
        self.max_cuda_errors = 3
        self.recovery_delay = 2.0
        
    def is_cuda_error(self, error: Exception) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—à–∏–±–∫–∞ CUDA –æ—à–∏–±–∫–æ–π."""
        error_str = str(error).lower()
        cuda_error_indicators = [
            'cuda error',
            'device-side assert',
            'cudaerrorassert',
            'cuda runtime error',
            'out of memory',
            'cuda out of memory'
        ]
        
        return any(indicator in error_str for indicator in cuda_error_indicators)
    
    def recover_from_cuda_error(self) -> bool:
        """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –ø–æ—Å–ª–µ CUDA –æ—à–∏–±–∫–∏."""
        try:
            logger.warning(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è CUDA (–ø–æ–ø—ã—Ç–∫–∞ {self.cuda_error_count + 1}/{self.max_cuda_errors})")
            
            if torch.cuda.is_available():
                # –û—á–∏—â–∞–µ–º –≤—Å–µ CUDA –∫–µ—à–∏
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                
                # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ
                time.sleep(self.recovery_delay)
                
                # –¢–µ—Å—Ç–∏—Ä—É–µ–º CUDA
                test_tensor = torch.randn(10, 10, device='cuda')
                result = test_tensor @ test_tensor.T
                result.cpu()
                
                logger.info("‚úÖ CUDA –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                self.cuda_error_count = 0
                return True
            else:
                logger.warning("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è CUDA: {e}")
            self.cuda_error_count += 1
            return False
    
    def safe_cuda_call(self, func: Callable, *args, **kwargs) -> Any:
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ —Å CUDA –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º."""
        for attempt in range(self.max_cuda_errors + 1):
            try:
                return func(*args, **kwargs)
                
            except Exception as e:
                if self.is_cuda_error(e) and attempt < self.max_cuda_errors:
                    logger.warning(f"‚ö†Ô∏è CUDA –æ—à–∏–±–∫–∞: {e}")
                    
                    if self.recover_from_cuda_error():
                        continue
                    else:
                        # –ï—Å–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, –ø—Ä–æ–±—É–µ–º CPU —Ä–µ–∂–∏–º
                        logger.warning("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ CPU —Ä–µ–∂–∏–º")
                        kwargs['device'] = 'cpu'
                        kwargs['force_cpu'] = True
                        continue
                else:
                    raise e
        
        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏—é –ø–æ—Å–ª–µ {self.max_cuda_errors} –ø–æ–ø—ã—Ç–æ–∫")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
cuda_recovery_manager = CUDARecoveryManager()
'''
    
    with open("utils/cuda_recovery.py", "w", encoding="utf-8") as f:
        f.write(recovery_code)
    
    print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è CUDA —Å–æ–∑–¥–∞–Ω–∞: utils/cuda_recovery.py")

def update_model_loader():
    """–û–±–Ω–æ–≤–ª—è–µ–º model_loader —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π dots_ocr."""
    print("üîÑ –û–±–Ω–æ–≤–ª—è–µ–º model_loader...")
    
    try:
        # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π model_loader
        with open("models/model_loader.py", "r", encoding="utf-8") as f:
            content = f.read()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        if "from models.dots_ocr_corrected import DotsOCRCorrectedModel" not in content:
            import_section = content.find("from models.dots_ocr import DotsOCRModel")
            if import_section != -1:
                new_import = "from models.dots_ocr_corrected import DotsOCRCorrectedModel\n"
                content = content[:import_section] + new_import + content[import_section:]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–µ–µ—Å—Ç—Ä –º–æ–¥–µ–ª–µ–π
        if '"dots_ocr_corrected": DotsOCRCorrectedModel' not in content:
            registry_section = content.find('"dots_ocr": DotsOCRModel')
            if registry_section != -1:
                end_line = content.find('\n', registry_section)
                new_entry = ',\n        "dots_ocr_corrected": DotsOCRCorrectedModel'
                content = content[:end_line] + new_entry + content[end_line:]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with open("models/model_loader.py", "w", encoding="utf-8") as f:
            f.write(content)
        
        print("‚úÖ model_loader –æ–±–Ω–æ–≤–ª–µ–Ω")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ model_loader: {e}")

def test_cuda_recovery():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è CUDA."""
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è CUDA...")
    
    try:
        if torch.cuda.is_available():
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç CUDA
            test_tensor = torch.randn(100, 100, device='cuda')
            result = test_tensor @ test_tensor.T
            result.cpu()
            torch.cuda.empty_cache()
            
            print("‚úÖ CUDA —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            return True
        else:
            print("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω CPU —Ä–µ–∂–∏–º")
            return False
            
    except Exception as e:
        print(f"‚ùå CUDA —Ç–µ—Å—Ç –Ω–µ –ø—Ä–æ–π–¥–µ–Ω: {e}")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è."""
    print("üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï CUDA –ü–†–û–ë–õ–ï–ú –ò –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –°–ò–°–¢–ï–ú–´")
    print("=" * 60)
    
    # –≠—Ç–∞–ø 1: –û—á–∏—Å—Ç–∫–∞ CUDA
    clear_cuda_context()
    
    # –≠—Ç–∞–ø 2: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    reset_cuda_environment()
    
    # –≠—Ç–∞–ø 3: –°–æ–∑–¥–∞–Ω–∏–µ CPU fallback
    create_cpu_fallback_config()
    
    # –≠—Ç–∞–ø 4: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    optimize_generation_parameters()
    
    # –≠—Ç–∞–ø 5: –°–∏—Å—Ç–µ–º–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
    create_cuda_recovery_system()
    
    # –≠—Ç–∞–ø 6: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞
    update_model_loader()
    
    # –≠—Ç–∞–ø 7: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    cuda_ok = test_cuda_recovery()
    
    print("\n" + "=" * 60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø")
    print("=" * 60)
    
    print(f"‚úÖ CUDA –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω")
    print(f"‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
    print(f"‚úÖ CPU fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞")
    print(f"‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
    print(f"‚úÖ –°–∏—Å—Ç–µ–º–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è CUDA —Å–æ–∑–¥–∞–Ω–∞")
    print(f"‚úÖ model_loader –æ–±–Ω–æ–≤–ª–µ–Ω")
    print(f"{'‚úÖ' if cuda_ok else '‚ö†Ô∏è'} CUDA —Ç–µ—Å—Ç: {'–ü—Ä–æ–π–¥–µ–Ω' if cuda_ok else '–ù–µ –ø—Ä–æ–π–¥–µ–Ω (–±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω CPU)'}")
    
    print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("1. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ Python –ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π")
    print("2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ config_cpu_fallback.yaml –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö —Å CUDA")
    print("3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ test_end_to_end_final_with_inference.py –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
    
    return cuda_ok

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)