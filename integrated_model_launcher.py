#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫–∞—Ç–µ–ª—å –º–æ–¥–µ–ª–µ–π
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç Transformers –∏ vLLM —Ä–µ–∂–∏–º—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –∫–µ—à–∞–º–∏
"""

import subprocess
import time
import requests
import json
import os
import threading
from pathlib import Path

class IntegratedModelLauncher:
    def __init__(self):
        self.cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
        self.current_mode = None
        self.running_processes = []
        self.running_containers = []
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π (–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
        self.models_config = {
            "transformers": {
                "rednote-hilab/dots.ocr": {
                    "name": "DotsOCR",
                    "memory_8bit_gb": 3.5,
                    "port": 8000,
                    "category": "ocr",
                    "tested": True
                },
                "stepfun-ai/GOT-OCR-2.0-hf": {
                    "name": "GOT-OCR 2.0", 
                    "memory_8bit_gb": 0.8,
                    "port": 8001,
                    "category": "ocr",
                    "tested": False,
                    "issues": ["Requires specific prompt format"]
                },
                "Qwen/Qwen2-VL-2B-Instruct": {
                    "name": "Qwen2-VL 2B",
                    "memory_8bit_gb": 2.5,
                    "port": 8002,
                    "category": "vlm",
                    "tested": False
                },
                "microsoft/Phi-3.5-vision-instruct": {
                    "name": "Phi-3.5 Vision",
                    "memory_8bit_gb": 4.5,
                    "port": 8003,
                    "category": "vlm",
                    "tested": False
                },
                "vikhyatk/moondream2": {
                    "name": "Moondream2",
                    "memory_8bit_gb": 2.0,
                    "port": 8004,
                    "category": "vlm",
                    "tested": False,
                    "issues": ["Custom architecture - may need special handling"]
                }
            },
            "vllm": {
                "rednote-hilab/dots.ocr": {
                    "name": "DotsOCR",
                    "container_name": "rednote-hilab-dots-ocr-vllm",
                    "memory_required_gb": 8.0,
                    "port": 8000,
                    "category": "ocr",
                    "tested": True
                },
                "Qwen/Qwen2-VL-2B-Instruct": {
                    "name": "Qwen2-VL 2B",
                    "container_name": "qwen-qwen2-vl-2b-instruct-vllm", 
                    "memory_required_gb": 6.0,
                    "port": 8001,
                    "category": "vlm",
                    "tested": False
                },
                "microsoft/Phi-3.5-vision-instruct": {
                    "name": "Phi-3.5 Vision",
                    "container_name": "microsoft-phi-3-5-vision-instruct-vllm",
                    "memory_required_gb": 10.0,
                    "port": 8002,
                    "category": "vlm",
                    "tested": False,
                    "issues": ["May require specific vLLM version"]
                },
                "Qwen/Qwen2-VL-7B-Instruct": {
                    "name": "Qwen2-VL 7B",
                    "container_name": "qwen-qwen2-vl-7b-instruct-vllm",
                    "memory_required_gb": 12.0,
                    "port": 8003,
                    "category": "vlm",
                    "tested": False,
                    "issues": ["Requires high-end GPU"]
                }
            }
        }
    
    def get_gpu_info(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU"""
        try:
            result = subprocess.run([
                "nvidia-smi", 
                "--query-gpu=memory.total,memory.free,memory.used",
                "--format=csv,noheader,nounits"
            ], capture_output=True, text=True, check=True)
            
            total, free, used = map(int, result.stdout.strip().split(', '))
            return {
                'total_mb': total,
                'free_mb': free,
                'used_mb': used,
                'total_gb': total / 1024,
                'free_gb': free / 1024,
                'used_gb': used / 1024
            }
        except Exception:
            return None
    
    def check_cache_setup(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–µ—à–∞"""
        print(f"üìÅ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–µ—à –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {self.cache_dir}")
        
        if not self.cache_dir.exists():
            print("üìÅ –°–æ–∑–¥–∞–Ω–∏–µ –∫–µ—à –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏...")
            self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞
        if not os.access(self.cache_dir, os.R_OK | os.W_OK):
            print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∞–≤ –¥–ª—è –∫–µ—à –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
            try:
                os.chmod(self.cache_dir, 0o755)
                print("‚úÖ –ü—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã")
            except:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π
        cached_models = []
        total_cache_size = 0
        
        for item in self.cache_dir.iterdir():
            if item.is_dir() and item.name.startswith('models--'):
                model_name = item.name.replace('models--', '').replace('--', '/')
                size = sum(f.stat().st_size for f in item.rglob('*') if f.is_file())
                cached_models.append((model_name, size))
                total_cache_size += size
        
        if cached_models:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(cached_models)} –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:")
            print(f"üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–µ—à–∞: {total_cache_size / (1024**3):.2f} GB")
            for model_name, size in sorted(cached_models, key=lambda x: x[1], reverse=True):
                print(f"   ‚Ä¢ {model_name}: {size / (1024**3):.2f} GB")
        else:
            print("üì• –ö–µ—à –ø—É—Å—Ç, –º–æ–¥–µ–ª–∏ –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏")
        
        return True
    
    def recommend_mode(self):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
        gpu_info = self.get_gpu_info()
        
        if not gpu_info:
            return "transformers", "GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è Transformers (CPU)"
        
        free_gb = gpu_info['free_gb']
        total_gb = gpu_info['total_gb']
        
        print(f"üìä GPU –ø–∞–º—è—Ç—å: {free_gb:.1f} GB —Å–≤–æ–±–æ–¥–Ω–æ –∏–∑ {total_gb:.1f} GB")
        
        if free_gb >= 10:
            return "vllm", f"–û—Ç–ª–∏—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å vLLM ({free_gb:.1f} GB —Å–≤–æ–±–æ–¥–Ω–æ)"
        elif free_gb >= 6:
            return "vllm", f"–•–æ—Ä–æ—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å vLLM ({free_gb:.1f} GB —Å–≤–æ–±–æ–¥–Ω–æ)"
        elif free_gb >= 3:
            return "transformers", f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è Transformers —Ä–µ–∂–∏–º ({free_gb:.1f} GB —Å–≤–æ–±–æ–¥–Ω–æ)"
        else:
            return "transformers", f"–¢–æ–ª—å–∫–æ Transformers —Ä–µ–∂–∏–º –≤–æ–∑–º–æ–∂–µ–Ω ({free_gb:.1f} GB —Å–≤–æ–±–æ–¥–Ω–æ)"
    
    def start_transformers_mode(self, models=None):
        """–ó–∞–ø—É—Å–∫ Transformers —Ä–µ–∂–∏–º–∞"""
        if not models:
            models = ["rednote-hilab/dots.ocr"]
        
        print(f"ü§ñ –ó–∞–ø—É—Å–∫ Transformers —Ä–µ–∂–∏–º–∞ —Å –º–æ–¥–µ–ª—è–º–∏: {', '.join(models)}")
        
        # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
        self.stop_all()
        
        # –ó–∞–ø—É—Å–∫ –º–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
        cmd = [
            "python", "transformers_multi_model_server.py"
        ]
        
        try:
            print("üîÑ –ó–∞–ø—É—Å–∫ –º–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω–æ–≥–æ Transformers —Å–µ—Ä–≤–µ—Ä–∞...")
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            self.running_processes.append({
                "process": process,
                "name": "Transformers Multi-Model Server",
                "port": 8000,
                "models": models
            })
            
            self.current_mode = "transformers"
            
            # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞
            print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞...")
            time.sleep(10)
            
            # –ê–≤—Ç–æ–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
            for model in models:
                if model in self.models_config["transformers"]:
                    print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model}...")
                    self.load_transformers_model(model)
            
            print("‚úÖ Transformers —Ä–µ–∂–∏–º –∑–∞–ø—É—â–µ–Ω")
            print("üì° API –¥–æ—Å—Ç—É–ø–Ω–æ –Ω–∞: http://localhost:8000")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ Transformers —Ä–µ–∂–∏–º–∞: {e}")
            return False
    
    def load_transformers_model(self, model_name):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤ Transformers —Ä–µ–∂–∏–º–µ"""
        try:
            payload = {"model": model_name}
            response = requests.post("http://localhost:8000/models/load", 
                                   json=payload, timeout=300)
            if response.status_code == 200:
                print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {model_name}: {response.text}")
                return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {model_name}: {e}")
            return False
    
    def start_vllm_mode(self, models=None):
        """–ó–∞–ø—É—Å–∫ vLLM —Ä–µ–∂–∏–º–∞ —á–µ—Ä–µ–∑ Docker Compose"""
        if not models:
            models = ["rednote-hilab/dots.ocr"]
        
        print(f"üöÄ –ó–∞–ø—É—Å–∫ vLLM —Ä–µ–∂–∏–º–∞ —Å –º–æ–¥–µ–ª—è–º–∏: {', '.join(models)}")
        
        # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
        self.stop_all()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        env = os.environ.copy()
        env["HOME"] = str(Path.home())
        
        # –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ Docker Compose
        try:
            if len(models) == 1 and models[0] == "rednote-hilab/dots.ocr":
                # –ó–∞–ø—É—Å–∫ —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏
                cmd = ["docker", "compose", "-f", "docker-compose-vllm.yml", "up", "-d", "dots-ocr"]
            else:
                # –ú–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω—ã–π —Ä–µ–∂–∏–º
                cmd = ["docker", "compose", "-f", "docker-compose-vllm.yml", 
                       "--profile", "multi-model", "up", "-d"]
            
            print(f"üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ: {' '.join(cmd)}")
            result = subprocess.run(cmd, env=env, check=True, capture_output=True, text=True)
            
            self.current_mode = "vllm"
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞—Ö
            self.running_containers = []
            for model in models:
                if model in self.models_config["vllm"]:
                    config = self.models_config["vllm"][model]
                    self.running_containers.append({
                        "name": config["container_name"],
                        "model": model,
                        "port": config["port"],
                        "config": config
                    })
            
            print("‚úÖ vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∑–∞–ø—É—â–µ–Ω—ã")
            print(f"üìÅ –ö–µ—à –ø—Ä–∏–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω: {self.cache_dir}")
            
            for container in self.running_containers:
                print(f"üì° {container['config']['name']}: http://localhost:{container['port']}")
            
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ vLLM: {e}")
            if e.stderr:
                print(f"‚ùå Stderr: {e.stderr}")
            return False
    
    def stop_all(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
        print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤...")
        
        # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ Python –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
        for proc_info in self.running_processes:
            try:
                proc_info["process"].terminate()
                proc_info["process"].wait(timeout=10)
                print(f"‚úÖ –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω {proc_info['name']}")
            except:
                try:
                    proc_info["process"].kill()
                except:
                    pass
        
        self.running_processes = []
        
        # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
        try:
            subprocess.run(["docker", "compose", "-f", "docker-compose-vllm.yml", "down"], 
                         check=False, capture_output=True)
            print("‚úÖ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        except:
            pass
        
        self.running_containers = []
        self.current_mode = None
    
    def wait_for_services(self, timeout=300):
        """–û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–æ–≤"""
        print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–æ–≤...")
        
        if self.current_mode == "transformers":
            endpoints = [{"name": "Transformers Server", "port": 8000}]
        elif self.current_mode == "vllm":
            endpoints = [{"name": container["config"]["name"], "port": container["port"]} 
                        for container in self.running_containers]
        else:
            print("‚ùå –ù–µ—Ç –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤")
            return False
        
        start_time = time.time()
        ready_services = set()
        
        while len(ready_services) < len(endpoints) and (time.time() - start_time) < timeout:
            for endpoint in endpoints:
                if endpoint["name"] in ready_services:
                    continue
                
                try:
                    response = requests.get(f"http://localhost:{endpoint['port']}/health", timeout=5)
                    if response.status_code == 200:
                        print(f"‚úÖ {endpoint['name']} –≥–æ—Ç–æ–≤")
                        ready_services.add(endpoint["name"])
                except:
                    pass
            
            if len(ready_services) < len(endpoints):
                time.sleep(10)
        
        if len(ready_services) == len(endpoints):
            print("üéâ –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã –≥–æ—Ç–æ–≤—ã!")
            return True
        else:
            print(f"‚ö†Ô∏è –ì–æ—Ç–æ–≤–æ {len(ready_services)} –∏–∑ {len(endpoints)} —Å–µ—Ä–≤–∏—Å–æ–≤")
            return False
    
    def show_status(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å"""
        print("\nüìä –¢–ï–ö–£–©–ò–ô –°–¢–ê–¢–£–° –°–ò–°–¢–ï–ú–´")
        print("=" * 40)
        
        # GPU –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        gpu_info = self.get_gpu_info()
        if gpu_info:
            print(f"üéÆ GPU –ø–∞–º—è—Ç—å: {gpu_info['used_gb']:.1f}/{gpu_info['total_gb']:.1f} GB")
            print(f"   –°–≤–æ–±–æ–¥–Ω–æ: {gpu_info['free_gb']:.1f} GB")
        else:
            print("üéÆ GPU: –ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        
        # –ö–µ—à –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"üìÅ –ö–µ—à: {self.cache_dir}")
        if self.cache_dir.exists():
            cache_size = sum(f.stat().st_size for f in self.cache_dir.rglob('*') if f.is_file())
            print(f"üíæ –†–∞–∑–º–µ—Ä –∫–µ—à–∞: {cache_size / (1024**3):.2f} GB")
        
        # –¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º
        print(f"üîß –†–µ–∂–∏–º: {self.current_mode or '–ù–µ –∑–∞–ø—É—â–µ–Ω'}")
        
        # –ó–∞–ø—É—â–µ–Ω–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
        if self.current_mode == "transformers" and self.running_processes:
            print("ü§ñ Transformers —Å–µ—Ä–≤–µ—Ä: http://localhost:8000")
        elif self.current_mode == "vllm" and self.running_containers:
            print(f"üöÄ vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã ({len(self.running_containers)}):")
            for container in self.running_containers:
                print(f"   ‚Ä¢ {container['config']['name']}: http://localhost:{container['port']}")
        else:
            print("üì° –°–µ—Ä–≤–∏—Å—ã: –ù–µ –∑–∞–ø—É—â–µ–Ω—ã")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        mode, reason = self.recommend_mode()
        print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {mode.upper()} —Ä–µ–∂–∏–º")
        print(f"   –ü—Ä–∏—á–∏–Ω–∞: {reason}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    launcher = IntegratedModelLauncher()
    
    print("üéØ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô –ó–ê–ü–£–°–ö–ê–¢–ï–õ–¨ –ú–û–î–ï–õ–ï–ô")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–µ—à–∞
    if not launcher.check_cache_setup():
        print("‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –∫–µ—à–∞")
        return
    
    while True:
        print("\nüîß –í–´–ë–ï–†–ò–¢–ï –†–ï–ñ–ò–ú –†–ê–ë–û–¢–´:")
        print("1. üìä –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
        print("2. ü§ñ –ó–∞–ø—É—Å—Ç–∏—Ç—å Transformers —Ä–µ–∂–∏–º")
        print("3. üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å vLLM —Ä–µ–∂–∏–º")
        print("4. üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º")
        print("5. üõë –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã")
        print("6. ‚è≥ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–∏—Å–æ–≤")
        print("7. üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º")
        print("8. üìÅ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–µ—à–µ–º")
        print("0. ‚ùå –í—ã—Ö–æ–¥")
        
        choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä: ").strip()
        
        if choice == "1":
            launcher.show_status()
            
        elif choice == "2":
            print("\nü§ñ TRANSFORMERS –†–ï–ñ–ò–ú")
            print("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏:")
            models = list(launcher.models_config["transformers"].keys())
            for i, model in enumerate(models, 1):
                config = launcher.models_config["transformers"][model]
                print(f"{i}. {config['name']} ({config['memory_8bit_gb']} GB)")
            
            selection = input("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, Enter –¥–ª—è DotsOCR): ").strip()
            if selection:
                indices = [int(x.strip()) for x in selection.split(',') if x.strip().isdigit()]
                selected_models = [models[i-1] for i in indices if 1 <= i <= len(models)]
            else:
                selected_models = ["rednote-hilab/dots.ocr"]
            
            if launcher.start_transformers_mode(selected_models):
                launcher.wait_for_services()
            
        elif choice == "3":
            print("\nüöÄ vLLM –†–ï–ñ–ò–ú")
            print("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞:")
            models = list(launcher.models_config["vllm"].keys())
            for i, model in enumerate(models, 1):
                config = launcher.models_config["vllm"][model]
                print(f"{i}. {config['name']} ({config['memory_required_gb']} GB)")
            
            selection = input("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, Enter –¥–ª—è DotsOCR): ").strip()
            if selection:
                indices = [int(x.strip()) for x in selection.split(',') if x.strip().isdigit()]
                selected_models = [models[i-1] for i in indices if 1 <= i <= len(models)]
            else:
                selected_models = ["rednote-hilab/dots.ocr"]
            
            if launcher.start_vllm_mode(selected_models):
                launcher.wait_for_services()
            
        elif choice == "4":
            if launcher.current_mode == "transformers":
                print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Å Transformers –Ω–∞ vLLM...")
                launcher.start_vllm_mode()
                launcher.wait_for_services()
            elif launcher.current_mode == "vllm":
                print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Å vLLM –Ω–∞ Transformers...")
                launcher.start_transformers_mode()
                launcher.wait_for_services()
            else:
                print("‚ùå –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è")
                
        elif choice == "5":
            launcher.stop_all()
            print("‚úÖ –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
            
        elif choice == "6":
            launcher.wait_for_services()
            
        elif choice == "7":
            if launcher.current_mode:
                print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {launcher.current_mode} —Ä–µ–∂–∏–º–∞...")
                subprocess.run(["python", "test_memory_optimized_ocr.py"])
            else:
                print("‚ùå –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
                
        elif choice == "8":
            print(f"\nüìÅ –£–ü–†–ê–í–õ–ï–ù–ò–ï –ö–ï–®–ï–ú")
            print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {launcher.cache_dir}")
            print("1. –ü–æ–∫–∞–∑–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ")
            print("2. –û—á–∏—Å—Ç–∏—Ç—å –∫–µ—à")
            print("3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å")
            
            cache_choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ: ").strip()
            if cache_choice == "1":
                launcher.check_cache_setup()
            elif cache_choice == "2":
                confirm = input("‚ö†Ô∏è –£–¥–∞–ª–∏—Ç—å –≤–µ—Å—å –∫–µ—à? (yes/no): ").strip().lower()
                if confirm == "yes":
                    import shutil
                    if launcher.cache_dir.exists():
                        shutil.rmtree(launcher.cache_dir)
                        launcher.cache_dir.mkdir(parents=True, exist_ok=True)
                        print("‚úÖ –ö–µ—à –æ—á–∏—â–µ–Ω")
            elif cache_choice == "3":
                launcher.check_cache_setup()
                
        elif choice == "0":
            launcher.stop_all()
            break
            
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")

if __name__ == "__main__":
    main()