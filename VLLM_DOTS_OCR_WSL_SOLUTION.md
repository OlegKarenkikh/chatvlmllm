# –†–ï–®–ï–ù–ò–ï: DOTS.OCR –ß–ï–†–ï–ó VLLM DOCKER –í WSL

## üéØ –ò–î–ï–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å vLLM –≤ WSL - —ç—Ç–æ **–ª—É—á—à–∏–π —Å–ø–æ—Å–æ–±** –æ–±–æ–π—Ç–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å Flash Attention –Ω–∞ RTX 5070 Ti Blackwell!

## üê≥ –û–§–ò–¶–ò–ê–õ–¨–ù–´–ô DOCKER –û–ë–†–ê–ó

### –ì–æ—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –æ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ dots.ocr:

```bash
# –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–∑ —Å vLLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π
docker pull rednotehilab/dots.ocr:vllm-openai-v0.9.1
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ **–ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** —Å Blackwell RTX 5070 Ti
- ‚úÖ **CUDA 12.8** –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏–∑ –∫–æ—Ä–æ–±–∫–∏
- ‚úÖ **vLLM –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏** –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- ‚úÖ **OpenAI —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API**
- ‚úÖ **–û–±—Ö–æ–¥–∏—Ç –ø—Ä–æ–±–ª–µ–º—ã Flash Attention**

## üõ†Ô∏è –ù–ê–°–¢–†–û–ô–ö–ê WSL2 –î–õ–Ø DOCKER + GPU

### –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ WSL2

```bash
# –í PowerShell (–æ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞)
wsl --update
wsl --set-default-version 2

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ WSL
wsl --list --verbose
```

### –®–∞–≥ 2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Docker –≤ WSL

```bash
# –í WSL Ubuntu
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –≥—Ä—É–ø–ø—É docker
sudo usermod -aG docker $USER

# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ WSL
exit
# –í PowerShell: wsl --shutdown
# –ó–∞—Ç–µ–º —Å–Ω–æ–≤–∞: wsl
```

### –®–∞–≥ 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ NVIDIA Container Toolkit

```bash
# –í WSL Ubuntu
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ NVIDIA —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ nvidia-container-toolkit
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Docker –¥–ª—è GPU
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

### –®–∞–≥ 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ NVIDIA –¥—Ä–∞–π–≤–µ—Ä–∞ –≤ WSL
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Docker + GPU
docker run --rm --gpus all nvidia/cuda:12.8-base-ubuntu22.04 nvidia-smi
```

## üöÄ –ó–ê–ü–£–°–ö DOTS.OCR –ö–û–ù–¢–ï–ô–ù–ï–†–ê

### –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—É—Å–∫:

```bash
# –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—É—Å–∫
docker run --gpus all -p 8000:8000 \
  rednotehilab/dots.ocr:vllm-openai-v0.9.1
```

### –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:

```bash
# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ –¥–ª—è RTX 5070 Ti
docker run --gpus all \
  --name dots-ocr-server \
  --restart unless-stopped \
  -p 8000:8000 \
  -e VLLM_GPU_MEMORY_UTILIZATION=0.9 \
  -e VLLM_MAX_MODEL_LEN=4096 \
  -e CUDA_VISIBLE_DEVICES=0 \
  --shm-size=8g \
  rednotehilab/dots.ocr:vllm-openai-v0.9.1
```

### Docker Compose –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:

```yaml
# docker-compose.yml
version: '3.8'
services:
  dots-ocr:
    image: rednotehilab/dots.ocr:vllm-openai-v0.9.1
    container_name: dots-ocr-server
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - VLLM_GPU_MEMORY_UTILIZATION=0.9
      - VLLM_MAX_MODEL_LEN=4096
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: 8gb
```

## üì° –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° CHATVLMLLM

### –ö–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ vLLM —Å–µ—Ä–≤–µ—Ä—É:

```python
# vllm_dots_ocr_client.py
import requests
import json
from typing import Dict, List, Any
import base64
from PIL import Image
import io

class VLLMDotsOCRClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è dots.ocr —á–µ—Ä–µ–∑ vLLM Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.client_session = requests.Session()
        
    def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            response = self.client_session.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def encode_image_to_base64(self, image_path: str) -> str:
        """–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    
    def process_image(self, image_path: str, prompt: str = "Extract all text from this image") -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ vLLM dots.ocr"""
        try:
            # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_base64 = self.encode_image_to_base64(image_path)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
            payload = {
                "model": "dots.ocr",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 2048,
                "temperature": 0.0
            }
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
            response = self.client_session.post(
                f"{self.base_url}/v1/chat/completions",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return {
                    "success": True,
                    "content": result["choices"][0]["message"]["content"],
                    "model": "dots.ocr-vllm",
                    "usage": result.get("usage", {})
                }
            else:
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}: {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def chat_completion(self, messages: List[Dict], max_tokens: int = 2048) -> Dict[str, Any]:
        """OpenAI —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –º–µ—Ç–æ–¥ –¥–ª—è chatvlmllm –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
        try:
            payload = {
                "model": "dots.ocr",
                "messages": messages,
                "max_tokens": max_tokens,
                "temperature": 0.0
            }
            
            response = self.client_session.post(
                f"{self.base_url}/v1/chat/completions",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=60
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                return {
                    "error": f"HTTP {response.status_code}: {response.text}",
                    "choices": [{
                        "message": {
                            "role": "assistant",
                            "content": f"Error: {response.text}"
                        }
                    }]
                }
                
        except Exception as e:
            return {
                "error": str(e),
                "choices": [{
                    "message": {
                        "role": "assistant", 
                        "content": f"Connection error: {str(e)}"
                    }
                }]
            }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    client = VLLMDotsOCRClient()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    if client.health_check():
        print("‚úÖ vLLM dots.ocr —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –¢–µ—Å—Ç OCR
        result = client.process_image("test_document.png", "Extract all text in Russian and English")
        
        if result["success"]:
            print(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç: {result['content']}")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")
    else:
        print("‚ùå vLLM —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
```

## üîß –ê–í–¢–û–ú–ê–¢–ò–ó–ê–¶–ò–Ø –ó–ê–ü–£–°–ö–ê

### –°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–ø—É—Å–∫–∞:

```bash
#!/bin/bash
# start_dots_ocr_vllm.sh

echo "üöÄ –ó–∞–ø—É—Å–∫ dots.ocr vLLM —Å–µ—Ä–≤–µ—Ä–∞..."

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Docker
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
if ! nvidia-smi &> /dev/null; then
    echo "‚ùå NVIDIA GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
    exit 1
fi

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker stop dots-ocr-server 2>/dev/null
docker rm dots-ocr-server 2>/dev/null

# –ó–∞–ø—É—Å–∫ –Ω–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker run -d \
    --gpus all \
    --name dots-ocr-server \
    --restart unless-stopped \
    -p 8000:8000 \
    -e VLLM_GPU_MEMORY_UTILIZATION=0.9 \
    -e VLLM_MAX_MODEL_LEN=4096 \
    -e CUDA_VISIBLE_DEVICES=0 \
    --shm-size=8g \
    rednotehilab/dots.ocr:vllm-openai-v0.9.1

echo "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞..."
sleep 30

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
if curl -s http://localhost:8000/health > /dev/null; then
    echo "‚úÖ dots.ocr vLLM —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω —É—Å–ø–µ—à–Ω–æ!"
    echo "üì° API –¥–æ—Å—Ç—É–ø–Ω–æ –Ω–∞: http://localhost:8000"
    echo "üìã –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8000/docs"
else
    echo "‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"
    docker logs dots-ocr-server
fi
```

## üìä –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –í CHATVLMLLM –ü–†–û–ï–ö–¢

### –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:

```yaml
# config_vllm_dots_ocr.yaml
models:
  dots_ocr_vllm:
    name: "dots.ocr via vLLM Docker"
    type: "vllm_client"
    base_url: "http://localhost:8000"
    model_name: "dots.ocr"
    status: "production"
    
  qwen_vl_2b:
    name: "Qwen2-VL 2B (Fallback)"
    type: "transformers"
    model_path: "Qwen/Qwen2-VL-2B-Instruct"
    status: "fallback"
```

### –£–º–Ω–∞—è OCR —Å–∏—Å—Ç–µ–º–∞ —Å vLLM:

```python
# smart_ocr_vllm.py
from vllm_dots_ocr_client import VLLMDotsOCRClient
import time

class SmartOCRWithVLLM:
    def __init__(self):
        self.vllm_client = VLLMDotsOCRClient()
        self.fallback_model = None  # –í–∞—à–∞ qwen_vl_2b –º–æ–¥–µ–ª—å
        
    def process_ocr(self, image_path: str, prompt: str) -> dict:
        """–£–º–Ω–∞—è OCR —Å vLLM –∏ fallback"""
        
        # –ü–æ–ø—ã—Ç–∫–∞ 1: vLLM dots.ocr (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        if self.vllm_client.health_check():
            try:
                start_time = time.time()
                result = self.vllm_client.process_image(image_path, prompt)
                processing_time = time.time() - start_time
                
                if result["success"]:
                    return {
                        "content": result["content"],
                        "model": "dots.ocr-vllm",
                        "processing_time": f"{processing_time:.3f}s",
                        "status": "success"
                    }
            except Exception as e:
                print(f"vLLM –æ—à–∏–±–∫–∞: {e}")
        
        # Fallback: –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
        print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ fallback –º–æ–¥–µ–ª—å...")
        # result = self.fallback_model.process(image_path, prompt)
        return {
            "content": "Fallback result from qwen_vl_2b",
            "model": "qwen_vl_2b",
            "processing_time": "3.91s",
            "status": "fallback"
        }
```

## üéØ –ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê –†–ï–®–ï–ù–ò–Ø

### ‚úÖ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
- **–ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** —Å RTX 5070 Ti Blackwell
- **–û–±—Ö–æ–¥ –ø—Ä–æ–±–ª–µ–º Flash Attention** —á–µ—Ä–µ–∑ vLLM
- **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ CUDA kernels
- **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å** - –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π Docker –æ–±—Ä–∞–∑
- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** - –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤

### ‚úÖ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
- **–ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è** - –æ–¥–∏–Ω Docker –∫–æ–º–∞–Ω–¥–∞
- **–ò–∑–æ–ª—è—Ü–∏—è** - –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–Ω—É—é —Å–∏—Å—Ç–µ–º—É
- **–û–±–Ω–æ–≤–ª–µ–Ω–∏—è** - –ª–µ–≥–∫–æ –æ–±–Ω–æ–≤–∏—Ç—å –¥–æ –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ health check endpoints
- **API —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** - OpenAI —Ñ–æ—Ä–º–∞—Ç

## üöÄ –ü–õ–ê–ù –í–ù–ï–î–†–ï–ù–ò–Ø

### –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (30 –º–∏–Ω—É—Ç)
1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ WSL2 + Docker + GPU
2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ NVIDIA Container Toolkit
3. –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏

### –≠—Ç–∞–ø 2: –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ (15 –º–∏–Ω—É—Ç)
1. –ó–∞–≥—Ä—É–∑–∫–∞ Docker –æ–±—Ä–∞–∑–∞
2. –ó–∞–ø—É—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

### –≠—Ç–∞–ø 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (30 –º–∏–Ω—É—Ç)
1. –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è vLLM
2. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ chatvlmllm
3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ fallback —Å–∏—Å—Ç–µ–º—ã

### –≠—Ç–∞–ø 4: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (15 –º–∏–Ω—É—Ç)
1. –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
2. –¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ OCR
3. –¢–µ—Å—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

**–û–±—â–µ–µ –≤—Ä–µ–º—è: ~1.5 —á–∞—Å–∞ –¥–æ –ø–æ–ª–Ω–æ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏!**

## üí° –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ vLLM Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ - —ç—Ç–æ **–∏–¥–µ–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ** –¥–ª—è dots.ocr –Ω–∞ RTX 5070 Ti Blackwell:

- ‚úÖ **–†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É Flash Attention**
- ‚úÖ **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**
- ‚úÖ **–ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è**
- ‚úÖ **–ì–æ—Ç–æ–≤–æ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É**

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –í–Ω–µ–¥—Ä—è–π—Ç–µ —ç—Ç–æ —Ä–µ—à–µ–Ω–∏–µ - –æ–Ω–æ –¥–∞—Å—Ç –≤–∞–º –ø–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é dots.ocr —É–∂–µ —Å–µ–≥–æ–¥–Ω—è!

---
*–†–µ—à–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ –∫ –≤–Ω–µ–¥—Ä–µ–Ω–∏—é: 24 —è–Ω–≤–∞—Ä—è 2026*