#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π vLLM —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
"""

import json
import time
import requests
import base64
from pathlib import Path
from typing import Dict, Any, List

class VLLMModelTester:
    def __init__(self, config_file: str = "vllm_models_config.json"):
        self.config_file = config_file
        self.configs = self.load_configs()
        self.test_images = [
            "test_documents/01_simple_text.png",
            "test_documents/02_table.png", 
            "test_documents/04_numbers.png"
        ]
        
    def load_configs(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –º–æ–¥–µ–ª–µ–π"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {e}")
            return {}
    
    def check_model_health(self, model_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        if model_name not in self.configs:
            return False
        
        port = self.configs[model_name]['port']
        try:
            response = requests.get(f"http://localhost:{port}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def test_model_ocr(self, model_name: str, image_path: str) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OCR –º–æ–¥–µ–ª–∏"""
        if not Path(image_path).exists():
            return {"success": False, "error": f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}"}
        
        port = self.configs[model_name]['port']
        
        try:
            # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            with open(image_path, "rb") as f:
                image_data = f.read()
            
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
            payload = {
                "model": model_name,
                "messages": [{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "Extract all text from this image"},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_base64}"}}
                    ]
                }],
                "max_tokens": 1000,
                "temperature": 0.1
            }
            
            start_time = time.time()
            response = requests.post(
                f"http://localhost:{port}/v1/chat/completions",
                json=payload,
                timeout=120
            )
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                text = result["choices"][0]["message"]["content"]
                
                return {
                    "success": True,
                    "text": text,
                    "processing_time": round(processing_time, 2),
                    "word_count": len(text.split()),
                    "char_count": len(text),
                    "usage": result.get("usage", {}),
                    "image_path": image_path
                }
            else:
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}: {response.text[:200]}"
                }
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def test_model_text(self, model_name: str, prompt: str) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        port = self.configs[model_name]['port']
        
        try:
            payload = {
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 500,
                "temperature": 0.1
            }
            
            start_time = time.time()
            response = requests.post(
                f"http://localhost:{port}/v1/chat/completions",
                json=payload,
                timeout=60
            )
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                text = result["choices"][0]["message"]["content"]
                
                return {
                    "success": True,
                    "text": text,
                    "processing_time": round(processing_time, 2),
                    "word_count": len(text.split()),
                    "usage": result.get("usage", {})
                }
            else:
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}: {response.text[:200]}"
                }
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        print("üß™ –ö–û–ú–ü–õ–ï–ö–°–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô VLLM")
        print("=" * 45)
        
        results = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "models_tested": {},
            "summary": {}
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        available_models = []
        for model_name in self.configs:
            if self.check_model_health(model_name):
                available_models.append(model_name)
                print(f"‚úÖ {model_name} - –¥–æ—Å—Ç—É–ø–Ω–∞")
            else:
                print(f"‚ùå {model_name} - –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        
        if not available_models:
            print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return results
        
        print(f"\nüéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(available_models)} –º–æ–¥–µ–ª–µ–π...")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        for model_name in available_models:
            print(f"\nüîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {model_name}...")
            
            model_results = {
                "model_info": self.configs[model_name],
                "ocr_tests": [],
                "text_tests": [],
                "performance": {}
            }
            
            # OCR —Ç–µ—Å—Ç—ã
            ocr_times = []
            ocr_successes = 0
            
            for image_path in self.test_images:
                if Path(image_path).exists():
                    print(f"   üì∑ –¢–µ—Å—Ç OCR: {Path(image_path).name}")
                    result = self.test_model_ocr(model_name, image_path)
                    model_results["ocr_tests"].append(result)
                    
                    if result["success"]:
                        ocr_successes += 1
                        ocr_times.append(result["processing_time"])
                        print(f"      ‚úÖ {result['processing_time']}—Å, {result['word_count']} —Å–ª–æ–≤")
                    else:
                        print(f"      ‚ùå {result['error']}")
            
            # –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ç–µ—Å—Ç—ã
            text_prompts = [
                "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
                "–û–ø–∏—à–∏ –ø—Ä–æ—Ü–µ—Å—Å —Ñ–æ—Ç–æ—Å–∏–Ω—Ç–µ–∑–∞",
                "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?"
            ]
            
            text_times = []
            text_successes = 0
            
            for prompt in text_prompts:
                print(f"   üí¨ –¢–µ—Å—Ç —Ç–µ–∫—Å—Ç–∞: {prompt[:30]}...")
                result = self.test_model_text(model_name, prompt)
                model_results["text_tests"].append(result)
                
                if result["success"]:
                    text_successes += 1
                    text_times.append(result["processing_time"])
                    print(f"      ‚úÖ {result['processing_time']}—Å, {result['word_count']} —Å–ª–æ–≤")
                else:
                    print(f"      ‚ùå {result['error']}")
            
            # –†–∞—Å—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            model_results["performance"] = {
                "ocr_success_rate": round((ocr_successes / len(self.test_images)) * 100, 1) if self.test_images else 0,
                "ocr_avg_time": round(sum(ocr_times) / len(ocr_times), 2) if ocr_times else 0,
                "text_success_rate": round((text_successes / len(text_prompts)) * 100, 1),
                "text_avg_time": round(sum(text_times) / len(text_times), 2) if text_times else 0,
                "total_tests": len(self.test_images) + len(text_prompts),
                "total_successes": ocr_successes + text_successes
            }
            
            results["models_tested"][model_name] = model_results
            
            perf = model_results["performance"]
            print(f"   üìä OCR: {perf['ocr_success_rate']}% —É—Å–ø–µ—Ö, {perf['ocr_avg_time']}—Å —Å—Ä–µ–¥–Ω–µ–µ")
            print(f"   üìä –¢–µ–∫—Å—Ç: {perf['text_success_rate']}% —É—Å–ø–µ—Ö, {perf['text_avg_time']}—Å —Å—Ä–µ–¥–Ω–µ–µ")
        
        # –û–±—â–∞—è —Å–≤–æ–¥–∫–∞
        print(f"\nüìà –°–í–û–î–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("=" * 25)
        
        summary = {
            "total_models": len(available_models),
            "best_ocr_model": None,
            "best_text_model": None,
            "fastest_model": None
        }
        
        best_ocr_rate = 0
        best_text_rate = 0
        fastest_time = float('inf')
        
        for model_name, model_data in results["models_tested"].items():
            perf = model_data["performance"]
            
            # –õ—É—á—à–∞—è OCR –º–æ–¥–µ–ª—å
            if perf["ocr_success_rate"] > best_ocr_rate:
                best_ocr_rate = perf["ocr_success_rate"]
                summary["best_ocr_model"] = model_name
            
            # –õ—É—á—à–∞—è —Ç–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å
            if perf["text_success_rate"] > best_text_rate:
                best_text_rate = perf["text_success_rate"]
                summary["best_text_model"] = model_name
            
            # –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å
            avg_time = (perf["ocr_avg_time"] + perf["text_avg_time"]) / 2
            if avg_time < fastest_time and avg_time > 0:
                fastest_time = avg_time
                summary["fastest_model"] = model_name
            
            print(f"üèÜ {model_name}:")
            print(f"   OCR: {perf['ocr_success_rate']}% ({perf['ocr_avg_time']}—Å)")
            print(f"   –¢–µ–∫—Å—Ç: {perf['text_success_rate']}% ({perf['text_avg_time']}—Å)")
            print(f"   –û–±—â–∏–π —É—Å–ø–µ—Ö: {perf['total_successes']}/{perf['total_tests']}")
        
        results["summary"] = summary
        
        print(f"\nü•á –õ–£–ß–®–ò–ï –ú–û–î–ï–õ–ò:")
        if summary["best_ocr_model"]:
            print(f"   OCR: {summary['best_ocr_model']} ({best_ocr_rate}%)")
        if summary["best_text_model"]:
            print(f"   –¢–µ–∫—Å—Ç: {summary['best_text_model']} ({best_text_rate}%)")
        if summary["fastest_model"]:
            print(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {summary['fastest_model']} ({fastest_time:.2f}—Å)")
        
        return results
    
    def save_results(self, results: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # JSON –æ—Ç—á–µ—Ç
        json_file = f"vllm_test_results_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        txt_file = f"vllm_test_summary_{timestamp}.txt"
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write("–û–¢–ß–ï–¢ –û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ò –ú–û–î–ï–õ–ï–ô VLLM\n")
            f.write("=" * 40 + "\n")
            f.write(f"–î–∞—Ç–∞: {results['timestamp']}\n")
            f.write(f"–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(results['models_tested'])}\n\n")
            
            for model_name, model_data in results["models_tested"].items():
                f.write(f"–ú–û–î–ï–õ–¨: {model_name}\n")
                f.write("-" * 30 + "\n")
                
                config = model_data["model_info"]
                f.write(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {config['category']}\n")
                f.write(f"–†–∞–∑–º–µ—Ä: {config['size_gb']} –ì–ë\n")
                f.write(f"–ü–æ—Ä—Ç: {config['port']}\n")
                
                perf = model_data["performance"]
                f.write(f"OCR —É—Å–ø–µ—Ö: {perf['ocr_success_rate']}%\n")
                f.write(f"OCR –≤—Ä–µ–º—è: {perf['ocr_avg_time']}—Å\n")
                f.write(f"–¢–µ–∫—Å—Ç —É—Å–ø–µ—Ö: {perf['text_success_rate']}%\n")
                f.write(f"–¢–µ–∫—Å—Ç –≤—Ä–µ–º—è: {perf['text_avg_time']}—Å\n")
                f.write(f"–û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {perf['total_successes']}/{perf['total_tests']}\n\n")
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        print(f"   üìÑ {json_file}")
        print(f"   üìÑ {txt_file}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    tester = VLLMModelTester()
    
    if not tester.configs:
        print("‚ùå –ù–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –º–æ–¥–µ–ª–µ–π")
        return
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    results = tester.run_comprehensive_test()
    
    if results["models_tested"]:
        tester.save_results(results)
        print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    else:
        print("\n‚ùå –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")

if __name__ == "__main__":
    main()