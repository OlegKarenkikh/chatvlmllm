#!/usr/bin/env python3
"""
dots.ocr –º–æ–¥–µ–ª—å, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è RTX 5070 Ti Blackwell
–ë–µ–∑ flash-attn, —Å eager attention –∏ bfloat16 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
"""

import torch
import time
from transformers import AutoModelForCausalLM, AutoProcessor
from PIL import Image
import logging

logger = logging.getLogger(__name__)

class DotsOCRBlackwellModel:
    def __init__(self):
        self.model = None
        self.processor = None
        self.model_name = "rednote-hilab/dots.ocr"
        
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å Blackwell –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏"""
        try:
            start_time = time.time()
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º Blackwell –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            torch.backends.cudnn.benchmark = True
            torch.backends.cuda.enable_flash_sdp(True)
            
            logger.info("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º dots.ocr —Å Blackwell –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏...")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è Blackwell
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                torch_dtype=torch.bfloat16,  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è Blackwell
                attn_implementation="eager",  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è RTX 5070 Ti
                device_map="auto",
                trust_remote_code=True,
                low_cpu_mem_usage=True
            )
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
            self.processor = AutoProcessor.from_pretrained(
                self.model_name,
                trust_remote_code=True
            )
            
            load_time = time.time() - start_time
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
            vram_used = torch.cuda.memory_allocated() / 1024**3
            
            logger.info(f"‚úÖ dots.ocr –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f}s")
            logger.info(f"‚úÖ Dtype: {self.model.dtype}")
            logger.info(f"‚úÖ Device: {self.model.device}")
            logger.info(f"‚úÖ VRAM: {vram_used:.2f}GB")
            logger.info(f"‚úÖ Attention: eager (Blackwell compatible)")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ dots.ocr: {e}")
            return False
    
    def process_image(self, image, prompt="Extract all text from this image"):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
        if not self.model or not self.processor:
            logger.error("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return None
            
        try:
            start_time = time.time()
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if isinstance(image, str):
                image = Image.open(image).convert('RGB')
            elif not isinstance(image, Image.Image):
                logger.error("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                return None
            
            # –°–æ–∑–¥–∞–Ω–∏–µ conversation –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            conversation = [
                {
                    "role": "user", 
                    "content": [
                        {"type": "image", "image": image},
                        {"type": "text", "text": prompt}
                    ]
                }
            ]
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ chat template
            text_prompt = self.processor.apply_chat_template(
                conversation, 
                tokenize=False, 
                add_generation_prompt=True
            )
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            inputs = self.processor(
                text=[text_prompt],
                images=[image],
                padding=True,
                return_tensors="pt"
            ).to("cuda")
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è Blackwell
            with torch.no_grad():
                generated_ids = self.model.generate(
                    **inputs,
                    max_new_tokens=512,
                    do_sample=False,
                    temperature=0.0,
                    use_cache=True,
                    pad_token_id=self.processor.tokenizer.eos_token_id,
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    repetition_penalty=1.1,
                    length_penalty=1.0
                )
            
            # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, 
                skip_special_tokens=True, 
                clean_up_tokenization_spaces=False
            )[0]
            
            processing_time = time.time() - start_time
            
            logger.info(f"‚è±Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.3f}s")
            logger.info(f"üìù –î–ª–∏–Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {len(output_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            return output_text.strip()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return None
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏"""
        if self.model:
            del self.model
        if self.processor:
            del self.processor
        torch.cuda.empty_cache()
        logger.info("üßπ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")

def test_dots_ocr_blackwell():
    """–¢–µ—Å—Ç dots.ocr —Å Blackwell –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏"""
    print("üß™ –¢–ï–°–¢ DOTS.OCR BLACKWELL COMPATIBLE")
    print("=" * 60)
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
    print(f"üñ•Ô∏è GPU: {torch.cuda.get_device_name(0)}")
    print(f"üîß Compute Capability: {torch.cuda.get_device_capability(0)}")
    print(f"üêç PyTorch: {torch.__version__}")
    print(f"‚ö° CUDA: {torch.version.cuda}")
    print(f"‚úÖ bfloat16: {torch.cuda.is_bf16_supported()}")
    print()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model = DotsOCRBlackwellModel()
    
    if not model.load_model():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
        return False
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print("üîç –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    test_image = Image.new('RGB', (800, 600), color='white')
    
    # –¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    print("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    result = model.process_image(
        test_image, 
        "Extract all text from this image in Russian"
    )
    
    if result:
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–µ–Ω: {result[:100]}...")
        print("üéâ DOTS.OCR –†–ê–ë–û–¢–ê–ï–¢ –° BLACKWELL!")
        success = True
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
        success = False
    
    # –û—á–∏—Å—Ç–∫–∞
    model.cleanup()
    
    return success

if __name__ == "__main__":
    success = test_dots_ocr_blackwell()
    if success:
        print("\nüöÄ DOTS.OCR –ì–û–¢–û–í–ê –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ –ù–ê RTX 5070 TI!")
    else:
        print("\n‚ùå –¢–†–ï–ë–£–ï–¢–°–Ø –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê")