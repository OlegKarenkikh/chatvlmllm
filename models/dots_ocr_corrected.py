"""
–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø dots.ocr –ù–ê –û–°–ù–û–í–ï –û–§–ò–¶–ò–ê–õ–¨–ù–û–ô –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–ò

–û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞:
- –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: https://github.com/rednote-hilab/dots.ocr
- Hugging Face: https://huggingface.co/rednote-hilab/dots.ocr
- –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

–ö–ª—é—á–µ–≤—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
1. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
2. –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
3. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
4. –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ CUDA –æ—à–∏–±–æ–∫
5. –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
"""

import os
import json
import torch
from typing import Any, Dict, List, Optional, Union
from PIL import Image
import traceback

from models.base_model import BaseModel
from utils.logger import logger


class DotsOCRCorrectedModel(BaseModel):
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è dots.ocr —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.model = None
        self.processor = None
        self.max_new_tokens = config.get('max_new_tokens', 24000)
        
        # –û—Ç–∫–ª—é—á–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        os.environ["TOKENIZERS_PARALLELISM"] = "false"
        
        # –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        self.official_prompts = {
            "layout_all": """Please output the layout information from the PDF image, including each layout element's bbox, its category, and the corresponding text content within the bbox.

1. Bbox format: [x1, y1, x2, y2]

2. Layout Categories: The possible categories are ['Caption', 'Footnote', 'Formula', 'List-item', 'Page-footer', 'Page-header', 'Picture', 'Section-header', 'Table', 'Text', 'Title'].

3. Text Extraction & Formatting Rules:
    - Picture: For the 'Picture' category, the text field should be omitted.
    - Formula: Format its text as LaTeX.
    - Table: Format its text as HTML.
    - All Others (Text, Title, etc.): Format their text as Markdown.

4. Constraints:
    - The output text must be the original text from the image, with no translation.
    - All layout elements must be sorted according to human reading order.

5. Final Output: The entire output must be a single JSON object.""",
            
            "ocr_only": "Extract all text from this image, maintaining the original reading order.",
            
            "text_only": "Please extract all text content from this image without any layout information or formatting.",
            
            "simple_ocr": "What text do you see in this image?"
        }
    
    def load_model(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
        try:
            logger.info(f"Loading dots.ocr from {self.model_path}")
            
            from transformers import AutoModelForCausalLM, AutoProcessor
            
            device = self._get_device()
            logger.info(f"Using device: {device}")
            
            # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∑–∫–∏
            load_kwargs = self._get_load_kwargs()
            
            # –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            load_kwargs.update({
                'torch_dtype': torch.bfloat16,
                'trust_remote_code': True,
                'attn_implementation': "eager"  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π fallback
            })
            
            # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Flash Attention
                import flash_attn
                load_kwargs['attn_implementation'] = "flash_attention_2"
                logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º flash_attention_2 –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
            except ImportError:
                # –ü—Ä–æ–±—É–µ–º PyTorch SDPA
                try:
                    if torch.cuda.is_available():
                        # –¢–µ—Å—Ç–∏—Ä—É–µ–º SDPA
                        test_tensor = torch.randn(1, 1, 10, 64, device='cuda', dtype=torch.bfloat16)
                        torch.nn.functional.scaled_dot_product_attention(test_tensor, test_tensor, test_tensor)
                        load_kwargs['attn_implementation'] = "sdpa"
                        logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º PyTorch SDPA")
                    else:
                        logger.info("üí° –ò—Å–ø–æ–ª—å–∑—É–µ–º eager attention (CPU —Ä–µ–∂–∏–º)")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è SDPA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                    logger.info("üí° –ò—Å–ø–æ–ª—å–∑—É–µ–º eager attention (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∂–∏–º)")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            logger.info("Loading model weights...")
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_path,
                **load_kwargs
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
            logger.info("Loading processor...")
            self.processor = AutoProcessor.from_pretrained(
                self.model_path, 
                trust_remote_code=True
            )
            
            self.model.eval()
            logger.info("dots.ocr loaded successfully")
            
        except Exception as e:
            logger.error(f"Failed to load dots.ocr: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise
    
    def _safe_inference(self, image: Image.Image, prompt: str) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ —á–∞—Ç–∞
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image", "image": image},
                        {"type": "text", "text": prompt}
                    ]
                }
            ]
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —à–∞–±–ª–æ–Ω —á–∞—Ç–∞
            text = self.processor.apply_chat_template(
                messages, 
                tokenize=False, 
                add_generation_prompt=True
            )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–∑—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            try:
                from qwen_vl_utils import process_vision_info
                image_inputs, video_inputs = process_vision_info(messages)
            except ImportError:
                logger.warning("qwen_vl_utils –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥")
                image_inputs = [image]
                video_inputs = None
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            inputs = self.processor(
                text=[text],
                images=image_inputs,
                videos=video_inputs,
                padding=True,
                return_tensors="pt"
            )
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            device = next(self.model.parameters()).device
            inputs = inputs.to(device)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            with torch.no_grad():
                generated_ids = self.model.generate(
                    **inputs, 
                    max_new_tokens=self.max_new_tokens,
                    do_sample=False,  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
                    temperature=0.1,
                    pad_token_id=self.processor.tokenizer.eos_token_id
                )
            
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            generated_ids_trimmed = [
                out_ids[len(in_ids):] 
                for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, 
                skip_special_tokens=True, 
                clean_up_tokenization_spaces=False
            )[0]
            
            return output_text.strip()
            
        except Exception as e:
            logger.error(f"Inference failed: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise
    
    def _parse_json_result(self, raw_output: str) -> Union[Dict, str]:
        """–ü–∞—Ä—Å–∏–º JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π."""
        if not raw_output or raw_output.strip() == "":
            return "Empty result"
        
        # –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON
        try:
            # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
            cleaned_output = raw_output.strip()
            
            # –ò—â–µ–º JSON –æ–±—ä–µ–∫—Ç –≤ —Ç–µ–∫—Å—Ç–µ
            start_idx = cleaned_output.find('{')
            end_idx = cleaned_output.rfind('}')
            
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                json_str = cleaned_output[start_idx:end_idx+1]
                parsed_json = json.loads(json_str)
                
                # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –º–∞–∫–µ—Ç–∞, –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
                if isinstance(parsed_json, list):
                    return self._extract_text_from_layout(parsed_json)
                elif isinstance(parsed_json, dict):
                    return self._extract_text_from_layout_dict(parsed_json)
                else:
                    return str(parsed_json)
            else:
                # JSON –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                return cleaned_output
                
        except json.JSONDecodeError as e:
            logger.warning(f"JSON decode error: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –µ—Å–ª–∏ JSON –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è
            return raw_output
        except Exception as e:
            logger.error(f"Error parsing result: {e}")
            return raw_output
    
    def _extract_text_from_layout(self, layout_list: List[Dict]) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –º–∞–∫–µ—Ç–∞."""
        try:
            text_parts = []
            
            for element in layout_list:
                if isinstance(element, dict):
                    # –ò—â–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–ª—è—Ö
                    text_content = None
                    
                    # –í–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ–ª—è —Å —Ç–µ–∫—Å—Ç–æ–º
                    text_fields = ['text', 'content', 'value', 'ocr_text', 'extracted_text']
                    
                    for field in text_fields:
                        if field in element and element[field]:
                            text_content = element[field]
                            break
                    
                    if text_content:
                        # –û—á–∏—â–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
                        cleaned_text = str(text_content).strip()
                        if cleaned_text and cleaned_text not in text_parts:
                            text_parts.append(cleaned_text)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç
            if text_parts:
                return '\n'.join(text_parts)
            else:
                return "No text content found in layout"
                
        except Exception as e:
            logger.error(f"Error extracting text from layout: {e}")
            return str(layout_list)
    
    def _extract_text_from_layout_dict(self, layout_dict: Dict) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Å–ª–æ–≤–∞—Ä—è –º–∞–∫–µ—Ç–∞."""
        try:
            # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å —Å —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏
            if 'elements' in layout_dict:
                return self._extract_text_from_layout(layout_dict['elements'])
            elif 'layout' in layout_dict:
                return self._extract_text_from_layout(layout_dict['layout'])
            elif 'text' in layout_dict:
                return str(layout_dict['text'])
            elif 'content' in layout_dict:
                return str(layout_dict['content'])
            else:
                # –ò—â–µ–º –ª—é–±—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è
                text_parts = []
                for key, value in layout_dict.items():
                    if isinstance(value, str) and len(value.strip()) > 0:
                        text_parts.append(value.strip())
                    elif isinstance(value, list):
                        for item in value:
                            if isinstance(item, dict) and 'text' in item:
                                text_parts.append(str(item['text']).strip())
                
                return '\n'.join(text_parts) if text_parts else str(layout_dict)
                
        except Exception as e:
            logger.error(f"Error extracting text from layout dict: {e}")
            return str(layout_dict)
    
    def process_image(self, image: Image.Image, prompt: Optional[str] = None, 
                     mode: str = "ocr_only") -> str:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π."""
        if self.model is None:
            raise RuntimeError("Model not loaded")
        
        try:
            # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç
            if prompt is None:
                prompt = self.official_prompts.get(mode, self.official_prompts["ocr_only"])
            
            logger.info(f"Processing with mode: {mode}")
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if image is None:
                raise ValueError("Image is None")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
            raw_result = self._safe_inference(image, prompt)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if mode == "layout_all":
                # –î–ª—è —Ä–µ–∂–∏–º–∞ layout_all –æ–∂–∏–¥–∞–µ–º JSON
                processed_result = self._parse_json_result(raw_result)
            else:
                # –î–ª—è OCR —Ä–µ–∂–∏–º–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –∫–∞–∫ –µ—Å—Ç—å
                processed_result = raw_result
            
            logger.info("Processing completed successfully")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if isinstance(processed_result, str):
                return processed_result if processed_result else "[dots.ocr: Empty result]"
            else:
                return str(processed_result)
            
        except Exception as e:
            logger.error(f"Error processing image: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return f"[dots.ocr error: {e}]"
    
    def chat(self, image: Image.Image, prompt: str, **kwargs) -> str:
        """–ß–∞—Ç —Å –º–æ–¥–µ–ª—å—é."""
        return self.process_image(image, prompt=prompt, mode="custom")
    
    def extract_text(self, image: Image.Image) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –±–µ–∑ –º–∞–∫–µ—Ç–∞."""
        return self.process_image(image, mode="text_only")
    
    def parse_document(self, image: Image.Image) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–º –¥–æ–∫—É–º–µ–Ω—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–∞–∫–µ—Ç–µ."""
        try:
            result = self.process_image(image, mode="layout_all")
            
            # –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON
            try:
                parsed = json.loads(result)
                return {
                    "success": True,
                    "layout": parsed,
                    "text": self._extract_text_from_layout(parsed) if isinstance(parsed, list) else str(parsed)
                }
            except json.JSONDecodeError:
                return {
                    "success": False,
                    "raw_result": result,
                    "text": result
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "text": f"Error: {e}"
            }
    
    def unload(self) -> None:
        """–í—ã–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å."""
        try:
            if self.model is not None:
                del self.model
                self.model = None
            if self.processor is not None:
                del self.processor
                self.processor = None
            
            # –û—á–∏—â–∞–µ–º CUDA –∫–µ—à –±–µ–∑–æ–ø–∞—Å–Ω–æ
            if torch.cuda.is_available():
                try:
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                except Exception as e:
                    logger.warning(f"Warning during CUDA cleanup: {e}")
            
            logger.info("dots.ocr unloaded successfully")
            
        except Exception as e:
            logger.warning(f"Warning during model unload: {e}")