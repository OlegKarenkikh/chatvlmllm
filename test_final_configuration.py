#!/usr/bin/env python3
"""
–§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ - —Ç–æ–ª—å–∫–æ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –º–æ–¥–µ–ª–∏
"""

import time
import torch
from PIL import Image, ImageDraw, ImageFont
import sys
import os
import yaml

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def load_config():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
    with open('config.yaml', 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def create_test_image():
    """–°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
    img = Image.new('RGB', (300, 150), color='white')
    draw = ImageDraw.Draw(img)
    
    try:
        font = ImageFont.truetype("arial.ttf", 14)
    except:
        font = ImageFont.load_default()
    
    draw.text((10, 10), "–§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢", fill='black', font=font)
    draw.text((10, 40), "–ú–æ–¥–µ–ª—å: –°–û–í–ú–ï–°–¢–ò–ú–ê–Ø", fill='black', font=font)
    draw.text((10, 70), "–î–∞—Ç–∞: 19.01.2026", fill='black', font=font)
    draw.text((10, 100), "–°—Ç–∞—Ç—É—Å: –û–ö", fill='black', font=font)
    
    return img

def test_model_quick(model_name):
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –º–æ–¥–µ–ª–∏"""
    print(f"\nüöÄ –¢–ï–°–¢: {model_name}")
    print("-" * 30)
    
    try:
        from models.model_loader import ModelLoader
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º
        start = time.time()
        model = ModelLoader.load_model(model_name)
        load_time = time.time() - start
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞: {load_time:.1f}s")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        image = create_test_image()
        start = time.time()
        result = model.process_image(image)
        process_time = time.time() - start
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞: {process_time:.1f}s")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        keywords = ["–§–ò–ù–ê–õ–¨–ù–´–ô", "–¢–ï–°–¢", "–°–û–í–ú–ï–°–¢–ò–ú–ê–Ø", "19.01.2026", "–û–ö"]
        found = sum(1 for kw in keywords if kw.upper() in result.upper())
        quality = (found / len(keywords)) * 100
        print(f"‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ: {quality:.0f}% ({found}/{len(keywords)})")
        print(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç: {result[:50]}...")
        
        # –í—ã–≥—Ä—É–∂–∞–µ–º
        model.unload()
        
        return {
            "success": True,
            "load_time": load_time,
            "process_time": process_time,
            "quality": quality
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return {"success": False, "error": str(e)}

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üî¨ –§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        vram_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"‚úÖ GPU: {gpu_name}")
        print(f"‚úÖ VRAM: {vram_gb:.2f}GB")
    else:
        print("‚ùå GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        return False
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = load_config()
    available_models = list(config['models'].keys())
    
    print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {len(available_models)}")
    for model in available_models:
        model_info = config['models'][model]
        print(f"   - {model}: {model_info['name']}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏
    results = {}
    for model_name in available_models:
        result = test_model_quick(model_name)
        results[model_name] = result
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
        time.sleep(1)
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    # –°–≤–æ–¥–∫–∞
    print("\n" + "=" * 50)
    print("üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–í–û–î–ö–ê")
    print("=" * 50)
    
    working_models = 0
    for model_name, result in results.items():
        if result.get("success"):
            working_models += 1
            load_time = result.get("load_time", 0)
            process_time = result.get("process_time", 0)
            quality = result.get("quality", 0)
            print(f"‚úÖ {model_name:15} | {load_time:5.1f}s | {process_time:5.1f}s | {quality:5.0f}%")
        else:
            error = result.get("error", "Unknown")
            print(f"‚ùå {model_name:15} | –û–®–ò–ë–ö–ê: {error}")
    
    success_rate = (working_models / len(available_models)) * 100
    print(f"\nüèÜ –†–ï–ó–£–õ–¨–¢–ê–¢: {working_models}/{len(available_models)} –º–æ–¥–µ–ª–µ–π —Ä–∞–±–æ—Ç–∞—é—Ç ({success_rate:.0f}%)")
    
    if working_models == len(available_models):
        print("üéâ –í–°–ï –ú–û–î–ï–õ–ò –°–û–í–ú–ï–°–¢–ò–ú–´ –ò –†–ê–ë–û–¢–ê–Æ–¢!")
        print("‚úÖ –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ")
        return True
    else:
        print("‚ö†Ô∏è –ï—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –Ω–µ–∫–æ—Ç–æ—Ä—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)