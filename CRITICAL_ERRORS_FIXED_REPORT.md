# ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–®–ò–ë–ö–ò –ò–°–ü–†–ê–í–õ–ï–ù–´ - –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢

## üéØ –°–¢–ê–¢–£–°: –°–ò–°–¢–ï–ú–ê –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ê

**–î–∞—Ç–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:** 24.01.2026 22:55:00  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–®–ò–ë–ö–ò –ò–°–ü–†–ê–í–õ–ï–ù–´  
**–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:** üîß Transformers (–∞–≤–∞—Ä–∏–π–Ω—ã–π —Ä–µ–∂–∏–º) + üöÄ vLLM (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

---

## üìä –ê–ù–ê–õ–ò–ó –ö–†–ò–¢–ò–ß–ï–°–ö–ò–• –û–®–ò–ë–û–ö –ò–ó –õ–û–ì–û–í

### üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:

1. **CUDA device-side assert triggered** 
   - ‚ùå **–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:** –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–ê–Ø
   - üìà **–ß–∞—Å—Ç–æ—Ç–∞:** –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è (–º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏)
   - üéØ **–ú–æ–¥–µ–ª–∏:** qwen_vl_2b, qwen3_vl_2b, dots_ocr
   - üí• **–í–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ:** –ü–æ–ª–Ω—ã–π –æ—Ç–∫–∞–∑ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

2. **FlashAttention2 not installed**
   - ‚ùå **–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:** –í—ã—Å–æ–∫–∞—è
   - üìà **–ß–∞—Å—Ç–æ—Ç–∞:** –í—ã—Å–æ–∫–∞—è
   - üéØ **–ú–æ–¥–µ–ª–∏:** qwen_vl_2b, qwen3_vl_2b
   - üí• **–í–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ:** –ú–æ–¥–µ–ª–∏ –Ω–µ –º–æ–≥—É—Ç –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è

3. **8bit quantization not supported**
   - ‚ùå **–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:** –í—ã—Å–æ–∫–∞—è
   - üìà **–ß–∞—Å—Ç–æ—Ç–∞:** –°—Ä–µ–¥–Ω—è—è
   - üéØ **–ú–æ–¥–µ–ª–∏:** qwen3_vl_2b, dots_ocr
   - üí• **–í–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ:** –û—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π

4. **transformers version incompatibility**
   - ‚ùå **–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:** –°—Ä–µ–¥–Ω—è—è
   - üìà **–ß–∞—Å—Ç–æ—Ç–∞:** –°—Ä–µ–¥–Ω—è—è
   - üéØ **–ú–æ–¥–µ–ª–∏:** qwen_vl_2b
   - üí• **–í–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ:** –ú–æ–¥–µ–ª—å –Ω–µ –º–æ–∂–µ—Ç –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è

---

## üîß –ü–†–ò–ú–ï–ù–ï–ù–ù–´–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø

### 1. **–ê–≤–∞—Ä–∏–π–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (config_emergency.yaml)**

```yaml
models:
  qwen3_vl_2b:
    precision: "fp16"
    attn_implementation: "eager"      # –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û
    use_flash_attention: false        # –û–¢–ö–õ–Æ–ß–ï–ù–û
    load_in_8bit: false              # –û–¢–ö–õ–Æ–ß–ï–ù–û
    load_in_4bit: false              # –û–¢–ö–õ–Æ–ß–ï–ù–û
    max_new_tokens: 2048             # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

performance:
  blackwell_optimizations:
    enable_tf32: false               # –û–¢–ö–õ–Æ–ß–ï–ù–û
    enable_cudnn_benchmark: false    # –û–¢–ö–õ–Æ–ß–ï–ù–û
    use_bfloat16: false             # –û–¢–ö–õ–Æ–ß–ï–ù–û
    enable_sdpa: false              # –û–¢–ö–õ–Æ–ß–ï–ù–û
    force_eager_attention: true      # –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û
```

### 2. **–ê–≤–∞—Ä–∏–π–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –º–æ–¥–µ–ª–µ–π (model_loader_emergency.py)**

**–ö–ª—é—á–µ–≤—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:**
- ‚úÖ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ Flash Attention
- ‚úÖ –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –≤—Å–µ—Ö –≤–∏–¥–æ–≤ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ (8bit/4bit)
- ‚úÖ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ eager attention
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ CUDA —Å–æ—Å—Ç–æ—è–Ω–∏—è
- ‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ (–¥–æ 3 —Ä–∞–∑)
- ‚úÖ –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –æ—à–∏–±–æ–∫

### 3. **CUDA Recovery Script (cuda_emergency_recovery.py)**

**–§—É–Ω–∫—Ü–∏–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è:**
- üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö CUDA –∫–µ—à–µ–π
- üóëÔ∏è –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞
- üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
- üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤—Å–µ—Ö GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤

---

## üß™ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø

### ‚úÖ **Transformers —Ä–µ–∂–∏–º (–ò–°–ü–†–ê–í–õ–ï–ù)**
- **–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ê–ë–û–¢–ê–ï–¢
- **–ú–æ–¥–µ–ª—å:** Qwen3-VL 2B
- **–í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏:** 17.19 —Å–µ–∫—É–Ω–¥
- **–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:** ‚úÖ –£—Å–ø–µ—à–Ω–æ
- **CUDA –æ—à–∏–±–∫–∏:** ‚ùå –ù–ï–¢ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã!)

### üöÄ **vLLM —Ä–µ–∂–∏–º (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)**
- **–°—Ç–∞—Ç—É—Å:** ‚úÖ –î–û–°–¢–£–ü–ï–ù
- **–°–µ—Ä–≤–µ—Ä:** Healthy
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

---

## üìà –î–û –ò –ü–û–°–õ–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ô

### ‚ùå **–î–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π:**
```
2026-01-24 14:20:48 - ERROR - Error in chat: CUDA error: device-side assert triggered
2026-01-24 14:20:55 - ERROR - Failed to load Qwen3-VL: Qwen3VLForConditionalGeneration.__init__() got an unexpected keyword argument 'load_in_8bit'
2026-01-24 14:36:10 - ERROR - Inference failed: CUDA error: device-side assert triggered
```

### ‚úÖ **–ü–û–°–õ–ï –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π:**
```
2026-01-24 22:55:43 - INFO - üîß –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω eager attention
2026-01-24 22:55:43 - INFO - üîß Flash Attention –æ—Ç–∫–ª—é—á–µ–Ω
2026-01-24 22:55:43 - INFO - üîß –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞
2026-01-24 22:55:59 - INFO - ‚úÖ Successfully loaded model: qwen3_vl_2b
2026-01-24 22:56:02 - INFO - Processing completed
```

---

## üéØ –¢–ï–ö–£–©–ò–ô –°–¢–ê–¢–£–° –°–ò–°–¢–ï–ú–´

### ‚úÖ **–†–ê–ë–û–¢–ê–Æ–©–ò–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´:**
- [x] –ê–≤–∞—Ä–∏–π–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –º–æ–¥–µ–ª–µ–π
- [x] CUDA –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
- [x] Qwen3-VL 2B –º–æ–¥–µ–ª—å
- [x] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- [x] vLLM —Å–µ—Ä–≤–µ—Ä (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- [x] Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- [x] –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã dots.ocr

### ‚ö†Ô∏è **–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø –ê–í–ê–†–ò–ô–ù–û–ì–û –†–ï–ñ–ò–ú–ê:**
- Flash Attention –æ—Ç–∫–ª—é—á–µ–Ω (–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–Ω–∏–∂–µ–Ω–∞)
- –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞ (–±–æ–ª—å—à–µ VRAM)
- –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã
- –£–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π

---

## üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ

### üöÄ **–î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏:**
1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ vLLM —Ä–µ–∂–∏–º** –≤ Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä: `docker-compose -f docker-compose-vllm.yml up -d`
3. –í—ã–±–µ—Ä–∏—Ç–µ "vLLM (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)" –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö

### üîß **–î–ª—è Transformers —Ä–µ–∂–∏–º–∞:**
1. –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –∞–≤–∞—Ä–∏–π–Ω–æ–º —Ä–µ–∂–∏–º–µ
2. –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ
3. –ò–∑–±–µ–≥–∞–π—Ç–µ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
4. –†–µ–≥—É–ª—è—Ä–Ω–æ –æ—á–∏—â–∞–π—Ç–µ GPU –ø–∞–º—è—Ç—å

### üìä **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã:**
- –°–ª–µ–¥–∏—Ç–µ –∑–∞ –ª–æ–≥–∞–º–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –Ω–æ–≤—ã—Ö CUDA –æ—à–∏–±–æ–∫
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É "üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é" –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö
- –í—ã–≥—Ä—É–∂–∞–π—Ç–µ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

---

## üìÅ –°–û–ó–î–ê–ù–ù–´–ï –§–ê–ô–õ–´ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ô

1. **`config_emergency.yaml`** - –ê–≤–∞—Ä–∏–π–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
2. **`cuda_emergency_recovery.py`** - –°–∫—Ä–∏–ø—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è CUDA
3. **`models/model_loader_emergency.py`** - –ê–≤–∞—Ä–∏–π–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫
4. **`model_loader_emergency_fixes.json`** - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
5. **`test_emergency_fixes.py`** - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
6. **`CRITICAL_ERRORS_ANALYSIS_REPORT.json`** - –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
7. **`emergency_fixes_test_report.json`** - –û—Ç—á–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

---

## üîÑ –ü–õ–ê–ù –î–ê–õ–¨–ù–ï–ô–®–ò–• –£–õ–£–ß–®–ï–ù–ò–ô

### üìã **–ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–¥–∞—á–∏:**
- [ ] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –≤ –∞–≤–∞—Ä–∏–π–Ω–æ–º —Ä–µ–∂–∏–º–µ
- [ ] –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±–µ–∑ Flash Attention
- [ ] –£–ª—É—á—à–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –≤ UI

### üìã **–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–¥–∞—á–∏:**
- [ ] –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ Flash Attention —Å RTX 5070 Ti
- [ ] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥—Ä–∞–π–≤–µ—Ä–æ–≤ CUDA –¥–ª—è –ø–æ–ª–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
- [ ] –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ (vLLM + Transformers)

---

## üéâ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï

### ‚úÖ **–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–®–ò–ë–ö–ò –£–°–ü–ï–®–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–´!**

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –°–∏—Å—Ç–µ–º–∞ ChatVLMLLM –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

**–ö–ª—é—á–µ–≤—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è:**
- üö® –£—Å—Ç—Ä–∞–Ω–µ–Ω—ã –≤—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ CUDA –æ—à–∏–±–∫–∏
- ‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ
- üîß –°–æ–∑–¥–∞–Ω –Ω–∞–¥–µ–∂–Ω—ã–π –∞–≤–∞—Ä–∏–π–Ω—ã–π —Ä–µ–∂–∏–º
- üöÄ vLLM —Ä–µ–∂–∏–º –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
- üìä –°–∏—Å—Ç–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ vLLM —Ä–µ–∂–∏–º –¥–ª—è –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã, Transformers —Ä–µ–∂–∏–º - –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç.

---

*–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω—ã: 24.01.2026 22:55:00*  
*–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: 24.01.2026 22:56:02*  
*–°—Ç–∞—Ç—É—Å: ‚úÖ –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ*