#!/usr/bin/env python3
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–¥–Ω–æ–π –º–æ–¥–µ–ª—å—é –∑–∞ —Ä–∞–∑
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞–º—è—Ç—å—é
"""

import subprocess
import time
import requests
import json
from typing import Dict, Optional, Tuple

class SingleModelManager:
    def __init__(self):
        self.models = {
            "dots-ocr": {
                "name": "dots.ocr",
                "model_path": "rednote-hilab/dots.ocr",
                "port": 8000,
                "container_name": "dots-ocr-single",
                "memory_gb": 6.0,
                "max_tokens": 1024,
                "gpu_util": 0.7
            },
            "qwen3-vl": {
                "name": "Qwen3-VL 2B",
                "model_path": "Qwen/Qwen3-VL-2B-Instruct", 
                "port": 8004,
                "container_name": "qwen3-vl-single",
                "memory_gb": 8.0,
                "max_tokens": 2048,
                "gpu_util": 0.8
            }
        }
        
        self.current_model = None
    
    def run_command(self, command, timeout=60):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã"""
        try:
            if isinstance(command, list):
                result = subprocess.run(command, capture_output=True, text=True, timeout=timeout)
            else:
                result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=timeout)
            return result.returncode == 0, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return False, "", "Command timed out"
        except Exception as e:
            return False, "", str(e)
    
    def check_model_health(self, port):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –º–æ–¥–µ–ª–∏"""
        try:
            response = requests.get(f"http://localhost:{port}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def stop_all_containers(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
        print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤...")
        
        # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
        containers = [
            "dots-ocr-single", "qwen3-vl-single",
            "dots-ocr-ultra-optimized", "qwen3-vl-ultra-optimized",
            "dots-ocr-vllm-optimized", "qwen-qwen3-vl-2b-instruct-vllm",
            "dots-ocr-memory-optimized", "qwen3-vl-2b-memory-optimized"
        ]
        
        for container in containers:
            success, _, _ = self.run_command(["docker", "stop", container], timeout=30)
            if success:
                print(f"‚úÖ –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {container}")
                # –£–¥–∞–ª—è–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
                self.run_command(["docker", "rm", container], timeout=10)
        
        self.current_model = None
        time.sleep(3)  # –ü–∞—É–∑–∞ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤
    
    def start_model(self, model_key: str) -> Tuple[bool, str]:
        """–ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if model_key not in self.models:
            return False, f"Unknown model: {model_key}"
        
        model = self.models[model_key]
        
        print(f"üöÄ –ó–∞–ø—É—Å–∫ {model['name']}...")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –∫–µ—à—É HuggingFace
        try:
            userprofile = subprocess.check_output(['echo', '%USERPROFILE%'], shell=True, text=True).strip()
            cache_path = f"{userprofile}/.cache/huggingface/hub"
        except:
            cache_path = "~/.cache/huggingface/hub"
        
        # –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
        command = [
            "docker", "run", "-d",
            "--name", model["container_name"],
            "--restart", "unless-stopped",
            "-p", f"{model['port']}:8000",
            "--gpus", "all",
            "--shm-size", "4g",
            "-v", f"{cache_path}:/root/.cache/huggingface/hub:rw",
            "-e", "CUDA_VISIBLE_DEVICES=0",
            "-e", "NVIDIA_VISIBLE_DEVICES=all",
            "vllm/vllm-openai:latest",
            "--model", model["model_path"],
            "--host", "0.0.0.0",
            "--port", "8000",
            "--trust-remote-code",
            "--max-model-len", str(model["max_tokens"]),
            "--gpu-memory-utilization", str(model["gpu_util"]),
            "--dtype", "bfloat16",
            "--enforce-eager",
            "--disable-log-requests"
        ]
        
        success, stdout, stderr = self.run_command(command, timeout=120)
        
        if not success:
            return False, f"Failed to start {model['name']}: {stderr}"
        
        print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ {model['name']}...")
        
        # –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
        max_wait = 300  # 5 –º–∏–Ω—É—Ç
        start_time = time.time()
        
        while time.time() - start_time < max_wait:
            if self.check_model_health(model["port"]):
                print(f"‚úÖ {model['name']} –≥–æ—Ç–æ–≤!")
                self.current_model = model_key
                return True, f"{model['name']} started successfully"
            
            elapsed = int(time.time() - start_time)
            if elapsed % 30 == 0:  # –ö–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
                print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {model['name']}... ({elapsed}s)")
            
            time.sleep(5)
        
        return False, f"{model['name']} failed to start within {max_wait} seconds"
    
    def switch_to_model(self, model_key: str) -> Tuple[bool, str]:
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å"""
        if model_key not in self.models:
            return False, f"Unknown model: {model_key}"
        
        model = self.models[model_key]
        
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ –∞–∫—Ç–∏–≤–Ω–∞
        if self.current_model == model_key and self.check_model_health(model["port"]):
            return True, f"{model['name']} is already active"
        
        print(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ {model['name']}...")
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
        self.stop_all_containers()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ü–µ–ª–µ–≤—É—é –º–æ–¥–µ–ª—å
        success, message = self.start_model(model_key)
        
        if success:
            return True, f"Switched to {model['name']}"
        else:
            return False, f"Failed to switch to {model['name']}: {message}"
    
    def get_status(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã"""
        status = {
            "current_model": self.current_model,
            "models": {}
        }
        
        for key, model in self.models.items():
            is_healthy = self.check_model_health(model["port"])
            status["models"][key] = {
                "name": model["name"],
                "port": model["port"],
                "healthy": is_healthy,
                "active": is_healthy and self.current_model == key,
                "memory_gb": model["memory_gb"]
            }
        
        return status
    
    def test_model(self, model_key: str) -> Tuple[bool, Dict]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if model_key not in self.models:
            return False, {"error": "Unknown model"}
        
        model = self.models[model_key]
        
        if not self.check_model_health(model["port"]):
            return False, {"error": "Model not healthy"}
        
        try:
            # –¢–µ—Å—Ç API –º–æ–¥–µ–ª–µ–π
            response = requests.get(f"http://localhost:{model['port']}/v1/models", timeout=10)
            
            if response.status_code == 200:
                models_data = response.json()
                return True, {
                    "healthy": True,
                    "models_api": True,
                    "available_models": [m["id"] for m in models_data.get("data", [])],
                    "port": model["port"]
                }
            else:
                return False, {"error": f"Models API returned {response.status_code}"}
                
        except Exception as e:
            return False, {"error": str(e)}

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    manager = SingleModelManager()
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Single Model Manager")
    print("=" * 50)
    
    # 1. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
    manager.stop_all_containers()
    
    # 2. –¢–µ—Å—Ç –∑–∞–ø—É—Å–∫–∞ dots.ocr
    print("\n1Ô∏è‚É£ –¢–µ—Å—Ç –∑–∞–ø—É—Å–∫–∞ dots.ocr...")
    success, message = manager.switch_to_model("dots-ocr")
    
    if success:
        print(f"‚úÖ {message}")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API
        test_success, test_result = manager.test_model("dots-ocr")
        if test_success:
            print("‚úÖ API dots.ocr —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        else:
            print(f"‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å API: {test_result}")
    else:
        print(f"‚ùå {message}")
    
    # 3. –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
    print(f"\n2Ô∏è‚É£ –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:")
    status = manager.get_status()
    
    print(f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {status.get('current_model', 'None')}")
    for key, model_info in status["models"].items():
        status_icon = "üü¢" if model_info["active"] else "üî¥"
        print(f"  {status_icon} {model_info['name']}: –ø–æ—Ä—Ç {model_info['port']}, {model_info['memory_gb']} –ì–ë")
    
    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = {
        "single_model_mode": True,
        "current_model": manager.current_model,
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "models": manager.models
    }
    
    with open("single_model_config.json", "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: single_model_config.json")
    
    # 5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    if manager.current_model:
        active_model = manager.models[manager.current_model]
        print(f"‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –≤ —Ä–µ–∂–∏–º–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏")
        print(f"ü§ñ –ê–∫—Ç–∏–≤–Ω–∞: {active_model['name']} (–ø–æ—Ä—Ç {active_model['port']})")
        print(f"üí° –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: streamlit run app.py")
        print(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: python single_model_manager.py switch qwen3-vl")
    else:
        print(f"‚ùå –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏")
        print(f"üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ –º–æ–¥–µ–ª—å: python single_model_manager.py switch dots-ocr")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        action = sys.argv[1]
        manager = SingleModelManager()
        
        if action == "switch" and len(sys.argv) > 2:
            model_key = sys.argv[2]
            success, message = manager.switch_to_model(model_key)
            print(f"{'‚úÖ' if success else '‚ùå'} {message}")
        
        elif action == "status":
            status = manager.get_status()
            print(json.dumps(status, indent=2, ensure_ascii=False))
        
        elif action == "stop":
            manager.stop_all_containers()
            print("‚úÖ All containers stopped")
        
        else:
            print("Usage: python single_model_manager.py [switch <model>|status|stop]")
            print("Models: dots-ocr, qwen3-vl")
    else:
        main()