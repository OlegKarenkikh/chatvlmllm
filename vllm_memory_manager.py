#!/usr/bin/env python3
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏ –¥–ª—è vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
–£–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—É—Å–∫–æ–º/–æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –ø–∞–º—è—Ç–∏
"""

import docker
import requests
import time
import json
import subprocess
from typing import Dict, List, Optional, Tuple
import streamlit as st

class VLLMMemoryManager:
    def __init__(self):
        self.client = docker.from_env()
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –∏ –∏—Ö –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
        self.containers_config = {
            "dots-ocr": {
                "container_name": "dots-ocr-vllm-optimized",
                "compose_service": "dots-ocr",
                "port": 8000,
                "model": "rednote-hilab/dots.ocr",
                "estimated_memory_gb": 4.5,  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
                "priority": 1  # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            },
            "qwen3-vl-2b": {
                "container_name": "qwen-qwen3-vl-2b-instruct-vllm",
                "compose_service": "qwen3-vl-2b",
                "port": 8004,
                "model": "Qwen/Qwen3-VL-2B-Instruct",
                "estimated_memory_gb": 6.5,  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
                "priority": 2  # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            },
            "qwen2-vl-2b": {
                "container_name": "qwen-qwen2-vl-2b-instruct-vllm",
                "compose_service": "qwen2-vl-2b",
                "port": 8001,
                "model": "Qwen/Qwen2-VL-2B-Instruct",
                "estimated_memory_gb": 6.0,
                "priority": 3
            }
        }
        
        self.max_gpu_memory_gb = 12  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–æ—Å—Ç—É–ø–Ω–∞—è GPU –ø–∞–º—è—Ç—å
        self.compose_file = "docker-compose-vllm.yml"
    
    def get_container_status(self, container_name: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
        try:
            container = self.client.containers.get(container_name)
            return {
                "exists": True,
                "running": container.status == "running",
                "status": container.status,
                "health": getattr(container.attrs.get("State", {}), "Health", {}).get("Status", "unknown")
            }
        except docker.errors.NotFound:
            return {
                "exists": False,
                "running": False,
                "status": "not_found",
                "health": "unknown"
            }
        except Exception as e:
            return {
                "exists": False,
                "running": False,
                "status": "error",
                "health": "unknown",
                "error": str(e)
            }
    
    def check_container_health(self, port: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —á–µ—Ä–µ–∑ API"""
        try:
            response = requests.get(f"http://localhost:{port}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_running_containers(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
        running = []
        for name, config in self.containers_config.items():
            status = self.get_container_status(config["container_name"])
            if status["running"] and self.check_container_health(config["port"]):
                running.append(name)
        return running
    
    def calculate_memory_usage(self, containers: List[str]) -> float:
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        total_memory = 0
        for container in containers:
            if container in self.containers_config:
                total_memory += self.containers_config[container]["estimated_memory_gb"]
        return total_memory
    
    def can_run_together(self, containers: List[str]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –º–æ–≥—É—Ç –ª–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Ä–∞–±–æ—Ç–∞—Ç—å –≤–º–µ—Å—Ç–µ"""
        total_memory = self.calculate_memory_usage(containers)
        return total_memory <= self.max_gpu_memory_gb
    
    def start_container(self, container_name: str) -> bool:
        """–ó–∞–ø—É—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
        if container_name not in self.containers_config:
            return False
        
        config = self.containers_config[container_name]
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º docker-compose –¥–ª—è –∑–∞–ø—É—Å–∫–∞
            result = subprocess.run([
                "docker-compose", "-f", self.compose_file,
                "up", "-d", config["compose_service"]
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                # –ñ–¥–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
                max_wait = 120  # 2 –º–∏–Ω—É—Ç—ã
                start_time = time.time()
                
                while time.time() - start_time < max_wait:
                    if self.check_container_health(config["port"]):
                        return True
                    time.sleep(5)
                
                return False
            else:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ {container_name}: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ {container_name}: {e}")
            return False
    
    def stop_container(self, container_name: str) -> bool:
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
        if container_name not in self.containers_config:
            return False
        
        config = self.containers_config[container_name]
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º docker-compose –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            result = subprocess.run([
                "docker-compose", "-f", self.compose_file,
                "stop", config["compose_service"]
            ], capture_output=True, text=True, timeout=30)
            
            return result.returncode == 0
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ {container_name}: {e}")
            return False
    
    def switch_to_model(self, target_model: str) -> Tuple[bool, str]:
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞–º—è—Ç—å—é"""
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏
        target_container = None
        for name, config in self.containers_config.items():
            if config["model"] == target_model:
                target_container = name
                break
        
        if not target_container:
            return False, f"–ú–æ–¥–µ–ª—å {target_model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
        
        running_containers = self.get_running_containers()
        target_config = self.containers_config[target_container]
        
        # –ï—Å–ª–∏ —Ü–µ–ª–µ–≤–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —É–∂–µ –∑–∞–ø—É—â–µ–Ω –∏ –∑–¥–æ—Ä–æ–≤
        if target_container in running_containers:
            return True, f"–ú–æ–¥–µ–ª—å {target_model} —É–∂–µ –∞–∫—Ç–∏–≤–Ω–∞"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ–º –ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ü–µ–ª–µ–≤–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å —Ç–µ–∫—É—â–∏–º–∏
        potential_containers = running_containers + [target_container]
        
        if self.can_run_together(potential_containers):
            # –ú–æ–∂–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å –±–µ–∑ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –¥—Ä—É–≥–∏—Ö
            success = self.start_container(target_container)
            if success:
                return True, f"–ú–æ–¥–µ–ª—å {target_model} –∑–∞–ø—É—â–µ–Ω–∞ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –¥—Ä—É–≥–∏–º–∏)"
            else:
                return False, f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –º–æ–¥–µ–ª–∏ {target_model}"
        else:
            # –ù—É–∂–Ω–æ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –ø–∞–º—è—Ç—å - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å –Ω–∏–∑–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
            containers_to_stop = []
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç = –º–µ–Ω—å—à–µ–µ —á–∏—Å–ª–æ)
            running_sorted = sorted(running_containers, 
                                  key=lambda x: self.containers_config[x]["priority"], 
                                  reverse=True)
            
            memory_needed = target_config["estimated_memory_gb"]
            current_memory = self.calculate_memory_usage(running_containers)
            
            for container in running_sorted:
                if current_memory + memory_needed <= self.max_gpu_memory_gb:
                    break
                
                containers_to_stop.append(container)
                current_memory -= self.containers_config[container]["estimated_memory_gb"]
            
            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
            stopped_containers = []
            for container in containers_to_stop:
                if self.stop_container(container):
                    stopped_containers.append(container)
                    time.sleep(2)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –æ—Å—Ç–∞–Ω–æ–≤–∫–∞–º–∏
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ü–µ–ª–µ–≤–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            success = self.start_container(target_container)
            
            if success:
                message = f"–ú–æ–¥–µ–ª—å {target_model} –∑–∞–ø—É—â–µ–Ω–∞"
                if stopped_containers:
                    stopped_models = [self.containers_config[c]["model"].split("/")[-1] for c in stopped_containers]
                    message += f" (–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã: {', '.join(stopped_models)})"
                return True, message
            else:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å, –ø—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ
                for container in stopped_containers:
                    self.start_container(container)
                return False, f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –º–æ–¥–µ–ª–∏ {target_model}"
    
    def get_memory_status(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        running_containers = self.get_running_containers()
        current_memory = self.calculate_memory_usage(running_containers)
        
        container_details = []
        for container in running_containers:
            config = self.containers_config[container]
            container_details.append({
                "name": container,
                "model": config["model"].split("/")[-1],
                "memory_gb": config["estimated_memory_gb"],
                "port": config["port"],
                "priority": config["priority"]
            })
        
        return {
            "running_containers": len(running_containers),
            "current_memory_gb": current_memory,
            "max_memory_gb": self.max_gpu_memory_gb,
            "available_memory_gb": self.max_gpu_memory_gb - current_memory,
            "memory_usage_percent": (current_memory / self.max_gpu_memory_gb) * 100,
            "containers": container_details,
            "can_add_more": current_memory < self.max_gpu_memory_gb
        }
    
    def optimize_memory_usage(self) -> Tuple[bool, str]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        running_containers = self.get_running_containers()
        current_memory = self.calculate_memory_usage(running_containers)
        
        if current_memory <= self.max_gpu_memory_gb:
            return True, f"–ü–∞–º—è—Ç—å –≤ –Ω–æ—Ä–º–µ: {current_memory:.1f}/{self.max_gpu_memory_gb} –ì–ë"
        
        # –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞ - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å –Ω–∏–∑–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
        containers_sorted = sorted(running_containers, 
                                 key=lambda x: self.containers_config[x]["priority"], 
                                 reverse=True)
        
        stopped_containers = []
        for container in containers_sorted:
            if current_memory <= self.max_gpu_memory_gb:
                break
            
            if self.stop_container(container):
                stopped_containers.append(container)
                current_memory -= self.containers_config[container]["estimated_memory_gb"]
                time.sleep(2)
        
        if stopped_containers:
            stopped_models = [self.containers_config[c]["model"].split("/")[-1] for c in stopped_containers]
            return True, f"–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã {', '.join(stopped_models)}"
        else:
            return False, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞–º—è—Ç—å"

def create_memory_management_ui():
    """–°–æ–∑–¥–∞–Ω–∏–µ UI –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
    
    st.subheader("üß† –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é vLLM")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞
    if "memory_manager" not in st.session_state:
        st.session_state.memory_manager = VLLMMemoryManager()
    
    manager = st.session_state.memory_manager
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø–∞–º—è—Ç–∏
    memory_status = manager.get_memory_status()
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø–∞–º—è—Ç–∏
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "–ê–∫—Ç–∏–≤–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤", 
            memory_status["running_containers"],
            help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"
        )
    
    with col2:
        st.metric(
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU", 
            f"{memory_status['current_memory_gb']:.1f} –ì–ë",
            f"{memory_status['memory_usage_percent']:.1f}%"
        )
    
    with col3:
        st.metric(
            "–î–æ—Å—Ç—É–ø–Ω–æ –ø–∞–º—è—Ç–∏", 
            f"{memory_status['available_memory_gb']:.1f} –ì–ë",
            help="–°–≤–æ–±–æ–¥–Ω–∞—è GPU –ø–∞–º—è—Ç—å"
        )
    
    with col4:
        memory_color = "normal"
        if memory_status['memory_usage_percent'] > 90:
            memory_color = "inverse"
        elif memory_status['memory_usage_percent'] > 75:
            memory_color = "off"
        
        st.metric(
            "–õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏", 
            f"{memory_status['max_memory_gb']} –ì–ë",
            help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–æ—Å—Ç—É–ø–Ω–∞—è GPU –ø–∞–º—è—Ç—å"
        )
    
    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
    progress_value = min(memory_status['memory_usage_percent'] / 100, 1.0)
    st.progress(progress_value, text=f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏: {memory_status['memory_usage_percent']:.1f}%")
    
    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
    if memory_status['memory_usage_percent'] > 100:
        st.error("‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç GPU –ø–∞–º—è—Ç–∏! –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ.")
    elif memory_status['memory_usage_percent'] > 90:
        st.warning("‚ö†Ô∏è –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è.")
    
    # –î–µ—Ç–∞–ª–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
    if memory_status["containers"]:
        st.subheader("üìä –ê–∫—Ç–∏–≤–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã")
        
        for container in memory_status["containers"]:
            with st.expander(f"ü§ñ {container['model']} (–ü–æ—Ä—Ç: {container['port']})"):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.write(f"**–ü–∞–º—è—Ç—å:** {container['memory_gb']} –ì–ë")
                
                with col2:
                    st.write(f"**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** {container['priority']}")
                
                with col3:
                    if st.button(f"–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å {container['model']}", key=f"stop_{container['name']}"):
                        success = manager.stop_container(container['name'])
                        if success:
                            st.success(f"–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä {container['model']} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                            st.rerun()
                        else:
                            st.error(f"–û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ {container['model']}")
    
    # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏
    st.subheader("üéõÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üîß –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞–º—è—Ç—å", type="primary"):
            success, message = manager.optimize_memory_usage()
            if success:
                st.success(message)
            else:
                st.error(message)
            st.rerun()
    
    with col2:
        if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å"):
            st.rerun()
    
    # –ë—ã—Å—Ç—Ä–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    st.subheader("üöÄ –ë—ã—Å—Ç—Ä–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
    
    available_models = [
        "rednote-hilab/dots.ocr",
        "Qwen/Qwen3-VL-2B-Instruct",
        "Qwen/Qwen2-VL-2B-Instruct"
    ]
    
    selected_model = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏",
        available_models,
        help="–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø–∞–º—è—Ç—å—é –ø—Ä–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–∏"
    )
    
    if st.button("üéØ –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –º–æ–¥–µ–ª—å", type="secondary"):
        with st.spinner(f"–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ {selected_model.split('/')[-1]}..."):
            success, message = manager.switch_to_model(selected_model)
            
            if success:
                st.success(message)
            else:
                st.error(message)
            
            time.sleep(2)
            st.rerun()
    
    # –≠–∫—Å–ø–æ—Ä—Ç —Å—Ç–∞—Ç—É—Å–∞
    with st.expander("üìã –≠–∫—Å–ø–æ—Ä—Ç —Å—Ç–∞—Ç—É—Å–∞"):
        status_json = json.dumps(memory_status, indent=2, ensure_ascii=False)
        st.code(status_json, language="json")
        
        st.download_button(
            "üíæ –°–∫–∞—á–∞—Ç—å —Å—Ç–∞—Ç—É—Å",
            data=status_json,
            file_name=f"vllm_memory_status_{int(time.time())}.json",
            mime="application/json"
        )

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ø–∞–º—è—Ç–∏
    manager = VLLMMemoryManager()
    
    print("üß† –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ø–∞–º—è—Ç–∏ vLLM")
    print("=" * 50)
    
    # –°—Ç–∞—Ç—É—Å –ø–∞–º—è—Ç–∏
    status = manager.get_memory_status()
    print(f"–ê–∫—Ç–∏–≤–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {status['running_containers']}")
    print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {status['current_memory_gb']:.1f}/{status['max_memory_gb']} –ì–ë ({status['memory_usage_percent']:.1f}%)")
    
    for container in status['containers']:
        print(f"  - {container['model']}: {container['memory_gb']} –ì–ë (–ø–æ—Ä—Ç {container['port']})")
    
    # –¢–µ—Å—Ç –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    print(f"\nüîÑ –¢–µ—Å—Ç –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ Qwen3-VL...")
    success, message = manager.switch_to_model("Qwen/Qwen3-VL-2B-Instruct")
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {message}")