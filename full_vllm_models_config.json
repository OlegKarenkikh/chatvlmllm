{
  "rednote-hilab/dots.ocr": {
    "model_name": "rednote-hilab/dots.ocr",
    "container_name": "dots-ocr-fixed",
    "port": 8000,
    "size_gb": 5.67,
    "category": "ocr",
    "vllm_params": {
      "max_model_len": 1024,
      "gpu_memory_utilization": 0.85,
      "trust_remote_code": true,
      "enforce_eager": true
    },
    "issues": [],
    "priority": 1,
    "status": "tested_working"
  },
  "deepseek-ai/deepseek-ocr": {
    "model_name": "deepseek-ai/deepseek-ocr",
    "container_name": "deepseek-ocr-vllm",
    "port": 8001,
    "size_gb": 0.01,
    "category": "ocr",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.6,
      "trust_remote_code": true,
      "enforce_eager": true
    },
    "issues": [
      "Very small size - may be incomplete"
    ],
    "priority": 2,
    "status": "needs_testing"
  },
  "stepfun-ai/GOT-OCR-2.0-hf": {
    "model_name": "stepfun-ai/GOT-OCR-2.0-hf",
    "container_name": "got-ocr-2-0-hf-vllm",
    "port": 8002,
    "size_gb": 1.06,
    "category": "ocr",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": true
    },
    "issues": [
      "May require additional dependencies"
    ],
    "priority": 2,
    "status": "needs_testing"
  },
  "stepfun-ai/GOT-OCR2_0": {
    "model_name": "stepfun-ai/GOT-OCR2_0",
    "container_name": "stepfun-got-ocr2-0-vllm",
    "port": 8003,
    "size_gb": 1.34,
    "category": "ocr",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": true
    },
    "issues": [
      "Requires verovio package"
    ],
    "priority": 2,
    "status": "known_incompatible"
  },
  "ucaslcl/GOT-OCR2_0": {
    "model_name": "ucaslcl/GOT-OCR2_0",
    "container_name": "ucaslcl-got-ocr2-0-vllm",
    "port": 8004,
    "size_gb": 2.67,
    "category": "ocr",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": true
    },
    "issues": [
      "Requires verovio package"
    ],
    "priority": 2,
    "status": "known_incompatible"
  },
  "Qwen/Qwen3-VL-2B-Instruct": {
    "model_name": "Qwen/Qwen3-VL-2B-Instruct",
    "container_name": "qwen3-vl-2b-instruct-vllm",
    "port": 8010,
    "size_gb": 3.97,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": false
    },
    "issues": [],
    "priority": 3,
    "status": "tested_working"
  },
  "Qwen/Qwen2-VL-2B-Instruct": {
    "model_name": "Qwen/Qwen2-VL-2B-Instruct",
    "container_name": "qwen2-vl-2b-instruct-vllm",
    "port": 8011,
    "size_gb": 4.13,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 4096,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": false
    },
    "issues": [],
    "priority": 3,
    "status": "needs_testing"
  },
  "Qwen/Qwen2.5-VL-7B-Instruct": {
    "model_name": "Qwen/Qwen2.5-VL-7B-Instruct",
    "container_name": "qwen2-5-vl-7b-instruct-vllm",
    "port": 8012,
    "size_gb": 0.66,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 4096,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": false
    },
    "issues": [
      "Small size - may be incomplete"
    ],
    "priority": 3,
    "status": "needs_testing"
  },
  "Qwen/Qwen2-VL-7B-Instruct": {
    "model_name": "Qwen/Qwen2-VL-7B-Instruct",
    "container_name": "qwen2-vl-7b-instruct-vllm",
    "port": 8013,
    "size_gb": 7.61,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 4096,
      "gpu_memory_utilization": 0.6,
      "trust_remote_code": true,
      "enforce_eager": false
    },
    "issues": [
      "Large model - high memory usage"
    ],
    "priority": 4,
    "status": "needs_testing"
  },
  "microsoft/Phi-3.5-vision-instruct": {
    "model_name": "microsoft/Phi-3.5-vision-instruct",
    "container_name": "phi-3-5-vision-instruct-vllm",
    "port": 8014,
    "size_gb": 7.73,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 4096,
      "gpu_memory_utilization": 0.6,
      "trust_remote_code": true,
      "enforce_eager": false
    },
    "issues": [
      "Large model - high memory usage"
    ],
    "priority": 4,
    "status": "needs_testing"
  },
  "datalab-to/chandra": {
    "model_name": "datalab-to/chandra",
    "container_name": "datalab-chandra-vllm",
    "port": 8015,
    "size_gb": 0.42,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.6,
      "trust_remote_code": true,
      "enforce_eager": false
    },
    "issues": [],
    "priority": 3,
    "status": "needs_testing"
  },
  "deepseek-ai/deepseek-vl-1.3b-chat": {
    "model_name": "deepseek-ai/deepseek-vl-1.3b-chat",
    "container_name": "deepseek-vl-1-3b-chat-vllm",
    "port": 8020,
    "size_gb": 0.0,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.5,
      "trust_remote_code": true,
      "enforce_eager": true
    },
    "issues": [
      "Zero size - likely incomplete download"
    ],
    "priority": 5,
    "status": "likely_broken"
  },
  "h2oai/h2ovl-mississippi-2b": {
    "model_name": "h2oai/h2ovl-mississippi-2b",
    "container_name": "h2ovl-mississippi-2b-vllm",
    "port": 8021,
    "size_gb": 4.01,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.6,
      "trust_remote_code": true,
      "enforce_eager": true
    },
    "issues": [
      "Custom architecture - may not be supported"
    ],
    "priority": 5,
    "status": "needs_testing"
  },
  "h2oai/h2ovl-mississippi-800m": {
    "model_name": "h2oai/h2ovl-mississippi-800m",
    "container_name": "h2ovl-mississippi-800m-vllm",
    "port": 8022,
    "size_gb": 1.54,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.5,
      "trust_remote_code": true,
      "enforce_eager": true
    },
    "issues": [
      "Custom architecture - may not be supported"
    ],
    "priority": 5,
    "status": "needs_testing"
  },
  "vikhyatk/moondream2": {
    "model_name": "vikhyatk/moondream2",
    "container_name": "moondream2-vllm",
    "port": 8023,
    "size_gb": 3.59,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.6,
      "trust_remote_code": true,
      "enforce_eager": true
    },
    "issues": [
      "Custom architecture - may not be supported"
    ],
    "priority": 5,
    "status": "needs_testing"
  }
}