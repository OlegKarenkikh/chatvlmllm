#!/usr/bin/env python3
"""
–¢–µ—Å—Ç dots.ocr —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
"""

import os
import sys
import time
import torch
from pathlib import Path
from PIL import Image

# Add project root to path
sys.path.append(str(Path(__file__).parent))

# Set environment variable
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from models.model_loader import ModelLoader
from utils.logger import logger


def test_with_official_prompts():
    """–¢–µ—Å—Ç —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏ dots.ocr."""
    
    print("üìã –¢–ï–°–¢ –° –û–§–ò–¶–ò–ê–õ–¨–ù–´–ú–ò –ü–†–û–ú–ü–¢–ê–ú–ò DOTS.OCR")
    print("=" * 50)
    
    try:
        # Load model
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        model_wrapper = ModelLoader.load_model('dots_ocr')
        
        # Get the actual model and processor
        model = model_wrapper.model
        processor = model_wrapper.processor
        
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # Try to get official prompts
        try:
            from dots_ocr.utils import dict_promptmode_to_prompt
            print("‚úÖ –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã")
            
            ocr_prompt = dict_promptmode_to_prompt["ocr"]
            layout_prompt = dict_promptmode_to_prompt["prompt_layout_all_en"]
            
            print(f"üìù OCR –ø—Ä–æ–º–ø—Ç: {ocr_prompt[:100]}...")
            print(f"üìã Layout –ø—Ä–æ–º–ø—Ç: {layout_prompt[:100]}...")
            
        except ImportError:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã")
            print("üí° –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –ø—Ä–æ–º–ø—Ç—ã")
            
            ocr_prompt = "Extract all text from this image."
            layout_prompt = """Please output the layout information from the PDF image, including each layout element's bbox, its category, and the corresponding text content within the bbox.

1. Bbox format: [x1, y1, x2, y2]
2. Layout Categories: The possible categories are ['Caption', 'Footnote', 'Formula', 'List-item', 'Page-footer', 'Page-header', 'Picture', 'Section-header', 'Table', 'Text', 'Title'].
3. Text Extraction & Formatting Rules:
   - Picture: For the 'Picture' category, the text field should be omitted.
   - Formula: Format its text as LaTeX.
   - Table: Format its text as HTML.
   - All Others (Text, Title, etc.): Format their text as Markdown.
4. Constraints:
   - The output text must be the original text from the image, with no translation.
   - All layout elements must be sorted according to human reading order.
5. Final Output: The entire output must be a single JSON object."""
        
        # Test with different images
        test_images = ["test_document.png", "complex_document.png", "realistic_document.png"]
        
        for image_path in test_images:
            if not Path(image_path).exists():
                print(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {image_path} - —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
                continue
                
            print(f"\nüñºÔ∏è –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å {image_path}")
            
            image = Image.open(image_path)
            print(f"üì∑ –†–∞–∑–º–µ—Ä: {image.size}, —Ä–µ–∂–∏–º: {image.mode}")
            
            # Convert to RGB if needed
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Test OCR prompt
            print("\nüî§ –¢–µ—Å—Ç OCR –ø—Ä–æ–º–ø—Ç–∞...")
            result = test_prompt(model, processor, image, ocr_prompt, "OCR")
            
            if result and result.strip():
                print("‚úÖ OCR —Ä–∞–±–æ—Ç–∞–µ—Ç!")
                break
            
            # Test Layout prompt
            print("\nüìã –¢–µ—Å—Ç Layout –ø—Ä–æ–º–ø—Ç–∞...")
            result = test_prompt(model, processor, image, layout_prompt, "Layout")
            
            if result and result.strip():
                print("‚úÖ Layout —Ä–∞–±–æ—Ç–∞–µ—Ç!")
                break
        
        # Unload model
        ModelLoader.unload_model('dots_ocr')
        print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        print(f"Traceback: {traceback.format_exc()}")


def test_prompt(model, processor, image, prompt, prompt_type):
    """–¢–µ—Å—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞."""
    
    try:
        # Manual inference
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image},
                    {"type": "text", "text": prompt}
                ]
            }
        ]
        
        # Preparation for inference
        text = processor.apply_chat_template(
            messages, 
            tokenize=False, 
            add_generation_prompt=True
        )
        
        # Process vision info
        from qwen_vl_utils import process_vision_info
        image_inputs, video_inputs = process_vision_info(messages)
        
        inputs = processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt"
        )
        
        inputs = inputs.to("cuda")
        
        # Generate with more tokens
        print(f"üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è {prompt_type}...")
        
        with torch.no_grad():
            generated_ids = model.generate(
                **inputs, 
                max_new_tokens=2000,  # –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤
                do_sample=False,
                pad_token_id=processor.tokenizer.eos_token_id,
                eos_token_id=processor.tokenizer.eos_token_id
            )
        
        # Decode output
        generated_ids_trimmed = [
            out_ids[len(in_ids):] 
            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        
        (output_text,) = processor.batch_decode(
            generated_ids_trimmed, 
            skip_special_tokens=True, 
            clean_up_tokenization_spaces=False
        )
        
        print(f"üì§ {prompt_type} —Ä–µ–∑—É–ª—å—Ç–∞—Ç:")
        print(f"–î–ª–∏–Ω–∞: {len(output_text)}")
        
        if output_text.strip():
            print(f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ: {output_text[:200]}...")
            
            # Try JSON parsing for layout
            if prompt_type == "Layout":
                try:
                    import json
                    parsed = json.loads(output_text)
                    print(f"‚úÖ –í–∞–ª–∏–¥–Ω—ã–π JSON: {type(parsed)}")
                except json.JSONDecodeError:
                    print("‚ö†Ô∏è –ù–µ JSON, –Ω–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç")
        else:
            print("‚ùå –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
        
        return output_text
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ {prompt_type}: {e}")
        return None


if __name__ == "__main__":
    test_with_official_prompts()