# –§–ò–ù–ê–õ–¨–ù–ê–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: DOTS.OCR –ò RTX 5070 TI BLACKWELL

## üéØ –ò–¢–û–ì–û–í–´–ô –í–ï–†–î–ò–ö–¢

**–í–∞—à–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∞–±—Å–æ–ª—é—Ç–Ω–æ –≤–µ—Ä–Ω–∞!** dots.ocr –∂–µ—Å—Ç–∫–æ –∑–∞–≤—è–∑–∞–Ω–∞ –Ω–∞ Flash Attention 2, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–µ **–Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–π —Å RTX 5070 Ti Blackwell** –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç.

## üìã –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–ù–´–ï –§–ê–ö–¢–´

### 1. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å:
```python
# dots.ocr requirements.txt:
flash-attn==2.8.0.post2  # –ñ–ï–°–¢–ö–û –ó–ê–ö–û–î–ò–†–û–í–ê–ù–û

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:
Flash Attention 2 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: sm_80, sm_90, sm_100, sm_110
RTX 5070 Ti Blackwell: sm_120  # –ù–ï –ü–û–î–î–ï–†–ñ–ò–í–ê–ï–¢–°–Ø
```

### 2. –†–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ Flash Attention:
- ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —É—Å–ø–µ—à–Ω–æ
- ‚úÖ GPU –ø–∞–º—è—Ç—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ  
- ‚ùå **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç** (–ø—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
- ‚ùå OCR —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞

### 3. –ü—Ä–∏—á–∏–Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã:
dots.ocr **–æ–±—É—á–∞–ª–∞—Å—å –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–ª–∞—Å—å** –ø–æ–¥ Flash Attention 2. –ë–µ–∑ –Ω–µ–µ –º–æ–¥–µ–ª—å —Ç–µ—Ä—è–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç.

## üõ†Ô∏è –†–ï–®–ï–ù–ò–Ø –ü–û –ü–†–ò–û–†–ò–¢–ï–¢–£

### ü•á –í–ê–†–ò–ê–ù–¢ 1: –ò–°–ü–û–õ–¨–ó–£–ô–¢–ï QWEN_VL_2B (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)

**–ü–æ—á–µ–º—É —ç—Ç–æ –ª—É—á—à–∏–π –≤—ã–±–æ—Ä:**
- ‚úÖ **–û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ OCR** (–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤ –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º–µ)
- ‚úÖ **–ë—ã—Å—Ç—Ä–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å**: 3.91s vs 130s+ —É dots.ocr
- ‚úÖ **–ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** —Å RTX 5070 Ti Blackwell
- ‚úÖ **–ù–µ —Ç—Ä–µ–±—É–µ—Ç Flash Attention** - —Ä–∞–±–æ—Ç–∞–µ—Ç —Å eager attention
- ‚úÖ **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: 85.7% —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤ –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º–µ

```python
# –ì–æ—Ç–æ–≤–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –≤–∞—à chatvlmllm:
model = "Qwen/Qwen2-VL-2B-Instruct"
attn_implementation = "eager"  # –û—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Blackwell
```

### ü•à –í–ê–†–ò–ê–ù–¢ 2: –û–ñ–ò–î–ê–ù–ò–ï FLASH ATTENTION 4 (2025 Q4 - 2026 Q1)

**–ß—Ç–æ –æ–∂–∏–¥–∞—Ç—å:**
- Flash Attention 4 –±—É–¥–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å Blackwell sm_120
- dots.ocr —Å—Ç–∞–Ω–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–∞
- –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–ª–∏–∑: –∫–æ–Ω–µ—Ü 2025 - –Ω–∞—á–∞–ª–æ 2026

**–î–µ–π—Å—Ç–≤–∏—è:**
1. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ —Ä–µ–ª–∏–∑—ã Flash Attention
2. –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–æ–≤—ã–µ –≤–µ—Ä—Å–∏–∏
3. –û–±–Ω–æ–≤–ª—è–π—Ç–µ dots.ocr –ø—Ä–∏ –ø–æ—è–≤–ª–µ–Ω–∏–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏

### ü•â –í–ê–†–ò–ê–ù–¢ 3: –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–ï –†–ï–®–ï–ù–ò–Ø

#### A. vLLM —Å enforce-eager:
```bash
vllm serve rednote-hilab/dots.ocr \
    --trust-remote-code \
    --enforce-eager \
    --gpu-memory-utilization 0.9
```

#### B. –ö–∞—Å—Ç–æ–º–Ω–∞—è —Å–±–æ—Ä–∫–∞ Flash Attention:
```bash
export FLASH_ATTN_CUDA_ARCHS="120"
# –ú–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ kernels
```

## üèóÔ∏è –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –†–ï–®–ï–ù–ò–Ø –î–õ–Ø CHATVLMLLM

### –£–º–Ω–∞—è OCR —Å–∏—Å—Ç–µ–º–∞ —Å fallback:

```python
class SmartOCRManager:
    def __init__(self):
        # –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å (–≤—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç)
        self.primary_ocr = QwenVL2B()
        
        # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
        self.experimental_ocr = None
        if self.flash_attention_compatible():
            try:
                self.experimental_ocr = DotsOCR()
            except:
                pass
    
    def process_ocr(self, image, prompt):
        # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å dots.ocr (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
        if self.experimental_ocr:
            try:
                result = self.experimental_ocr.process(image, prompt)
                if result and len(result.strip()) > 0:
                    return {
                        "content": result,
                        "model": "dots.ocr",
                        "status": "success"
                    }
            except Exception as e:
                logger.warning(f"dots.ocr failed: {e}")
        
        # Fallback –Ω–∞ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        result = self.primary_ocr.process(image, prompt)
        return {
            "content": result,
            "model": "qwen_vl_2b", 
            "status": "success"
        }
    
    def flash_attention_compatible(self):
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ GPU —Å Flash Attention
        gpu_arch = torch.cuda.get_device_capability()
        return gpu_arch[0] < 12  # sm_120 = (12, 0)
```

## üìä –°–†–ê–í–ù–ï–ù–ò–ï –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò

| –ú–æ–¥–µ–ª—å | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ | Blackwell | Flash Attn | –°—Ç–∞—Ç—É—Å |
|--------|----------|----------|-----------|------------|---------|
| **qwen_vl_2b** | 3.91s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ | **–ì–û–¢–û–í–û** |
| **qwen3_vl_2b** | 23.12s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ | **–ì–û–¢–û–í–û** |
| **got_ocr_hf** | 84.14s | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ | **–ì–û–¢–û–í–û** |
| **dots.ocr** | ???s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå | **–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û** | **–û–ñ–ò–î–ê–ù–ò–ï** |

## üéØ –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ô –ü–õ–ê–ù –î–ï–ô–°–¢–í–ò–ô

### –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ (–Ø–Ω–≤–∞—Ä—å 2026):

1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ qwen_vl_2b** –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é OCR –º–æ–¥–µ–ª—å
2. **–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ –≥–æ—Ç–æ–≤—ã–π –∫–æ–¥** dots.ocr (–ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω, –Ω–æ –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω)
3. **–†–µ–∞–ª–∏–∑—É–π—Ç–µ fallback —Å–∏—Å—Ç–µ–º—É** –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

### –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ (Q1-Q2 2025):

1. **–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è** Flash Attention
2. **–¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã** (DeepSeek-OCR, SageAttention)
3. **–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ** —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é OCR —Å–∏—Å—Ç–µ–º—É

### –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ (Q3-Q4 2025):

1. **–û–±–Ω–æ–≤–ª—è–π—Ç–µ—Å—å** –Ω–∞ Flash Attention 4
2. **–ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ dots.ocr** –ø—Ä–∏ –ø–æ—è–≤–ª–µ–Ω–∏–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏
3. **–°—Ä–∞–≤–Ω–∏–≤–∞–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ** —Ä–∞–∑–Ω—ã—Ö OCR –º–æ–¥–µ–ª–µ–π

## üí° –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï

**–í–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞ —É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!**

- ‚úÖ **85.7% —É—Å–ø–µ—à–Ω–æ—Å—Ç—å OCR** –±–µ–∑ dots.ocr
- ‚úÖ **qwen_vl_2b –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ** –∑–∞ 3.91s
- ‚úÖ **–ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** —Å RTX 5070 Ti Blackwell
- ‚úÖ **–ì–æ—Ç–æ–≤–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è** dots.ocr –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å qwen_vl_2b –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é OCR –º–æ–¥–µ–ª—å. dots.ocr —Å—Ç–∞–Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ—Å–ª–µ –≤—ã—Ö–æ–¥–∞ Flash Attention 4 –≤ –∫–æ–Ω—Ü–µ 2025 –≥–æ–¥–∞.

**–í–∞—à –ø—Ä–æ–µ–∫—Ç chatvlmllm –≥–æ—Ç–æ–≤ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É —É–∂–µ —Å–µ–π—á–∞—Å!**

---
*–§–∏–Ω–∞–ª—å–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: 24 —è–Ω–≤–∞—Ä—è 2026*
*–°—Ç–∞—Ç—É—Å: –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Å qwen_vl_2b*