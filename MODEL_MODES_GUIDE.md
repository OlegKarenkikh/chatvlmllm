# üéØ –†–£–ö–û–í–û–î–°–¢–í–û –ü–û –†–ï–ñ–ò–ú–ê–ú –†–ê–ë–û–¢–´ –ú–û–î–ï–õ–ï–ô

–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∂–∏–º–∞–º–∏ —Ä–∞–±–æ—Ç—ã OCR/VLM –º–æ–¥–µ–ª–µ–π —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏ –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º.

## üöÄ –ë–´–°–¢–†–´–ô –°–¢–ê–†–¢

### 1. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞
```bash
# –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞
python integrated_model_launcher.py
```

### 2. –†—É—á–Ω–æ–π –≤—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞

**Transformers —Ä–µ–∂–∏–º (—ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏):**
```bash
python transformers_multi_model_server.py
```

**vLLM —Ä–µ–∂–∏–º (–≤—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å):**
```bash
python vllm_docker_manager.py
```

## üìä –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ñ–ò–ú–û–í

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | Transformers | vLLM |
|----------------|--------------|------|
| **GPU –ø–∞–º—è—Ç—å** | 3-6 GB | 6-12 GB |
| **–°–∫–æ—Ä–æ—Å—Ç—å** | –ú–µ–¥–ª–µ–Ω–Ω–æ (2-5 –º–∏–Ω) | –ë—ã—Å—Ç—Ä–æ (30-60 —Å–µ–∫) |
| **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å** | –í—ã—Å–æ–∫–∞—è | –°—Ä–µ–¥–Ω—è—è |
| **–ú–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω–æ—Å—Ç—å** | –î–∞ (–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ) | –î–∞ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ) |
| **–ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ** | –û–±—â–∏–π –∫–µ—à | –û–±—â–∏–π –∫–µ—à |
| **API —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** | OpenAI | OpenAI |

## üîß –†–ï–ñ–ò–ú–´ –†–ê–ë–û–¢–´

### ü§ñ Transformers —Ä–µ–∂–∏–º

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ù–∏–∑–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏ (8-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è)
- –í—ã—Å–æ–∫–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
- –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ —Å–ª–∞–±—ã—Ö GPU
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞/–≤—ã–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- –ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
- –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
python transformers_multi_model_server.py

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ API
curl -X POST http://localhost:8000/models/load \
  -H "Content-Type: application/json" \
  -d '{"model": "rednote-hilab/dots.ocr"}'

# OCR –∑–∞–ø—Ä–æ—Å
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "rednote-hilab/dots.ocr",
    "messages": [{"role": "user", "content": [
      {"type": "text", "text": "Extract text"},
      {"type": "image_url", "image_url": {"url": "data:image/png;base64,..."}}
    ]}]
  }'
```

### üöÄ vLLM —Ä–µ–∂–∏–º

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
- Batch processing
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- –í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
- –¢—Ä–µ–±—É–µ—Ç –º–æ—â–Ω—É—é GPU
- –°–ª–æ–∂–Ω–µ–µ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
# –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ Docker Compose
docker compose -f docker-compose-vllm.yml up -d

# –ò–ª–∏ —á–µ—Ä–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä
python vllm_docker_manager.py

# OCR –∑–∞–ø—Ä–æ—Å (—Ç–æ—Ç –∂–µ API)
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "rednote-hilab/dots.ocr",
    "messages": [{"role": "user", "content": [
      {"type": "text", "text": "Extract text"},
      {"type": "image_url", "image_url": {"url": "data:image/png;base64,..."}}
    ]}]
  }'
```

## üìÅ –£–ü–†–ê–í–õ–ï–ù–ò–ï –ö–ï–®–ï–ú –ú–û–î–ï–õ–ï–ô

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–µ—à–∞
```
~/.cache/huggingface/hub/
‚îú‚îÄ‚îÄ models--rednote-hilab--dots.ocr/
‚îú‚îÄ‚îÄ models--stepfun-ai--GOT-OCR-2.0-hf/
‚îú‚îÄ‚îÄ models--Qwen--Qwen2-VL-2B-Instruct/
‚îî‚îÄ‚îÄ models--microsoft--Phi-3.5-vision-instruct/
```

### –ú–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Docker
```yaml
volumes:
  # –û—Å–Ω–æ–≤–Ω–æ–µ –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
  - ${HOME}/.cache/huggingface/hub:/root/.cache/huggingface/hub
  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
  - ${HOME}/.cache/huggingface/hub:/home/vllm/.cache/huggingface/hub
  - ${HOME}/.cache/huggingface:/root/.cache/huggingface

environment:
  - HF_HOME=/root/.cache/huggingface
  - TRANSFORMERS_CACHE=/root/.cache/huggingface/hub
  - HF_HUB_CACHE=/root/.cache/huggingface/hub
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–µ—à–∞
```bash
# –ß–µ—Ä–µ–∑ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ª–∞—É–Ω—á–µ—Ä
python integrated_model_launcher.py
# –í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é "8. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–µ—à–µ–º"

# –ò–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
python -c "
from pathlib import Path
cache_dir = Path.home() / '.cache' / 'huggingface' / 'hub'
for item in cache_dir.iterdir():
    if item.is_dir() and item.name.startswith('models--'):
        size = sum(f.stat().st_size for f in item.rglob('*') if f.is_file())
        print(f'{item.name}: {size / (1024**3):.2f} GB')
"
```

## üéØ –ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ï –ú–û–î–ï–õ–ò

### ü§ñ Transformers —Ä–µ–∂–∏–º (8 –º–æ–¥–µ–ª–µ–π)
–í—Å–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç 8-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏:

1. **rednote-hilab/dots.ocr** (3.5 GB) ‚úÖ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ
   - –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å OCR
   - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–ª–æ–∂–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
   - –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ—Å—Ç—å

2. **stepfun-ai/GOT-OCR-2.0-hf** (0.8 GB) ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
   - –õ–µ–≥–∫–∞—è OCR –º–æ–¥–µ–ª—å
   - –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–º–ø—Ç–æ–≤
   - –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

3. **Qwen/Qwen2-VL-2B-Instruct** (2.5 GB) ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
   - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è VLM
   - –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
   - –í–æ–ø—Ä–æ—Å—ã –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º

4. **microsoft/Phi-3.5-vision-instruct** (4.5 GB) ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
   - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è VLM
   - –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
   - –°–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏

5. **vikhyatk/moondream2** (2.0 GB) ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
   - –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è VLM
   - –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
   - –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

6. **Qwen/Qwen2-VL-7B-Instruct** (4.5 GB) ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
   - –ë–æ–ª—å—à–∞—è VLM –º–æ–¥–µ–ª—å
   - –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
   - –ú–µ–¥–ª–µ–Ω–Ω–∞—è –Ω–∞ —Å–ª–∞–±–æ–º –∂–µ–ª–µ–∑–µ

### üöÄ vLLM —Ä–µ–∂–∏–º (4 –º–æ–¥–µ–ª–∏)
–¢–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é —Å vLLM:

1. **rednote-hilab/dots.ocr** (8.0 GB) ‚úÖ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ
   - DotsOCRForCausalLM –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
   - –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å OCR
   - –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞

2. **Qwen/Qwen2-VL-2B-Instruct** (6.0 GB) ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
   - Qwen2VLForConditionalGeneration
   - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è VLM
   - –•–æ—Ä–æ—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

3. **microsoft/Phi-3.5-vision-instruct** (10.0 GB) ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
   - Phi3VForCausalLM –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
   - –ú–æ–∂–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫—É—é –≤–µ—Ä—Å–∏—é vLLM
   - –í—ã—Å–æ–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø–∞–º—è—Ç–∏

4. **Qwen/Qwen2-VL-7B-Instruct** (12.0 GB) ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
   - –ë–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –º–æ—â–Ω—ã—Ö GPU
   - –¢—Ä–µ–±—É–µ—Ç > 12 GB VRAM
   - –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å

### ‚ùå –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å vLLM
–≠—Ç–∏ –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç **—Ç–æ–ª—å–∫–æ –≤ Transformers —Ä–µ–∂–∏–º–µ**:

- **stepfun-ai/GOT-OCR-2.0-hf**: –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ GOTQwenForCausalLM
- **vikhyatk/moondream2**: –ö–∞—Å—Ç–æ–º–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ MoondreamForConditionalGeneration
- **OpenGVLab/InternVL2-2B**: –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ InternVLChatModel
- **microsoft/Phi-3-vision-128k-instruct**: –î–ª–∏–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–±–ª–µ–º–∞—Ç–∏—á–µ–Ω –¥–ª—è vLLM

## üîß –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
```bash
# HuggingFace —Ç–æ–∫–µ–Ω (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
export HF_TOKEN=your_token_here

# –ö–∞—Å—Ç–æ–º–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∫–µ—à–∞
export HF_HOME=/custom/cache/path

# CUDA –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
export CUDA_VISIBLE_DEVICES=0
```

### Docker Compose –ø—Ä–æ—Ñ–∏–ª–∏
```bash
# –¢–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
docker compose -f docker-compose-vllm.yml up -d

# –ú–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω—ã–π —Ä–µ–∂–∏–º
docker compose -f docker-compose-vllm.yml --profile multi-model up -d

# –° –ø—Ä–æ–∫—Å–∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤—â–∏–∫–æ–º
docker compose -f docker-compose-vllm.yml --profile proxy up -d
```

## üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
```bash
# –¢–µ—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–∂–∏–º–∞
python test_memory_optimized_ocr.py

# –¢–µ—Å—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ endpoint
curl http://localhost:8000/health
curl http://localhost:8000/v1/models
```

### –†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
```python
import requests
import base64

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
with open("test_image.png", "rb") as f:
    image_base64 = base64.b64encode(f.read()).decode()

# OCR –∑–∞–ø—Ä–æ—Å
response = requests.post("http://localhost:8000/v1/chat/completions", json={
    "model": "rednote-hilab/dots.ocr",
    "messages": [{
        "role": "user",
        "content": [
            {"type": "text", "text": "Extract all text"},
            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_base64}"}}
        ]
    }]
})

print(response.json()["choices"][0]["message"]["content"])
```

## üõ†Ô∏è –£–ü–†–ê–í–õ–Ø–Æ–©–ò–ï –°–ö–†–ò–ü–¢–´

### 1. `integrated_model_launcher.py`
**–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤—Å–µ–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏

### 2. `transformers_multi_model_server.py`
**Transformers —Å–µ—Ä–≤–µ—Ä** - –º–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä —Å 8-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π

### 3. `vllm_docker_manager.py`
**vLLM –º–µ–Ω–µ–¥–∂–µ—Ä** - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏

### 4. `model_mode_selector.py`
**–°–µ–ª–µ–∫—Ç–æ—Ä —Ä–µ–∂–∏–º–æ–≤** - –≤—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞

### 5. `gpu_memory_manager.py`
**–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏** - –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏

## üö® –†–ï–®–ï–ù–ò–ï –ü–†–û–ë–õ–ï–ú

### –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ GPU –ø–∞–º—è—Ç–∏
```bash
# –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
python gpu_memory_manager.py

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π Transformers —Ä–µ–∂–∏–º
python transformers_multi_model_server.py
```

### –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–µ—à–∞
ls -la ~/.cache/huggingface/hub/

# –û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞
rm -rf ~/.cache/huggingface/hub/models--*

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞
chmod -R 755 ~/.cache/huggingface/
```

### Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤
docker logs dots-ocr-vllm

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –≤ Docker
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu20.04 nvidia-smi

# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ Docker
sudo systemctl restart docker
```

### WSL –ø—Ä–æ–±–ª–µ–º—ã
```bash
# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ WSL (–∏–∑ Windows PowerShell)
wsl --shutdown
wsl

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
ls -la /mnt/c/Users/$USER/.cache/huggingface/
```

## üìà –ú–û–ù–ò–¢–û–†–ò–ù–ì

### GPU –ø–∞–º—è—Ç—å
```bash
# –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
watch -n 1 nvidia-smi

# –ß–µ—Ä–µ–∑ Python
python -c "
import torch
if torch.cuda.is_available():
    print(f'Total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')
    print(f'Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.1f} GB')
    print(f'Cached: {torch.cuda.memory_reserved(0) / 1024**3:.1f} GB')
"
```

### API —Å—Ç–∞—Ç—É—Å
```bash
# Health check –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
for port in 8000 8001 8002; do
  echo "Port $port:"
  curl -s http://localhost:$port/health | jq .
done
```

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
```bash
# –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
time curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "rednote-hilab/dots.ocr", "messages": [...]}'
```

## üéâ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï

–°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≥–∏–±–∫–∏–π –≤—ã–±–æ—Ä –º–µ–∂–¥—É:

1. **Transformers —Ä–µ–∂–∏–º** - –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
2. **vLLM —Ä–µ–∂–∏–º** - –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

–û–±–∞ —Ä–µ–∂–∏–º–∞ –∏—Å–ø–æ–ª—å–∑—É—é—Ç **–æ–±—â–∏–π –∫–µ—à –º–æ–¥–µ–ª–µ–π** –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç **OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API**.

–í—ã–±–∏—Ä–∞–π—Ç–µ —Ä–µ–∂–∏–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–∞—à–∏—Ö –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤!

---
*–°–æ–∑–¥–∞–Ω–æ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è OCR/VLM –º–æ–¥–µ–ª—è–º–∏*