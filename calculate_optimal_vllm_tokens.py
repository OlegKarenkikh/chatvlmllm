#!/usr/bin/env python3
"""
–†–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è dots.ocr –≤ vLLM
–Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π GPU –ø–∞–º—è—Ç–∏
"""

import json
import subprocess
import re
from datetime import datetime

def get_gpu_memory_info():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU –ø–∞–º—è—Ç–∏"""
    
    print("üîç –ê–ù–ê–õ–ò–ó GPU –ü–ê–ú–Ø–¢–ò")
    print("=" * 40)
    
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —á–µ—Ä–µ–∑ nvidia-smi
        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.total,memory.used,memory.free', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            gpu_info = []
            
            for i, line in enumerate(lines):
                parts = line.split(', ')
                if len(parts) == 3:
                    total_mb = int(parts[0])
                    used_mb = int(parts[1])
                    free_mb = int(parts[2])
                    
                    gpu_info.append({
                        'gpu_id': i,
                        'total_mb': total_mb,
                        'used_mb': used_mb,
                        'free_mb': free_mb,
                        'total_gb': total_mb / 1024,
                        'used_gb': used_mb / 1024,
                        'free_gb': free_mb / 1024
                    })
                    
                    print(f"GPU {i}:")
                    print(f"  üìä –û–±—â–∞—è –ø–∞–º—è—Ç—å: {total_mb} MB ({total_mb/1024:.2f} GB)")
                    print(f"  üî¥ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: {used_mb} MB ({used_mb/1024:.2f} GB)")
                    print(f"  üü¢ –°–≤–æ–±–æ–¥–Ω–æ: {free_mb} MB ({free_mb/1024:.2f} GB)")
            
            return gpu_info
        else:
            print("‚ö†Ô∏è nvidia-smi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è GPU –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")
    
    # Fallback - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ RTX 5070 Ti
    return [{
        'gpu_id': 0,
        'total_mb': 12288,  # 12GB
        'used_mb': 0,       # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Å–≤–æ–±–æ–¥–Ω—É—é
        'free_mb': 12288,
        'total_gb': 12.0,
        'used_gb': 0.0,
        'free_gb': 12.0
    }]

def estimate_dots_ocr_memory_usage():
    """–û—Ü–µ–Ω–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ dots.ocr –º–æ–¥–µ–ª—å—é"""
    
    print("\nüßÆ –û–¶–ï–ù–ö–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –ü–ê–ú–Ø–¢–ò dots.ocr")
    print("=" * 50)
    
    # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã dots.ocr –º–æ–¥–µ–ª–∏
    model_info = {
        'name': 'rednote-hilab/dots.ocr',
        'estimated_params': 1.7e9,  # ~1.7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        'precision': 'fp16',        # 16-bit floating point
        'bytes_per_param': 2,       # fp16 = 2 –±–∞–π—Ç–∞ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä
    }
    
    # –†–∞—Å—á–µ—Ç –±–∞–∑–æ–≤–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –º–æ–¥–µ–ª–∏
    base_model_memory_gb = (model_info['estimated_params'] * model_info['bytes_per_param']) / (1024**3)
    
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {model_info['estimated_params']:.1e}")
    print(f"üîß –¢–æ—á–Ω–æ—Å—Ç—å: {model_info['precision']} ({model_info['bytes_per_param']} –±–∞–π—Ç–∞/–ø–∞—Ä–∞–º–µ—Ç—Ä)")
    print(f"üíæ –ë–∞–∑–æ–≤–∞—è –ø–∞–º—è—Ç—å –º–æ–¥–µ–ª–∏: {base_model_memory_gb:.2f} GB")
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã
    overhead_factors = {
        'kv_cache': 0.5,        # KV cache –¥–ª—è attention
        'activations': 0.3,     # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        'gradients': 0.0,       # –ù–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ
        'optimizer': 0.0,       # –ù–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ
        'system_overhead': 0.2, # –°–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã
        'vllm_overhead': 0.3,   # –ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã vLLM
    }
    
    total_overhead_gb = base_model_memory_gb * sum(overhead_factors.values())
    total_model_memory_gb = base_model_memory_gb + total_overhead_gb
    
    print(f"\nüìà –ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã:")
    for factor, multiplier in overhead_factors.items():
        overhead_gb = base_model_memory_gb * multiplier
        print(f"  ‚Ä¢ {factor}: {overhead_gb:.2f} GB ({multiplier*100:.0f}%)")
    
    print(f"\nüíæ –û–±—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –º–æ–¥–µ–ª–∏: {total_model_memory_gb:.2f} GB")
    
    return {
        'base_model_gb': base_model_memory_gb,
        'total_overhead_gb': total_overhead_gb,
        'total_model_gb': total_model_memory_gb,
        'overhead_factors': overhead_factors
    }

def calculate_optimal_max_tokens(gpu_info, model_memory):
    """–†–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
    
    print("\nüéØ –†–ê–°–ß–ï–¢ –û–ü–¢–ò–ú–ê–õ–¨–ù–û–ì–û –ö–û–õ–ò–ß–ï–°–¢–í–ê –¢–û–ö–ï–ù–û–í")
    print("=" * 55)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π GPU
    gpu = gpu_info[0]
    available_memory_gb = gpu['free_gb']
    
    print(f"üü¢ –î–æ—Å—Ç—É–ø–Ω–∞—è –ø–∞–º—è—Ç—å GPU: {available_memory_gb:.2f} GB")
    print(f"üíæ –ü–∞–º—è—Ç—å –º–æ–¥–µ–ª–∏: {model_memory['total_model_gb']:.2f} GB")
    
    # –ü–∞–º—è—Ç—å, –¥–æ—Å—Ç—É–ø–Ω–∞—è –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤
    memory_for_tokens_gb = available_memory_gb - model_memory['total_model_gb']
    
    if memory_for_tokens_gb <= 0:
        print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏!")
        return None
    
    print(f"üéØ –ü–∞–º—è—Ç—å –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤: {memory_for_tokens_gb:.2f} GB")
    
    # –†–∞—Å—á–µ—Ç –ø–∞–º—è—Ç–∏ –Ω–∞ —Ç–æ–∫–µ–Ω
    # –î–ª—è Vision-Language –º–æ–¥–µ–ª–µ–π –ø–∞–º—è—Ç—å –Ω–∞ —Ç–æ–∫–µ–Ω –∑–∞–≤–∏—Å–∏—Ç –æ—Ç:
    # - –†–∞–∑–º–µ—Ä–∞ —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π (hidden_size)
    # - –ö–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–µ–≤ (num_layers)
    # - –†–∞–∑–º–µ—Ä–∞ –≥–æ–ª–æ–≤–æ–∫ –≤–Ω–∏–º–∞–Ω–∏—è (num_attention_heads)
    
    # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è dots.ocr (–Ω–∞ –æ—Å–Ω–æ–≤–µ Qwen2-VL –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã)
    model_config = {
        'hidden_size': 1536,        # –†–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π
        'num_layers': 28,           # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤
        'num_attention_heads': 12,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ–ª–æ–≤–æ–∫ –≤–Ω–∏–º–∞–Ω–∏—è
        'precision_bytes': 2,       # fp16 = 2 –±–∞–π—Ç–∞
    }
    
    # –ü–∞–º—è—Ç—å –Ω–∞ —Ç–æ–∫–µ–Ω –≤ KV cache
    # KV cache = 2 (K + V) * num_layers * hidden_size * precision_bytes
    memory_per_token_bytes = (
        2 * model_config['num_layers'] * 
        model_config['hidden_size'] * 
        model_config['precision_bytes']
    )
    
    memory_per_token_mb = memory_per_token_bytes / (1024 * 1024)
    memory_per_token_gb = memory_per_token_bytes / (1024 ** 3)
    
    print(f"\nüìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏:")
    print(f"  ‚Ä¢ Hidden size: {model_config['hidden_size']}")
    print(f"  ‚Ä¢ Layers: {model_config['num_layers']}")
    print(f"  ‚Ä¢ Attention heads: {model_config['num_attention_heads']}")
    print(f"  ‚Ä¢ Precision: {model_config['precision_bytes']} bytes")
    
    print(f"\nüíæ –ü–∞–º—è—Ç—å –Ω–∞ —Ç–æ–∫–µ–Ω: {memory_per_token_mb:.3f} MB ({memory_per_token_bytes} bytes)")
    
    # –†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤
    max_tokens_theoretical = int(memory_for_tokens_gb / memory_per_token_gb)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    safety_factor = 0.8  # 80% –æ—Ç —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–∞–∫—Å–∏–º—É–º–∞
    max_tokens_safe = int(max_tokens_theoretical * safety_factor)
    
    # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ –∫—Ä–∞—Å–∏–≤—ã—Ö —á–∏—Å–µ–ª
    token_options = [1024, 2048, 4096, 8192, 16384, 32768]
    optimal_tokens = max([t for t in token_options if t <= max_tokens_safe], default=1024)
    
    print(f"\nüßÆ –†–∞—Å—á–µ—Ç—ã:")
    print(f"  ‚Ä¢ –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–π –º–∞–∫—Å–∏–º—É–º: {max_tokens_theoretical:,} —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"  ‚Ä¢ –° –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ ({safety_factor*100:.0f}%): {max_tokens_safe:,} —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"  ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {optimal_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –ø—Ä–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–º –∑–Ω–∞—á–µ–Ω–∏–∏
    memory_usage_gb = optimal_tokens * memory_per_token_gb
    total_memory_usage_gb = model_memory['total_model_gb'] + memory_usage_gb
    memory_utilization = (total_memory_usage_gb / gpu['total_gb']) * 100
    
    print(f"\nüìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ {optimal_tokens:,} —Ç–æ–∫–µ–Ω–∞—Ö:")
    print(f"  ‚Ä¢ –ü–∞–º—è—Ç—å –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤: {memory_usage_gb:.2f} GB")
    print(f"  ‚Ä¢ –û–±—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {total_memory_usage_gb:.2f} GB")
    print(f"  ‚Ä¢ –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU: {memory_utilization:.1f}%")
    
    return {
        'theoretical_max': max_tokens_theoretical,
        'safe_max': max_tokens_safe,
        'recommended': optimal_tokens,
        'memory_per_token_gb': memory_per_token_gb,
        'memory_usage_gb': memory_usage_gb,
        'total_memory_gb': total_memory_usage_gb,
        'utilization_percent': memory_utilization
    }

def create_optimized_vllm_config(optimal_tokens):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ vLLM"""
    
    print(f"\nüîß –°–û–ó–î–ê–ù–ò–ï –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ô –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò vLLM")
    print("=" * 60)
    
    # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Docker Compose
    docker_compose_config = f"""version: '3.8'

services:
  dots-ocr-optimized:
    image: vllm/vllm-openai:latest
    container_name: dots-ocr-vllm-optimized
    ports:
      - "8000:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - VLLM_WORKER_MULTIPROC_METHOD=spawn
    command: >
      --model rednote-hilab/dots.ocr
      --host 0.0.0.0
      --port 8000
      --max-model-len {optimal_tokens['recommended']}
      --gpu-memory-utilization 0.85
      --dtype float16
      --trust-remote-code
      --disable-log-requests
      --served-model-name rednote-hilab/dots.ocr
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

networks:
  default:
    name: vllm-network
"""
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    with open("docker-compose-vllm-optimized.yml", "w", encoding="utf-8") as f:
        f.write(docker_compose_config)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: docker-compose-vllm-optimized.yml")
    print(f"üéØ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤: {optimal_tokens['recommended']:,}")
    print(f"üíæ –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU –ø–∞–º—è—Ç–∏: 85%")
    print(f"üîß –¢–æ—á–Ω–æ—Å—Ç—å: float16")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ –∑–∞–ø—É—Å–∫–∞
    launch_script = f"""#!/bin/bash
# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ dots.ocr –≤ vLLM
# –†–∞—Å—Å—á–∏—Ç–∞–Ω–æ –¥–ª—è RTX 5070 Ti (12GB VRAM)

echo "üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ dots.ocr vLLM —Å–µ—Ä–≤–µ—Ä–∞"
echo "üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤: {optimal_tokens['recommended']:,}"
echo "üíæ –û–∂–∏–¥–∞–µ–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {optimal_tokens['total_memory_gb']:.2f} GB"
echo "üéØ –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU: {optimal_tokens['utilization_percent']:.1f}%"

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
echo "üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤..."
docker-compose -f docker-compose-vllm.yml down 2>/dev/null || true
docker-compose -f docker-compose-vllm-optimized.yml down 2>/dev/null || true

# –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
echo "üîÑ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞..."
docker-compose -f docker-compose-vllm-optimized.yml up -d

# –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
echo "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞..."
sleep 30

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
echo "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞..."
curl -s http://localhost:8000/health && echo "‚úÖ –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤!" || echo "‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π
echo "üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:"
curl -s http://localhost:8000/v1/models | python -m json.tool

echo "üéâ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π vLLM —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω!"
echo "üí° –¢–µ–ø–µ—Ä—å dots.ocr –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ {optimal_tokens['recommended']:,} —Ç–æ–∫–µ–Ω–æ–≤"
"""
    
    with open("start_vllm_optimized.sh", "w", encoding="utf-8") as f:
        f.write(launch_script)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Å–∫—Ä–∏–ø—Ç: start_vllm_optimized.sh")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ Windows batch —Ñ–∞–π–ª–∞
    batch_script = f"""@echo off
REM –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ dots.ocr –≤ vLLM –¥–ª—è Windows
REM –†–∞—Å—Å—á–∏—Ç–∞–Ω–æ –¥–ª—è RTX 5070 Ti (12GB VRAM)

echo üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ dots.ocr vLLM —Å–µ—Ä–≤–µ—Ä–∞
echo üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤: {optimal_tokens['recommended']:,}
echo üíæ –û–∂–∏–¥–∞–µ–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {optimal_tokens['total_memory_gb']:.2f} GB
echo üéØ –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU: {optimal_tokens['utilization_percent']:.1f}%%

REM –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
echo üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤...
docker-compose -f docker-compose-vllm.yml down >nul 2>&1
docker-compose -f docker-compose-vllm-optimized.yml down >nul 2>&1

REM –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
echo üîÑ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞...
docker-compose -f docker-compose-vllm-optimized.yml up -d

REM –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
echo ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞...
timeout /t 30 /nobreak >nul

REM –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
echo üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞...
curl -s http://localhost:8000/health >nul && echo ‚úÖ –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤! || echo ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞

echo üéâ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π vLLM —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω!
echo üí° –¢–µ–ø–µ—Ä—å dots.ocr –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ {optimal_tokens['recommended']:,} —Ç–æ–∫–µ–Ω–æ–≤
pause
"""
    
    with open("start_vllm_optimized.bat", "w", encoding="utf-8") as f:
        f.write(batch_script)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Å–∫—Ä–∏–ø—Ç: start_vllm_optimized.bat")
    
    return {
        'docker_compose_file': 'docker-compose-vllm-optimized.yml',
        'launch_script_linux': 'start_vllm_optimized.sh',
        'launch_script_windows': 'start_vllm_optimized.bat',
        'max_tokens': optimal_tokens['recommended'],
        'memory_usage_gb': optimal_tokens['total_memory_gb'],
        'utilization_percent': optimal_tokens['utilization_percent']
    }

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    
    print("üßÆ –†–ê–°–ß–ï–¢ –û–ü–¢–ò–ú–ê–õ–¨–ù–û–ì–û –ö–û–õ–ò–ß–ï–°–¢–í–ê –¢–û–ö–ï–ù–û–í –î–õ–Ø dots.ocr vLLM")
    print("=" * 70)
    print(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU
    gpu_info = get_gpu_memory_info()
    
    # –û—Ü–µ–Ω–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –º–æ–¥–µ–ª–∏
    model_memory = estimate_dots_ocr_memory_usage()
    
    # –†–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤
    optimal_tokens = calculate_optimal_max_tokens(gpu_info, model_memory)
    
    if not optimal_tokens:
        print("‚ùå –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã")
        return
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config_info = create_optimized_vllm_config(optimal_tokens)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    report = {
        'timestamp': datetime.now().isoformat(),
        'gpu_info': gpu_info,
        'model_memory_analysis': model_memory,
        'token_calculations': optimal_tokens,
        'configuration_files': config_info,
        'recommendations': [
            f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ {optimal_tokens['recommended']:,} —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
            f"–û–∂–∏–¥–∞–µ–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {optimal_tokens['total_memory_gb']:.2f} GB",
            f"–£—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU: {optimal_tokens['utilization_percent']:.1f}%",
            "–ó–∞–ø—É—Å—Ç–∏—Ç–µ: ./start_vllm_optimized.sh (Linux) –∏–ª–∏ start_vllm_optimized.bat (Windows)"
        ]
    }
    
    with open("vllm_token_optimization_report.json", "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 70)
    print("üéâ –†–ê–°–ß–ï–¢ –ó–ê–í–ï–†–®–ï–ù!")
    print("=" * 70)
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"  ‚Ä¢ –¢–µ–∫—É—â–∏–π –ª–∏–º–∏—Ç: 1,024 —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"  ‚Ä¢ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç: {optimal_tokens['recommended']:,} —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"  ‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤ {optimal_tokens['recommended']/1024:.1f} —Ä–∞–∑")
    print(f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {optimal_tokens['total_memory_gb']:.2f} GB")
    print(f"  ‚Ä¢ –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU: {optimal_tokens['utilization_percent']:.1f}%")
    
    print(f"\nüìÅ –°–û–ó–î–ê–ù–ù–´–ï –§–ê–ô–õ–´:")
    print(f"  ‚Ä¢ docker-compose-vllm-optimized.yml")
    print(f"  ‚Ä¢ start_vllm_optimized.sh (Linux)")
    print(f"  ‚Ä¢ start_vllm_optimized.bat (Windows)")
    print(f"  ‚Ä¢ vllm_token_optimization_report.json")
    
    print(f"\nüöÄ –ó–ê–ü–£–°–ö –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –°–ï–†–í–ï–†–ê:")
    print(f"  Linux/Mac: ./start_vllm_optimized.sh")
    print(f"  Windows: start_vllm_optimized.bat")
    print(f"  Docker: docker-compose -f docker-compose-vllm-optimized.yml up -d")
    
    print(f"\nüí° –û–ñ–ò–î–ê–ï–ú–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø:")
    print(f"  ‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print(f"  ‚Ä¢ –ë–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã")
    print(f"  ‚Ä¢ –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ OCR")
    print(f"  ‚Ä¢ –ù–µ—Ç –æ—à–∏–±–æ–∫ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤")

if __name__ == "__main__":
    main()