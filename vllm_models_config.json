{
  "rednote-hilab/dots.ocr": {
    "model_name": "rednote-hilab/dots.ocr",
    "container_name": "dots-ocr-fixed",
    "port": 8000,
    "size_gb": 5.72,
    "category": "ocr",
    "vllm_params": {
      "max_model_len": 1024,
      "gpu_memory_utilization": 0.85,
      "trust_remote_code": true,
      "enforce_eager": true,
      "port_offset": 0
    },
    "issues": [],
    "priority": 1
  },
  "stepfun-ai/GOT-OCR2_0": {
    "model_name": "stepfun-ai/GOT-OCR2_0",
    "container_name": "stepfun-ai-got-ocr2_0-vllm",
    "port": 8001,
    "size_gb": 1.34,
    "category": "ocr",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.8,
      "trust_remote_code": true,
      "enforce_eager": true,
      "port_offset": 0
    },
    "issues": [
      "Large vocabulary size may require more memory"
    ],
    "priority": 2
  },
  "ucaslcl/GOT-OCR2_0": {
    "model_name": "ucaslcl/GOT-OCR2_0",
    "container_name": "ucaslcl-got-ocr2_0-vllm",
    "port": 8002,
    "size_gb": 2.67,
    "category": "ocr",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.8,
      "trust_remote_code": true,
      "enforce_eager": true,
      "port_offset": 0
    },
    "issues": [
      "Large vocabulary size may require more memory"
    ],
    "priority": 2
  },
  "Qwen/Qwen3-VL-2B-Instruct": {
    "model_name": "Qwen/Qwen3-VL-2B-Instruct",
    "container_name": "qwen-qwen3-vl-2b-instruct-vllm",
    "port": 8003,
    "size_gb": 3.97,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 2048,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": false,
      "port_offset": 10
    },
    "issues": [],
    "priority": 3
  },
  "Qwen/Qwen2-VL-2B-Instruct": {
    "model_name": "Qwen/Qwen2-VL-2B-Instruct",
    "container_name": "qwen-qwen2-vl-2b-instruct-vllm",
    "port": 8004,
    "port": 8004,
    "size_gb": 4.13,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 4096,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": false,
      "port_offset": 10
    },
    "issues": [
      "Large vocabulary size may require more memory"
    ],
    "priority": 4
  },
  "Qwen/Qwen2-VL-7B-Instruct": {
    "model_name": "Qwen/Qwen2-VL-7B-Instruct",
    "container_name": "qwen-qwen2-vl-7b-instruct-vllm",
    "port": 8005,
    "size_gb": 7.61,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 4096,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": false,
      "port_offset": 10
    },
    "issues": [
      "Large vocabulary size may require more memory"
    ],
    "priority": 4
  },
  "Qwen/Qwen2.5-VL-7B-Instruct": {
    "model_name": "Qwen/Qwen2.5-VL-7B-Instruct",
    "container_name": "qwen-qwen2-5-vl-7b-instruct-vllm",
    "port": 8006,
    "size_gb": 0.66,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 4096,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": false,
      "port_offset": 10
    },
    "issues": [
      "Large vocabulary size may require more memory"
    ],
    "priority": 4
  },
  "microsoft/Phi-3.5-vision-instruct": {
    "model_name": "microsoft/Phi-3.5-vision-instruct",
    "container_name": "microsoft-phi-3-5-vision-instruct-vllm",
    "port": 8007,
    "size_gb": 7.73,
    "category": "vlm",
    "vllm_params": {
      "max_model_len": 4096,
      "gpu_memory_utilization": 0.7,
      "trust_remote_code": true,
      "enforce_eager": false,
      "port_offset": 10
    },
    "issues": [],
    "priority": 4
  }
}