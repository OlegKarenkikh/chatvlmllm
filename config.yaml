# ChatVLMLLM Configuration - CUDA 13.0 + transformers 5.0.0.dev0 –°–û–í–ú–ï–°–¢–ò–ú–´–ï –ú–û–î–ï–õ–ò
# –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: —Ç–æ–ª—å–∫–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏

models:
  # –û–°–ù–û–í–ù–´–ï –†–ê–ë–û–ß–ò–ï –ú–û–î–ï–õ–ò (CUDA 13.0 + transformers 5.0.0.dev0)
  qwen_vl_2b:
    name: "Qwen2-VL 2B ‚≠ê‚≠ê‚≠ê"
    description: "–û–°–ù–û–í–ù–ê–Ø OCR –ú–û–î–ï–õ–¨ - –ë—ã—Å—Ç—Ä–∞—è –∏ —Ç–æ—á–Ω–∞—è (100% –∫–∞—á–µ—Å—Ç–≤–æ OCR)"
    model_path: "Qwen/Qwen2-VL-2B-Instruct"
    model_type: "vlm"
    max_length: 4096
    precision: "fp16"
    device_map: "auto"
    trust_remote_code: true
    use_flash_attention: false
    min_pixels: 256
    max_pixels: 1280
    # ‚úÖ –ü–†–û–¢–ï–°–¢–ò–†–û–í–ê–ù–û: –ó–∞–≥—Ä—É–∑–∫–∞=25.7s, –û–±—Ä–∞–±–æ—Ç–∫–∞=8.96s, –ö–∞—á–µ—Å—Ç–≤–æ=100%
    # ‚úÖ –ü–û–õ–ù–ê–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨: CUDA 13.0 + transformers 5.0.0.dev0

  qwen3_vl_2b:
    name: "Qwen3-VL 2B ‚≠ê‚≠ê"
    description: "–ú–ù–û–ì–û–Ø–ó–´–ß–ù–ê–Ø –ú–û–î–ï–õ–¨ - 32 —è–∑—ã–∫–∞, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏"
    model_path: "Qwen/Qwen3-VL-2B-Instruct"
    model_type: "vlm"
    max_length: 4096
    precision: "fp16"
    device_map: "auto"
    trust_remote_code: true
    use_flash_attention: false
    min_pixels: 256
    max_pixels: 1280
    # ‚úÖ –ü–†–û–¢–ï–°–¢–ò–†–û–í–ê–ù–û: –ó–∞–≥—Ä—É–∑–∫–∞=16.5s, –û–±—Ä–∞–±–æ—Ç–∫–∞=42.8s, –ö–∞—á–µ—Å—Ç–≤–æ=60%
    # ‚úÖ –ü–û–õ–ù–ê–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨: CUDA 13.0 + transformers 5.0.0.dev0
    # Features: 32 languages OCR, 256K context, visual agent, spatial perception

app:
  title: "ChatVLMLLM - OCR –∏ Vision-Language –º–æ–¥–µ–ª–∏"
  page_icon: "üî¨"
  layout: "wide"
  theme: "light"
  
cache:
  enable: true
  directory: ".cache/app"
  max_age_seconds: 3600
  
export:
  default_format: "json"
  formats: ["json", "csv", "txt"]
  include_metadata: true
  
logging:
  level: "INFO"
  file: "logs/chatvlmllm.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
performance:
  enable_flash_attention: false  # –û—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è Windows
  use_int8_quantization: false
  optimize_memory: true
  max_batch_size: 1  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è GPU
  inference_timeout: 30
  single_model_mode: true  # –ó–∞–≥—Ä—É–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É –º–æ–¥–µ–ª—å
  auto_unload: true        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–≥—Ä—É–∂–∞—Ç—å –ø—Ä–∏ —Å–º–µ–Ω–µ

# GPU Requirements –¥–ª—è RTX 5070 Ti (12.82GB VRAM) - CUDA 13.0
gpu_requirements:
  current_gpu:
    name: "RTX 5070 Ti"
    vram_gb: 12.82
    cuda_version: "13.0"
    pytorch_version: "2.9.1+cu130"
    transformers_version: "5.0.0.dev0"
    
    # ‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ï –°–û–í–ú–ï–°–¢–ò–ú–´–ï –ú–û–î–ï–õ–ò (CUDA 13.0 + transformers 5.0.0.dev0)
    fully_working: ["qwen_vl_2b", "qwen3_vl_2b"]  # 2 –º–æ–¥–µ–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ
    
    # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã
    primary_ocr: "qwen_vl_2b"        # –û–°–ù–û–í–ù–ê–Ø OCR –º–æ–¥–µ–ª—å (100% –∫–∞—á–µ—Å—Ç–≤–æ)
    secondary_ocr: "qwen3_vl_2b"     # –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è OCR (60% –∫–∞—á–µ—Å—Ç–≤–æ, 32 —è–∑—ã–∫–∞)
    chat_model: "qwen_vl_2b"         # –ë—ã—Å—Ç—Ä—ã–π –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç
    
  performance_metrics:
    # –†–µ–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (CUDA 13.0 + transformers 5.0.0.dev0)
    qwen_vl_2b:
      load_time: "25.70s"
      process_time: "8.96s" 
      ocr_quality: "100% (5/5 keywords)"
      output_length: "67 chars"
      status: "‚úÖ –û–¢–õ–ò–ß–ù–û - –û–°–ù–û–í–ù–ê–Ø –ú–û–î–ï–õ–¨"
      compatibility: "‚úÖ –ü–û–õ–ù–ê–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨"
      
    qwen3_vl_2b:
      load_time: "16.49s"
      process_time: "42.85s"
      ocr_quality: "60% (3/5 keywords)" 
      output_length: "460 chars"
      status: "‚úÖ –•–û–†–û–®–û - –ú–ù–û–ì–û–Ø–ó–´–ß–ù–ê–Ø"
      compatibility: "‚úÖ –ü–û–õ–ù–ê–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨"
      features: "32 languages, 256K context, visual agent"
    
  optimization:
    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–¢–û–õ–¨–ö–û –°–û–í–ú–ï–°–¢–ò–ú–´–ï –ú–û–î–ï–õ–ò)
    default_model: "qwen_vl_2b"      # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è OCR (–õ–£–ß–®–ò–ô!)
    chat_model: "qwen_vl_2b"         # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —á–∞—Ç–∞
    single_model_mode: true          # –ó–∞–≥—Ä—É–∂–∞—Ç—å –ø–æ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
    auto_unload: true                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–≥—Ä—É–∂–∞—Ç—å –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ
    prefer_int8: false               # FP16 –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —ç—Ç–æ–π GPU
    batch_size: 1                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    
  removed_models:
    # –ú–æ–¥–µ–ª–∏ —É–¥–∞–ª–µ–Ω—ã –∏–∑-–∑–∞ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    got_ocr_hf: "‚ùå –ú—É—Å–æ—Ä–Ω—ã–π –≤—ã–≤–æ–¥ —Å transformers 5.0.0.dev0"
    got_ocr_ucas: "‚ùå –û—à–∏–±–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ —Å transformers 5.0.0.dev0"
    dots_ocr: "‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ (JSON –≤–º–µ—Å—Ç–æ OCR —Ç–µ–∫—Å—Ç–∞)"
    phi3_vision: "‚ùå –ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (76s)"
    deepseek_ocr: "‚ùå Graceful degradation (–Ω–µ OCR)"
    
  final_status:
    # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
    total_models_tested: 7
    compatible_models: 2
    compatibility_rate: "28.6%"
    system_status: "‚úÖ –°–¢–ê–ë–ò–õ–¨–ù–ê–Ø –†–ê–ë–û–¢–ê"
    recommendation: "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å qwen_vl_2b –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å"