#!/usr/bin/env python3
"""
–ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å —Ä–µ–∂–∏–º–æ–≤ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ø–∞–º—è—Ç–∏ –¥–ª—è Streamlit
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è MemoryController –≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
"""

import streamlit as st
import time
from typing import Tuple, Dict, Any, List
from utils.memory_controller import memory_controller, ExecutionMode
import subprocess
import json

class ModeSwitcher:
    """–ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å —Ä–µ–∂–∏–º–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ø–∞–º—è—Ç–∏"""
    
    def __init__(self):
        self.memory_controller = memory_controller
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
        if 'current_execution_mode' not in st.session_state:
            st.session_state.current_execution_mode = None
        if 'current_model' not in st.session_state:
            st.session_state.current_model = None
        if 'memory_status' not in st.session_state:
            st.session_state.memory_status = {}
    
    def display_memory_status(self) -> None:
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø–∞–º—è—Ç–∏"""
        status = self.memory_controller.get_memory_status()
        st.session_state.memory_status = status
        
        # GPU –ø–∞–º—è—Ç—å
        gpu_mem = status['gpu_memory']
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "GPU –ø–∞–º—è—Ç—å (–≤—Å–µ–≥–æ)", 
                f"{gpu_mem['total_gb']:.1f} GB",
                help="–û–±—â–∏–π –æ–±—ä–µ–º GPU –ø–∞–º—è—Ç–∏"
            )
        
        with col2:
            st.metric(
                "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è", 
                f"{gpu_mem['used_gb']:.1f} GB",
                f"{gpu_mem['utilization_percent']:.1f}%",
                help="–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è GPU –ø–∞–º—è—Ç—å"
            )
        
        with col3:
            st.metric(
                "–î–æ—Å—Ç—É–ø–Ω–æ", 
                f"{gpu_mem['free_gb']:.1f} GB",
                help="–î–æ—Å—Ç—É–ø–Ω–∞—è GPU –ø–∞–º—è—Ç—å"
            )
        
        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–º—è—Ç–∏
        if gpu_mem['free_gb'] < 2.0:
            st.error("‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–∞–ª–æ —Å–≤–æ–±–æ–¥–Ω–æ–π GPU –ø–∞–º—è—Ç–∏")
        elif gpu_mem['free_gb'] < 4.0:
            st.warning("‚ö†Ô∏è –ú–∞–ª–æ —Å–≤–æ–±–æ–¥–Ω–æ–π GPU –ø–∞–º—è—Ç–∏")
        else:
            st.success("‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–≤–æ–±–æ–¥–Ω–æ–π GPU –ø–∞–º—è—Ç–∏")
        
        # –¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º
        current_mode = status.get('current_mode')
        if current_mode:
            st.info(f"üîß –¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: **{current_mode.upper()}**")
        else:
            st.info("üîß –†–µ–∂–∏–º –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω")
    
    def display_loaded_models(self) -> None:
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        status = self.memory_controller.get_memory_status()
        loaded_models = status['loaded_models']
        
        st.subheader("üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏")
        
        # Transformers –º–æ–¥–µ–ª–∏
        transformers_models = loaded_models['transformers']
        if transformers_models:
            st.write("**Transformers –º–æ–¥–µ–ª–∏:**")
            for model in transformers_models:
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"‚Ä¢ {model}")
                with col2:
                    if st.button("üóëÔ∏è", key=f"unload_tf_{model}", help=f"–í—ã–≥—Ä—É–∑–∏—Ç—å {model}"):
                        self.unload_transformers_model(model)
        else:
            st.write("*–ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö Transformers –º–æ–¥–µ–ª–µ–π*")
        
        # vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
        vllm_containers = loaded_models['vllm_containers']
        if vllm_containers:
            st.write("**vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã:**")
            for container in vllm_containers:
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"‚Ä¢ {container}")
                with col2:
                    if st.button("üõë", key=f"stop_vllm_{container}", help=f"–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å {container}"):
                        self.stop_vllm_container(container)
        else:
            st.write("*–ù–µ—Ç –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤*")
    
    def display_cached_models(self) -> None:
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        cached_models = self.memory_controller.get_cached_models()
        
        st.subheader("üíæ –ö–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏")
        
        if cached_models:
            for model in cached_models:
                st.write(f"‚Ä¢ {model}")
        else:
            st.warning("–ù–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
            st.info("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–µ—à–∞")
    
    def switch_execution_mode(self, target_mode: str, target_model: str = None) -> Tuple[bool, str]:
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        
        if target_mode == "vLLM (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)":
            mode = ExecutionMode.VLLM
        else:
            mode = ExecutionMode.TRANSFORMERS
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            status_text.text("üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—é —Ä–µ–∂–∏–º–∞...")
            progress_bar.progress(20)
            
            if mode == ExecutionMode.VLLM:
                success, message = self.memory_controller.switch_to_vllm_mode(target_model)
            else:
                success, message = self.memory_controller.switch_to_transformers_mode(target_model)
            
            progress_bar.progress(80)
            
            if success:
                st.session_state.current_execution_mode = target_mode
                if target_model:
                    st.session_state.current_model = target_model
                
                status_text.text("‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
                progress_bar.progress(100)
                time.sleep(1)
                
                # –û—á–∏—â–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress_bar.empty()
                status_text.empty()
                
                return True, message
            else:
                progress_bar.empty()
                status_text.empty()
                return False, message
                
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            return False, f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∂–∏–º–∞: {e}"
    
    def change_model(self, new_model: str, execution_mode: str) -> Tuple[bool, str]:
        """–°–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ø–∞–º—è—Ç–∏"""
        
        container_type = "vllm" if "vLLM" in execution_mode else "transformers"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            status_text.text(f"üîÑ –°–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ {new_model}...")
            progress_bar.progress(30)
            
            success, message = self.memory_controller.change_model_in_container(
                new_model, container_type
            )
            
            progress_bar.progress(80)
            
            if success:
                st.session_state.current_model = new_model
                status_text.text("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∞")
                progress_bar.progress(100)
                time.sleep(1)
                
                # –û—á–∏—â–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress_bar.empty()
                status_text.empty()
                
                return True, message
            else:
                progress_bar.empty()
                status_text.empty()
                return False, message
                
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            return False, f"–û—à–∏–±–∫–∞ —Å–º–µ–Ω—ã –º–æ–¥–µ–ª–∏: {e}"
    
    def unload_transformers_model(self, model_name: str) -> None:
        """–í—ã–≥—Ä—É–∑–∫–∞ Transformers –º–æ–¥–µ–ª–∏"""
        with st.spinner(f"–í—ã–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name}..."):
            unloaded = self.memory_controller.unload_transformers_models([model_name])
            
            if unloaded:
                st.success(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –≤—ã–≥—Ä—É–∂–µ–Ω–∞")
                st.rerun()
            else:
                st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å {model_name}")
    
    def stop_vllm_container(self, container_name: str) -> None:
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
        with st.spinner(f"–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ {container_name}..."):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑ –∏–º–µ–Ω–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            model_names = [container_name]  # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞
            stopped = self.memory_controller.stop_vllm_containers(model_names)
            
            if stopped:
                st.success(f"‚úÖ –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä {container_name} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                st.rerun()
            else:
                st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä {container_name}")
    
    def emergency_cleanup(self) -> None:
        """–≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏"""
        with st.spinner("üö® –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏..."):
            success, message = self.memory_controller.emergency_cleanup()
            
            if success:
                st.success("‚úÖ –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                st.info(message)
                
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏
                st.session_state.current_execution_mode = None
                st.session_state.current_model = None
                
                st.rerun()
            else:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏: {message}")
    
    def display_mode_switcher_ui(self) -> None:
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ UI –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—è —Ä–µ–∂–∏–º–æ–≤"""
        
        st.subheader("üîß –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞–º–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
        
        # –¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å
        with st.expander("üìä –°—Ç–∞—Ç—É—Å –ø–∞–º—è—Ç–∏", expanded=True):
            self.display_memory_status()
        
        # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**–†–µ–∂–∏–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:**")
            execution_mode = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º",
                ["vLLM (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)", "Transformers (–õ–æ–∫–∞–ª—å–Ω–æ)"],
                index=0 if st.session_state.current_execution_mode == "vLLM (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)" else 1,
                key="execution_mode_selector"
            )
        
        with col2:
            st.write("**–ú–æ–¥–µ–ª—å:**")
            cached_models = self.memory_controller.get_cached_models()
            
            if cached_models:
                current_model_index = 0
                if st.session_state.current_model in cached_models:
                    current_model_index = cached_models.index(st.session_state.current_model)
                
                selected_model = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å",
                    cached_models,
                    index=current_model_index,
                    key="model_selector"
                )
            else:
                st.warning("–ù–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
                selected_model = None
        
        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üîÑ –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è", type="primary"):
                if selected_model:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å —Ä–µ–∂–∏–º
                    if execution_mode != st.session_state.current_execution_mode:
                        success, message = self.switch_execution_mode(execution_mode, selected_model)
                        if success:
                            st.success(f"‚úÖ {message}")
                        else:
                            st.error(f"‚ùå {message}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å
                    elif selected_model != st.session_state.current_model:
                        success, message = self.change_model(selected_model, execution_mode)
                        if success:
                            st.success(f"‚úÖ {message}")
                        else:
                            st.error(f"‚ùå {message}")
                    else:
                        st.info("–ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç")
                else:
                    st.error("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å")
        
        with col2:
            if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å"):
                self.memory_controller.cleanup_gpu_memory()
                st.success("‚úÖ GPU –ø–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")
                st.rerun()
        
        with col3:
            if st.button("üö® –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞"):
                self.emergency_cleanup()
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        with st.expander("üì¶ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏"):
            self.display_loaded_models()
        
        with st.expander("üíæ –ö–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏"):
            self.display_cached_models()
    
    def get_recommended_settings(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞–º—è—Ç–∏"""
        status = self.memory_controller.get_memory_status()
        gpu_mem = status['gpu_memory']
        
        recommendations = {
            "execution_mode": "transformers",  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            "precision": "fp16",
            "quantization": False,
            "max_tokens": 1024,
            "batch_size": 1
        }
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏
        free_gb = gpu_mem['free_gb']
        
        if free_gb >= 8.0:
            recommendations.update({
                "execution_mode": "vllm",
                "precision": "fp16",
                "max_tokens": 2048,
                "batch_size": 4
            })
        elif free_gb >= 6.0:
            recommendations.update({
                "execution_mode": "vllm",
                "precision": "fp16",
                "max_tokens": 1024,
                "batch_size": 2
            })
        elif free_gb >= 4.0:
            recommendations.update({
                "execution_mode": "transformers",
                "precision": "fp16",
                "max_tokens": 1024,
                "batch_size": 1
            })
        else:
            recommendations.update({
                "execution_mode": "transformers",
                "precision": "int8",
                "quantization": True,
                "max_tokens": 512,
                "batch_size": 1
            })
        
        return recommendations

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—è
mode_switcher = ModeSwitcher()