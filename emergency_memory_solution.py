#!/usr/bin/env python3
"""
–≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–∞–º—è—Ç—å—é GPU
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
"""

import subprocess
import time
import requests
import json

def stop_all_containers():
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
    print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤...")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
    try:
        result = subprocess.run(
            ["docker", "ps", "-a", "--format", "{{.Names}}"],
            capture_output=True, text=True, timeout=30
        )
        
        if result.returncode == 0:
            containers = result.stdout.strip().split('\n')
            vllm_containers = [c for c in containers if c and ('vllm' in c.lower() or 'dots' in c.lower() or 'qwen' in c.lower())]
            
            for container in vllm_containers:
                print(f"–û—Å—Ç–∞–Ω–æ–≤–∫–∞: {container}")
                subprocess.run(["docker", "stop", container], capture_output=True, timeout=30)
                subprocess.run(["docker", "rm", container], capture_output=True, timeout=10)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {e}")
    
    # –û—á–∏—Å—Ç–∫–∞ —Å–∏—Å—Ç–µ–º—ã
    subprocess.run(["docker", "system", "prune", "-f"], capture_output=True)
    time.sleep(5)

def get_gpu_memory_info():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU –ø–∞–º—è—Ç–∏"""
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=memory.total,memory.free,memory.used", "--format=csv,noheader,nounits"],
            capture_output=True, text=True, timeout=10
        )
        
        if result.returncode == 0:
            memory_info = result.stdout.strip().split(', ')
            total_mb = int(memory_info[0])
            free_mb = int(memory_info[1])
            used_mb = int(memory_info[2])
            
            return {
                "total_gb": total_mb / 1024,
                "free_gb": free_mb / 1024,
                "used_gb": used_mb / 1024,
                "available_percent": (free_mb / total_mb) * 100
            }
    except Exception as e:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU: {e}")
    
    return None

def start_minimal_dots_ocr():
    """–ó–∞–ø—É—Å–∫ dots.ocr —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
    print("üöÄ –ó–∞–ø—É—Å–∫ dots.ocr —Å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏...")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –∫–µ—à—É
    try:
        userprofile = subprocess.check_output(['echo', '%USERPROFILE%'], shell=True, text=True).strip()
        cache_path = f"{userprofile}/.cache/huggingface/hub"
    except:
        cache_path = "~/.cache/huggingface/hub"
    
    # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    command = [
        "docker", "run", "-d",
        "--name", "dots-ocr-minimal",
        "--restart", "unless-stopped",
        "-p", "8000:8000",
        "--gpus", "all",
        "--shm-size", "1g",  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π shared memory
        "-v", f"{cache_path}:/root/.cache/huggingface/hub:rw",
        "-e", "CUDA_VISIBLE_DEVICES=0",
        "-e", "NVIDIA_VISIBLE_DEVICES=all",
        "vllm/vllm-openai:latest",
        "--model", "rednote-hilab/dots.ocr",
        "--host", "0.0.0.0",
        "--port", "8000",
        "--trust-remote-code",
        "--max-model-len", "512",  # –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        "--gpu-memory-utilization", "0.25",  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
        "--dtype", "bfloat16",
        "--enforce-eager",
        "--disable-log-requests",
        "--max-num-batched-tokens", "128",  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –±–∞—Ç—á
        "--disable-custom-all-reduce",
        "--enable-prefix-caching", "false",  # –û—Ç–∫–ª—é—á–∞–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
        "--enable-chunked-prefill", "false"  # –û—Ç–∫–ª—é—á–∞–µ–º chunked prefill
    ]
    
    try:
        result = subprocess.run(command, capture_output=True, text=True, timeout=120)
        if result.returncode == 0:
            print("‚úÖ dots.ocr –∑–∞–ø—É—â–µ–Ω —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {result.stderr}")
            return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False

def wait_for_model_ready(port=8000, timeout=600):
    """–û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
    print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    
    start_time = time.time()
    
    while time.time() - start_time < timeout:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º health
            response = requests.get(f"http://localhost:{port}/health", timeout=5)
            if response.status_code == 200:
                print("‚úÖ Health check –ø—Ä–æ—à–µ–ª")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –º–æ–¥–µ–ª–µ–π
                models_response = requests.get(f"http://localhost:{port}/v1/models", timeout=5)
                if models_response.status_code == 200:
                    print("‚úÖ API –º–æ–¥–µ–ª–µ–π –≥–æ—Ç–æ–≤")
                    return True
                else:
                    print("‚è≥ API –º–æ–¥–µ–ª–µ–π –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤...")
            else:
                print("‚è≥ Health check –Ω–µ –ø—Ä–æ—à–µ–ª...")
        except Exception as e:
            elapsed = int(time.time() - start_time)
            if elapsed % 60 == 0:  # –ö–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
                print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ... ({elapsed}s)")
        
        time.sleep(10)
    
    return False

def test_minimal_ocr():
    """–¢–µ—Å—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π OCR"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π OCR...")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    from PIL import Image, ImageDraw, ImageFont
    
    img = Image.new('RGB', (200, 100), color='white')
    draw = ImageDraw.Draw(img)
    
    try:
        font = ImageFont.truetype("arial.ttf", 16)
    except:
        font = ImageFont.load_default()
    
    draw.text((10, 30), "Test OCR", fill='black', font=font)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    img.save("test_minimal_ocr.png")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
    import base64
    import io
    
    buffer = io.BytesIO()
    img.save(buffer, format='PNG')
    image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º API
    payload = {
        "model": "rednote-hilab/dots.ocr",
        "messages": [{
            "role": "user",
            "content": [
                {"type": "text", "text": "Extract text from this image"},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_base64}"}}
            ]
        }],
        "max_tokens": 100,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
        "temperature": 0.1
    }
    
    try:
        start_time = time.time()
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            json=payload,
            timeout=60
        )
        processing_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            tokens_used = result.get("usage", {}).get("total_tokens", 0)
            
            print(f"‚úÖ OCR —Ç–µ—Å—Ç —É—Å–ø–µ—à–µ–Ω!")
            print(f"   –í—Ä–µ–º—è: {processing_time:.1f}—Å")
            print(f"   –¢–æ–∫–µ–Ω–æ–≤: {tokens_used}")
            print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {content}")
            
            return True, {
                "success": True,
                "processing_time": processing_time,
                "tokens_used": tokens_used,
                "content": content
            }
        else:
            print(f"‚ùå API –æ—à–∏–±–∫–∞: {response.status_code}")
            print(f"   –û—Ç–≤–µ—Ç: {response.text}")
            return False, {"error": f"API error {response.status_code}"}
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")
        return False, {"error": str(e)}

def create_final_report():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
    gpu_info = get_gpu_memory_info()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
    try:
        result = subprocess.run(
            ["docker", "ps", "--filter", "name=dots-ocr-minimal", "--format", "{{.Status}}"],
            capture_output=True, text=True, timeout=10
        )
        container_status = result.stdout.strip() if result.returncode == 0 else "Unknown"
    except:
        container_status = "Unknown"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ API
    api_healthy = False
    try:
        response = requests.get("http://localhost:8000/health", timeout=5)
        api_healthy = response.status_code == 200
    except:
        pass
    
    report = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "solution": "emergency_memory_solution",
        "gpu_info": gpu_info,
        "container_status": container_status,
        "api_healthy": api_healthy,
        "configuration": {
            "model": "rednote-hilab/dots.ocr",
            "max_model_len": 512,
            "gpu_memory_utilization": 0.25,
            "max_num_batched_tokens": 128,
            "optimizations": [
                "Minimal context length (512)",
                "Low GPU utilization (25%)",
                "Small batch size (128)",
                "Disabled prefix caching",
                "Disabled chunked prefill",
                "Eager execution mode"
            ]
        },
        "recommendations": []
    }
    
    if api_healthy:
        report["status"] = "SUCCESS"
        report["recommendations"].append("–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ –≤ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ")
        report["recommendations"].append("–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: streamlit run app.py")
        report["recommendations"].append("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –∏ –ø—Ä–æ—Å—Ç—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    else:
        report["status"] = "FAILED"
        report["recommendations"].append("–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞")
        report["recommendations"].append("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: docker logs dots-ocr-minimal")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    with open("emergency_memory_solution_report.json", "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    return report

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üö® –≠–ö–°–¢–†–ï–ù–ù–û–ï –†–ï–®–ï–ù–ò–ï –ü–†–û–ë–õ–ï–ú–´ –° –ü–ê–ú–Ø–¢–¨–Æ GPU")
    print("=" * 60)
    
    # 1. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
    print("\n1Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ GPU –ø–∞–º—è—Ç–∏:")
    gpu_info = get_gpu_memory_info()
    
    if gpu_info:
        print(f"   –û–±—â–∞—è –ø–∞–º—è—Ç—å: {gpu_info['total_gb']:.1f} –ì–ë")
        print(f"   –°–≤–æ–±–æ–¥–Ω–∞—è –ø–∞–º—è—Ç—å: {gpu_info['free_gb']:.1f} –ì–ë")
        print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: {gpu_info['used_gb']:.1f} –ì–ë")
        print(f"   –î–æ—Å—Ç—É–ø–Ω–æ: {gpu_info['available_percent']:.1f}%")
        
        if gpu_info['free_gb'] < 6:
            print("‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ú–∞–ª–æ —Å–≤–æ–±–æ–¥–Ω–æ–π GPU –ø–∞–º—è—Ç–∏!")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU")
    
    # 2. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
    print("\n2Ô∏è‚É£ –û—á–∏—Å—Ç–∫–∞ —Å–∏—Å—Ç–µ–º—ã:")
    stop_all_containers()
    
    # 3. –ó–∞–ø—É—Å–∫ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    print("\n3Ô∏è‚É£ –ó–∞–ø—É—Å–∫ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
    success = start_minimal_dots_ocr()
    
    if not success:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–∞–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é")
        print("üí° –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        print("   - –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ GPU –ø–∞–º—è—Ç–∏")
        print("   - –ü—Ä–æ–±–ª–µ–º—ã —Å Docker/NVIDIA runtime")
        print("   - –ö–æ–Ω—Ñ–ª–∏–∫—Ç —Å –¥—Ä—É–≥–∏–º–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏")
        return False
    
    # 4. –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
    print("\n4Ô∏è‚É£ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏:")
    ready = wait_for_model_ready(timeout=600)  # 10 –º–∏–Ω—É—Ç
    
    if not ready:
        print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –≥–æ—Ç–æ–≤–∞ –ø–æ—Å–ª–µ 10 –º–∏–Ω—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è")
        print("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: docker logs dots-ocr-minimal")
        return False
    
    # 5. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print("\n5Ô∏è‚É£ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OCR:")
    test_success, test_result = test_minimal_ocr()
    
    # 6. –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    print("\n6Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞:")
    report = create_final_report()
    
    print(f"üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: emergency_memory_solution_report.json")
    
    # 7. –ò—Ç–æ–≥–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å
    print(f"\nüìä –ò–¢–û–ì–û–í–´–ô –°–¢–ê–¢–£–°:")
    print("=" * 60)
    
    if report["status"] == "SUCCESS":
        print("üéâ –≠–ö–°–¢–†–ï–ù–ù–û–ï –†–ï–®–ï–ù–ò–ï –£–°–ü–ï–®–ù–û!")
        print("‚úÖ dots.ocr —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ")
        print("‚ö†Ô∏è –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø:")
        print("   - –ú–∞–∫—Å–∏–º—É–º 512 —Ç–æ–∫–µ–Ω–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
        print("   - –¢–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        print("   - –ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞")
        print("üí° –ó–ê–ü–£–°–ö: streamlit run app.py")
        
        if test_success:
            print(f"üß™ OCR —Ç–µ—Å—Ç: ‚úÖ –ü–†–û–®–ï–õ")
            print(f"   –í—Ä–µ–º—è: {test_result.get('processing_time', 0):.1f}—Å")
        else:
            print(f"üß™ OCR —Ç–µ—Å—Ç: ‚ùå –ù–ï –ü–†–û–®–ï–õ")
    else:
        print("‚ùå –≠–ö–°–¢–†–ï–ù–ù–û–ï –†–ï–®–ï–ù–ò–ï –ù–ï –°–†–ê–ë–û–¢–ê–õ–û")
        print("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("   1. –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É")
        print("   2. –ó–∞–∫—Ä–æ–π—Ç–µ –≤—Å–µ GPU-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
        print("   3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA")
        print("   4. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU —Ä–µ–∂–∏–º–∞")
    
    return report["status"] == "SUCCESS"

if __name__ == "__main__":
    main()