#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
"""

import requests
import base64
import time
import json
from PIL import Image, ImageDraw, ImageFont
import io
from datetime import datetime

def create_test_image():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ç–µ–∫—Å—Ç–æ–º –∏ —Ç–∞–±–ª–∏—Ü–µ–π"""
    
    # –°–æ–∑–¥–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 800x600
    img = Image.new('RGB', (800, 600), color='white')
    draw = ImageDraw.Draw(img)
    
    try:
        font_large = ImageFont.truetype("arial.ttf", 24)
        font_medium = ImageFont.truetype("arial.ttf", 16)
        font_small = ImageFont.truetype("arial.ttf", 12)
    except:
        font_large = ImageFont.load_default()
        font_medium = ImageFont.load_default()
        font_small = ImageFont.load_default()
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    draw.text((50, 30), "–¢–ï–°–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –û–§–ò–¶–ò–ê–õ–¨–ù–´–• –ü–†–û–ú–ü–¢–û–í", fill='black', font=font_large)
    
    # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
    draw.text((50, 80), "–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤.", fill='black', font=font_medium)
    draw.text((50, 110), "–ö–∞–∂–¥—ã–π –ø—Ä–æ–º–ø—Ç –¥–æ–ª–∂–µ–Ω –¥–∞–≤–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.", fill='black', font=font_medium)
    
    # –¢–∞–±–ª–∏—Ü–∞
    draw.text((50, 160), "–¢–ê–ë–õ–ò–¶–ê –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:", fill='black', font=font_medium)
    
    # –†–∏—Å—É–µ–º —Ç–∞–±–ª–∏—Ü—É
    table_x = 50
    table_y = 190
    cell_width = 120
    cell_height = 30
    
    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
    headers = ["–ü—Ä–æ–º–ø—Ç", "–°—Ç–∞—Ç—É—Å", "–¢–æ–∫–µ–Ω—ã", "–†–µ–∑—É–ª—å—Ç–∞—Ç"]
    for i, header in enumerate(headers):
        x = table_x + i * cell_width
        y = table_y
        # –†–∞–º–∫–∞
        draw.rectangle([x, y, x + cell_width, y + cell_height], outline='black', width=2)
        # –¢–µ–∫—Å—Ç
        draw.text((x + 5, y + 5), header, fill='black', font=font_small)
    
    # –î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
    data = [
        ["–ü—Ä–æ—Å—Ç–æ–µ OCR", "OK", "~800", "–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç"],
        ["–î–µ—Ç–∞–ª—å–Ω–æ–µ OCR", "OK", "~900", "–° –ø–æ—Ä—è–¥–∫–æ–º"],
        ["–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã", "OK", "~950", "HTML + Markdown"],
        ["–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü", "OK", "~1000", "–¢–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—Ü—ã"],
        ["–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ", "OK", "~850", "–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π"]
    ]
    
    for row_idx, row in enumerate(data):
        for col_idx, cell in enumerate(row):
            x = table_x + col_idx * cell_width
            y = table_y + (row_idx + 1) * cell_height
            # –†–∞–º–∫–∞
            draw.rectangle([x, y, x + cell_width, y + cell_height], outline='black', width=1)
            # –¢–µ–∫—Å—Ç
            draw.text((x + 5, y + 5), cell, fill='black', font=font_small)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
    draw.text((50, 350), "–ü—Ä–æ–≤–µ—Ä—è–µ–º—ã–µ –∞—Å–ø–µ–∫—Ç—ã:", fill='black', font=font_medium)
    draw.text((50, 380), "‚Ä¢ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –≤ vLLM API", fill='black', font=font_small)
    draw.text((50, 400), "‚Ä¢ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –ª–∏–º–∏—Ç–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤", fill='black', font=font_small)
    draw.text((50, 420), "‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤", fill='black', font=font_small)
    draw.text((50, 440), "‚Ä¢ –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤", fill='black', font=font_small)
    
    # –ü–æ–¥–ø–∏—Å—å
    draw.text((50, 500), "–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω: " + datetime.now().strftime("%Y-%m-%d %H:%M"), fill='gray', font=font_small)
    
    return img

def test_token_calculation():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
    
    print("üßÆ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –†–ê–°–ß–ï–¢–ê –¢–û–ö–ï–ù–û–í")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ vLLM
    base_url = "http://localhost:8000"
    
    try:
        response = requests.get(f"{base_url}/health", timeout=5)
        if response.status_code != 200:
            print("‚ùå vLLM —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return False
        print("‚úÖ vLLM —Å–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ vLLM: {e}")
        return False
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
    try:
        response = requests.get(f"{base_url}/v1/models", timeout=5)
        if response.status_code == 200:
            models_data = response.json()
            for model in models_data.get("data", []):
                if "dots.ocr" in model["id"]:
                    model_max_tokens = model.get("max_model_len", 1024)
                    print(f"üìä –ú–æ–¥–µ–ª—å: {model['id']}")
                    print(f"üéØ –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤: {model_max_tokens}")
                    break
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏")
            return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏: {e}")
        return False
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Ç–æ–∫–µ–Ω–æ–≤
    test_cases = [
        {"requested": 8192, "description": "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"},
        {"requested": 7500, "description": "–ë–ª–∏–∑–∫–æ –∫ –º–∞–∫—Å–∏–º—É–º—É"},
        {"requested": 4096, "description": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"},
        {"requested": 2048, "description": "–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"},
        {"requested": 1024, "description": "–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"}
    ]
    
    print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ª–∏–º–∏—Ç–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤:")
    
    for case in test_cases:
        requested = case["requested"]
        description = case["description"]
        
        # –†–∞—Å—á–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ (–∫–∞–∫ –≤ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–¥–µ)
        safe_max_tokens = min(requested, model_max_tokens - 500)  # –†–µ–∑–µ—Ä–≤ –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
        
        if safe_max_tokens < 100:
            safe_max_tokens = model_max_tokens // 2
        
        print(f"   üìù {description}:")
        print(f"      –ó–∞–ø—Ä–æ—à–µ–Ω–æ: {requested}")
        print(f"      –ë–µ–∑–æ–ø–∞—Å–Ω–æ: {safe_max_tokens}")
        print(f"      –°—Ç–∞—Ç—É—Å: {'‚úÖ OK' if safe_max_tokens > 0 else '‚ùå –û—à–∏–±–∫–∞'}")
    
    return True

def test_official_prompts_with_safe_tokens():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏"""
    
    print("\nüéØ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–§–ò–¶–ò–ê–õ–¨–ù–´–• –ü–†–û–ú–ü–¢–û–í –° –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï–ú")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print("üì∑ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    test_image = create_test_image()
    test_image.save("test_interface_fix_document.png")
    print("‚úÖ –¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ: test_interface_fix_document.png")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ base64
    buffer = io.BytesIO()
    test_image.save(buffer, format='PNG')
    image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    # –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
    official_prompts = {
        "üî§ –ü—Ä–æ—Å—Ç–æ–µ OCR": "Extract all text from this image.",
        "üìã –î–µ—Ç–∞–ª—å–Ω–æ–µ OCR": "Extract all text content from this image while maintaining reading order. Exclude headers and footers.",
        "üèóÔ∏è –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã": "Extract text, layout, and structure from this document image. Include bounding boxes, categories, and format tables as HTML, formulas as LaTeX, and text as Markdown.",
        "üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü": "Extract and format the table content from this document as structured data.",
        "üìÑ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ": "Analyze this document and extract structured information including text, tables, and layout elements."
    }
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞ –º–æ–¥–µ–ª–∏
    base_url = "http://localhost:8000"
    model_max_tokens = 8192  # –ò–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    
    results = []
    
    print(f"üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(official_prompts)} –ø—Ä–æ–º–ø—Ç–æ–≤ —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏...")
    
    for prompt_name, prompt_text in official_prompts.items():
        print(f"\n   üß™ {prompt_name}")
        
        # –†–∞—Å—á–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (–∫–∞–∫ –≤ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–¥–µ)
        requested_tokens = 4096  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        safe_max_tokens = min(requested_tokens, model_max_tokens - 500)
        
        if safe_max_tokens < 100:
            safe_max_tokens = model_max_tokens // 2
        
        print(f"      üéØ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã: {safe_max_tokens} (–ª–∏–º–∏—Ç –º–æ–¥–µ–ª–∏: {model_max_tokens})")
        
        payload = {
            "model": "rednote-hilab/dots.ocr",
            "messages": [{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt_text},
                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_base64}"}}
                ]
            }],
            "max_tokens": safe_max_tokens,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            "temperature": 0.1
        }
        
        try:
            start_time = time.time()
            
            response = requests.post(
                f"{base_url}/v1/chat/completions",
                json=payload,
                timeout=120
            )
            
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                tokens_used = result.get("usage", {}).get("total_tokens", 0)
                
                print(f"      ‚úÖ –£—Å–ø–µ—Ö: {processing_time:.1f}—Å, —Ç–æ–∫–µ–Ω–æ–≤: {tokens_used}")
                print(f"      üìÑ –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                results.append({
                    "prompt_name": prompt_name,
                    "prompt": prompt_text,
                    "success": True,
                    "processing_time": processing_time,
                    "tokens_used": tokens_used,
                    "safe_max_tokens": safe_max_tokens,
                    "response_length": len(content),
                    "response": content
                })
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 150 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞
                preview = content[:150] + "..." if len(content) > 150 else content
                print(f"      üìù –ü—Ä–µ–≤—å—é: {preview}")
                
            else:
                error_text = response.text
                print(f"      ‚ùå –û—à–∏–±–∫–∞: {response.status_code}")
                print(f"         –û—Ç–≤–µ—Ç: {error_text[:200]}...")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –æ—à–∏–±–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
                if "max_tokens" in error_text and "exceeds" in error_text:
                    print(f"      üö® –û–®–ò–ë–ö–ê –¢–û–ö–ï–ù–û–í! –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ {safe_max_tokens} –≤—Å—ë –µ—â—ë —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ")
                
                results.append({
                    "prompt_name": prompt_name,
                    "prompt": prompt_text,
                    "success": False,
                    "error": response.status_code,
                    "error_text": error_text[:200],
                    "safe_max_tokens": safe_max_tokens
                })
                
        except Exception as e:
            print(f"      ‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
            results.append({
                "prompt_name": prompt_name,
                "prompt": prompt_text,
                "success": False,
                "error": "exception",
                "error_text": str(e),
                "safe_max_tokens": safe_max_tokens
            })
    
    return results

def analyze_fix_results(results):
    """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
    
    print("\n" + "=" * 60)
    print("üìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø")
    print("=" * 60)
    
    successful_tests = [r for r in results if r["success"]]
    failed_tests = [r for r in results if not r["success"]]
    
    print(f"\nüìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {len(successful_tests)}")
    print(f"   ‚ùå –ù–µ—É–¥–∞—á–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {len(failed_tests)}")
    print(f"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {(len(successful_tests)/len(results)*100):.1f}%")
    
    if successful_tests:
        print(f"\n‚è±Ô∏è –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
        avg_time = sum(r["processing_time"] for r in successful_tests) / len(successful_tests)
        avg_tokens = sum(r["tokens_used"] for r in successful_tests) / len(successful_tests)
        avg_safe_tokens = sum(r["safe_max_tokens"] for r in successful_tests) / len(successful_tests)
        
        print(f"   ‚è±Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time:.1f}—Å")
        print(f"   üéØ –°—Ä–µ–¥–Ω–∏–µ —Ç–æ–∫–µ–Ω—ã: {avg_tokens:.0f}")
        print(f"   üõ°Ô∏è –°—Ä–µ–¥–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã: {avg_safe_tokens:.0f}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–æ–≤
    if len(successful_tests) > 1:
        print(f"\nüîç –ê–ù–ê–õ–ò–ó –£–ù–ò–ö–ê–õ–¨–ù–û–°–¢–ò –û–¢–í–ï–¢–û–í:")
        
        responses = [r["response"] for r in successful_tests]
        unique_responses = set(responses)
        
        print(f"   üìä –í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤: {len(responses)}")
        print(f"   üéØ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {len(unique_responses)}")
        
        if len(unique_responses) == 1:
            print("   ‚ùå –í–°–ï –û–¢–í–ï–¢–´ –û–î–ò–ù–ê–ö–û–í–´–ï! –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ –ø–æ–º–æ–≥–ª–æ!")
        elif len(unique_responses) == len(responses):
            print("   ‚úÖ –í–°–ï –û–¢–í–ï–¢–´ –£–ù–ò–ö–ê–õ–¨–ù–´–ï! –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
        else:
            print(f"   ‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã: {len(unique_responses)}/{len(responses)}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—à–∏–±–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤
    token_errors = [r for r in failed_tests if "max_tokens" in r.get("error_text", "")]
    if token_errors:
        print(f"\nüö® –û–®–ò–ë–ö–ò –¢–û–ö–ï–ù–û–í:")
        print(f"   ‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤: {len(token_errors)}")
        print("   üí° –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–∞–ª—å–Ω–µ–π—à–µ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤")
    else:
        print(f"\n‚úÖ –¢–û–ö–ï–ù–´:")
        print("   ‚úÖ –ù–µ—Ç –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤!")
        print("   üéØ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    report_data = {
        "timestamp": datetime.now().isoformat(),
        "test_type": "interface_fix_verification",
        "test_results": results,
        "summary": {
            "total_tests": len(results),
            "successful_tests": len(successful_tests),
            "failed_tests": len(failed_tests),
            "success_rate": (len(successful_tests)/len(results)*100) if results else 0,
            "unique_responses": len(set(r["response"] for r in successful_tests)) if successful_tests else 0,
            "token_errors": len(token_errors),
            "fix_status": "SUCCESS" if len(successful_tests) > 0 and len(token_errors) == 0 else "NEEDS_WORK"
        }
    }
    
    with open("official_prompts_interface_fix_test.json", "w", encoding="utf-8") as f:
        json.dump(report_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìÑ –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: official_prompts_interface_fix_test.json")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    print(f"\nüéØ –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:")
    
    if len(successful_tests) == len(results) and len(token_errors) == 0:
        print("   üéâ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ü–û–õ–ù–û–°–¢–¨–Æ –£–°–ü–ï–®–ù–û!")
        print("   ‚úÖ –í—Å–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç")
        print("   ‚úÖ –ù–µ—Ç –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤")
        print("   ‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
    elif len(successful_tests) > 0 and len(token_errors) == 0:
        print("   ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –í –û–°–ù–û–í–ù–û–ú –£–°–ü–ï–®–ù–û")
        print(f"   ‚úÖ {len(successful_tests)}/{len(results)} –ø—Ä–æ–º–ø—Ç–æ–≤ —Ä–∞–±–æ—Ç–∞—é—Ç")
        print("   ‚úÖ –ù–µ—Ç –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤")
    elif len(token_errors) > 0:
        print("   ‚ö†Ô∏è –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ß–ê–°–¢–ò–ß–ù–û –£–°–ü–ï–®–ù–û")
        print(f"   ‚ùå –û—Å—Ç–∞–ª–∏—Å—å –æ—à–∏–±–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤: {len(token_errors)}")
        print("   üí° –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–∞–ª—å–Ω–µ–π—à–µ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤")
    else:
        print("   ‚ùå –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ù–ï –ü–û–ú–û–ì–õ–û")
        print("   üö® –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üîß –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –û–§–ò–¶–ò–ê–õ–¨–ù–´–• –ü–†–û–ú–ü–¢–û–í")
    print("=" * 60)
    print(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
    if not test_token_calculation():
        return
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    results = test_official_prompts_with_safe_tokens()
    if results:
        analyze_fix_results(results)

if __name__ == "__main__":
    main()