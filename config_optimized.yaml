# ChatVLMLLM Configuration - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è RTX 5070 Ti (12.82GB VRAM)

models:
  # –õ–µ–≥–∫–∏–µ OCR –º–æ–¥–µ–ª–∏ (–±—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)
  deepseek_ocr:
    name: "DeepSeek OCR"
    description: "–õ–µ–≥–∫–∞—è OCR –º–æ–¥–µ–ª—å –æ—Ç DeepSeek"
    model_path: "deepseek-ai/deepseek-ocr"
    model_type: "ocr"
    max_length: 4096
    precision: "fp16"
    device_map: "auto"
    trust_remote_code: true
    use_flash_attention: false
    # VRAM: FP16=0.01GB, Recommended=1GB
    
  got_ocr_hf:
    name: "GOT-OCR 2.0 (HF)"
    description: "HuggingFace –≤–µ—Ä—Å–∏—è GOT-OCR"
    model_path: "stepfun-ai/GOT-OCR-2.0-hf"
    model_type: "ocr"
    max_length: 4096
    precision: "fp16"
    device_map: "auto"
    trust_remote_code: true
    use_flash_attention: false
    ocr_type: "format"
    ocr_color: ""
    # VRAM: FP16=1.1GB, INT8=0.8GB, Recommended=2GB

  got_ocr_ucas:
    name: "GOT-OCR 2.0 (UCAS)"
    description: "–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è GOT-OCR"
    model_path: "ucaslcl/GOT-OCR2_0"
    model_type: "ocr"
    max_length: 4096
    precision: "fp16"
    device_map: "auto"
    trust_remote_code: true
    use_flash_attention: false
    ocr_type: "format"
    ocr_color: ""
    # VRAM: FP16=2.7GB, INT8=1.8GB, Recommended=3GB

  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ VLM –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–∞—à–µ–π GPU
  qwen3_vl_2b:
    name: "Qwen3-VL 2B"
    description: "–ù–æ–≤–µ–π—à–∞—è VLM —Å OCR –Ω–∞ 32 —è–∑—ã–∫–∞—Ö –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–º –∞–≥–µ–Ω—Ç–æ–º"
    model_path: "Qwen/Qwen3-VL-2B-Instruct"
    model_type: "vlm"
    max_length: 4096
    precision: "fp16"
    device_map: "auto"
    trust_remote_code: true
    use_flash_attention: false
    min_pixels: 256
    max_pixels: 1280
    # VRAM: FP16=4.4GB, INT8=2.2GB, Recommended=6GB
    # Features: 32 languages OCR, 256K context, visual agent, spatial perception
  
  qwen_vl_2b:
    name: "Qwen2-VL 2B"
    description: "–õ–µ–≥–∫–∞—è VLM –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
    model_path: "Qwen/Qwen2-VL-2B-Instruct"
    model_type: "vlm"
    max_length: 4096
    precision: "fp16"
    device_map: "auto"
    trust_remote_code: true
    use_flash_attention: false
    min_pixels: 256
    max_pixels: 1280
    # VRAM: FP16=4.7GB, INT8=3.6GB, Recommended=6GB

  phi3_vision:
    name: "Phi-3.5 Vision"
    description: "–ú–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å Microsoft –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"
    model_path: "microsoft/Phi-3.5-vision-instruct"
    model_type: "vlm"
    max_length: 4096
    precision: "fp16"
    device_map: "auto"
    trust_remote_code: true
    use_flash_attention: false
    min_pixels: 256
    max_pixels: 1280
    # VRAM: FP16=7.7GB, INT8=4.5GB, Recommended=8GB

  dots_ocr:
    name: "dots.ocr"
    description: "SOTA –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (1.7B, 100+ —è–∑—ã–∫–æ–≤)"
    model_path: "rednote-hilab/dots.ocr"
    model_type: "document_parser"
    max_length: 4096
    precision: "bf16"
    device_map: "auto"
    trust_remote_code: true
    use_flash_attention: false
    prompt_mode: "layout_all"
    max_new_tokens: 24000
    # VRAM: BF16=8GB, INT8=6GB, Recommended=10GB

  qwen3_vl_4b:
    name: "Qwen3-VL 4B"
    description: "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è Qwen3-VL —Å SOTA –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é"
    model_path: "Qwen/Qwen3-VL-4B-Instruct"
    model_type: "vlm"
    max_length: 4096
    precision: "fp16"
    device_map: "auto"
    trust_remote_code: true
    use_flash_attention: false
    min_pixels: 256
    max_pixels: 1280
    # VRAM: FP16=8.9GB, INT8=3.8GB, INT4=3GB, Recommended=10GB

  # –ò–°–ö–õ–Æ–ß–ï–ù–´ –¢–Ø–ñ–ï–õ–´–ï –ú–û–î–ï–õ–ò (>12GB VRAM):
  # qwen_vl_7b: 16.1GB - —Å–ª–∏—à–∫–æ–º —Ç—è–∂–µ–ª–∞—è
  # qwen3_vl_8b: 17.6GB - —Å–ª–∏—à–∫–æ–º —Ç—è–∂–µ–ª–∞—è

ocr:
  supported_formats: ["jpg", "jpeg", "png", "bmp", "tiff"]
  max_image_size: 10485760
  resize_max_dimension: 2048
  enable_preprocessing: true
  preprocessing_steps: ["resize", "normalize", "enhance"]
  
document_templates:
  passport:
    name: "Passport"
    fields: ["document_number", "surname", "given_names", "nationality", 
             "date_of_birth", "sex", "place_of_birth", "date_of_issue", 
             "date_of_expiry", "authority"]
  invoice:
    name: "Invoice"
    fields: ["invoice_number", "date", "seller_name", "seller_address",
             "buyer_name", "buyer_address", "items", "subtotal", "tax", "total_amount"]
  receipt:
    name: "Receipt"
    fields: ["store_name", "store_address", "date", "time", "items",
             "subtotal", "tax", "total", "payment_method"]

app:
  title: "ChatVLMLLM - –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —á–∞—Ç —Å VLM"
  page_icon: "üî¨"
  layout: "wide"
  theme: "light"
  
cache:
  enable: true
  directory: ".cache/app"
  max_age_seconds: 3600
  
export:
  default_format: "json"
  formats: ["json", "csv", "txt"]
  include_metadata: true
  
logging:
  level: "INFO"
  file: "logs/chatvlmllm.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
performance:
  enable_flash_attention: false  # –û—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è Windows
  use_int8_quantization: false
  optimize_memory: true
  max_batch_size: 2  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM
  inference_timeout: 30

# GPU Requirements –¥–ª—è RTX 5070 Ti (12.82GB VRAM)
gpu_requirements:
  current_gpu:
    name: "RTX 5070 Ti"
    vram_gb: 12.82
    recommended_models: ["qwen3_vl_2b", "qwen_vl_2b", "phi3_vision", "dots_ocr"]
    light_models: ["deepseek_ocr", "got_ocr_hf", "got_ocr_ucas"]
    max_model: "qwen3_vl_4b"  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —ç—Ç–æ–π GPU
  
  optimization:
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
    single_model_mode: true  # –ó–∞–≥—Ä—É–∂–∞—Ç—å –ø–æ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
    auto_unload: true        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–≥—Ä—É–∂–∞—Ç—å –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ
    prefer_int8: false       # FP16 –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —ç—Ç–æ–π GPU
    batch_size: 1           # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é