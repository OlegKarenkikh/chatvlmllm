#!/usr/bin/env python3
"""
–†–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–∂–µ –∑–∞–ø—É—â–µ–Ω–Ω–æ–π dots.ocr –≤ vLLM
"""

import json
import subprocess
import requests
from datetime import datetime

def get_current_vllm_status():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ vLLM"""
    
    print("üîç –ê–ù–ê–õ–ò–ó –¢–ï–ö–£–©–ï–ì–û –°–û–°–¢–û–Ø–ù–ò–Ø vLLM")
    print("=" * 45)
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞
        health_response = requests.get("http://localhost:8000/health", timeout=5)
        if health_response.status_code == 200:
            print("‚úÖ vLLM —Å–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç")
        else:
            print("‚ùå vLLM —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return None
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª—è—Ö
        models_response = requests.get("http://localhost:8000/v1/models", timeout=5)
        if models_response.status_code == 200:
            models_data = models_response.json()
            
            for model in models_data.get("data", []):
                print(f"üìä –ú–æ–¥–µ–ª—å: {model['id']}")
                print(f"   üìè –¢–µ–∫—É—â–∏–π –ª–∏–º–∏—Ç: {model.get('max_model_len', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} —Ç–æ–∫–µ–Ω–æ–≤")
                print(f"   üìÖ –°–æ–∑–¥–∞–Ω–∞: {model.get('created', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
                
            return models_data
        else:
            print("‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª—è—Ö")
            return None
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ vLLM: {e}")
        return None

def get_gpu_memory_info():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU –ø–∞–º—è—Ç–∏"""
    
    print("\nüîç –ê–ù–ê–õ–ò–ó –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø GPU –ü–ê–ú–Ø–¢–ò")
    print("=" * 45)
    
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.total,memory.used,memory.free', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            
            for i, line in enumerate(lines):
                parts = line.split(', ')
                if len(parts) == 3:
                    total_mb = int(parts[0])
                    used_mb = int(parts[1])
                    free_mb = int(parts[2])
                    
                    print(f"GPU {i}:")
                    print(f"  üìä –û–±—â–∞—è –ø–∞–º—è—Ç—å: {total_mb} MB ({total_mb/1024:.2f} GB)")
                    print(f"  üî¥ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: {used_mb} MB ({used_mb/1024:.2f} GB)")
                    print(f"  üü¢ –°–≤–æ–±–æ–¥–Ω–æ: {free_mb} MB ({free_mb/1024:.2f} GB)")
                    print(f"  üìà –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è: {(used_mb/total_mb)*100:.1f}%")
                    
                    return {
                        'total_mb': total_mb,
                        'used_mb': used_mb,
                        'free_mb': free_mb,
                        'total_gb': total_mb / 1024,
                        'used_gb': used_mb / 1024,
                        'free_gb': free_mb / 1024,
                        'utilization_percent': (used_mb/total_mb)*100
                    }
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è GPU –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")
    
    return None

def calculate_optimal_tokens_for_running_model(gpu_info, current_max_tokens=1024):
    """–†–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É–∂–µ –∑–∞–ø—É—â–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    
    print(f"\nüßÆ –†–ê–°–ß–ï–¢ –û–ü–¢–ò–ú–ê–õ–¨–ù–û–ì–û –ö–û–õ–ò–ß–ï–°–¢–í–ê –¢–û–ö–ï–ù–û–í")
    print("=" * 55)
    
    if not gpu_info:
        print("‚ùå –ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU")
        return None
    
    # –¢–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤–∫–ª—é—á–∞–µ—Ç –º–æ–¥–µ–ª—å + KV cache –¥–ª—è —Ç–µ–∫—É—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤
    current_model_memory_gb = gpu_info['used_gb']
    available_memory_gb = gpu_info['free_gb']
    total_memory_gb = gpu_info['total_gb']
    
    print(f"üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:")
    print(f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: {current_model_memory_gb:.2f} GB")
    print(f"  ‚Ä¢ –î–æ—Å—Ç—É–ø–Ω–æ: {available_memory_gb:.2f} GB")
    print(f"  ‚Ä¢ –û–±—â–∞—è –ø–∞–º—è—Ç—å: {total_memory_gb:.2f} GB")
    print(f"  ‚Ä¢ –¢–µ–∫—É—â–∏–π –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤: {current_max_tokens:,}")
    
    # –û—Ü–µ–Ω–∫–∞ –ø–∞–º—è—Ç–∏ –Ω–∞ —Ç–æ–∫–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Vision-Language –º–æ–¥–µ–ª–∏
    # –î–ª—è dots.ocr (–æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ Qwen2-VL –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ)
    model_config = {
        'hidden_size': 1536,        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π
        'num_layers': 28,           # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤
        'precision_bytes': 2,       # fp16 = 2 –±–∞–π—Ç–∞
    }
    
    # KV cache –ø–∞–º—è—Ç—å –Ω–∞ —Ç–æ–∫–µ–Ω = 2 (K + V) * num_layers * hidden_size * precision_bytes
    memory_per_token_bytes = (
        2 * model_config['num_layers'] * 
        model_config['hidden_size'] * 
        model_config['precision_bytes']
    )
    
    memory_per_token_mb = memory_per_token_bytes / (1024 * 1024)
    memory_per_token_gb = memory_per_token_bytes / (1024 ** 3)
    
    print(f"\nüíæ –ü–∞–º—è—Ç—å –Ω–∞ —Ç–æ–∫–µ–Ω:")
    print(f"  ‚Ä¢ {memory_per_token_mb:.3f} MB –Ω–∞ —Ç–æ–∫–µ–Ω")
    print(f"  ‚Ä¢ {memory_per_token_bytes:,} –±–∞–π—Ç –Ω–∞ —Ç–æ–∫–µ–Ω")
    
    # –†–∞—Å—á–µ—Ç –ø–∞–º—è—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–π —Ç–µ–∫—É—â–∏–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏
    current_tokens_memory_gb = current_max_tokens * memory_per_token_gb
    
    # –ë–∞–∑–æ–≤–∞—è –ø–∞–º—è—Ç—å –º–æ–¥–µ–ª–∏ (–±–µ–∑ KV cache)
    base_model_memory_gb = current_model_memory_gb - current_tokens_memory_gb
    
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:")
    print(f"  ‚Ä¢ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {base_model_memory_gb:.2f} GB")
    print(f"  ‚Ä¢ KV cache ({current_max_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤): {current_tokens_memory_gb:.2f} GB")
    
    # –†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—é –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å + –æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ KV cache
    total_available_for_tokens_gb = available_memory_gb + current_tokens_memory_gb
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    safety_factor = 0.9  # 90% –æ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏
    safe_memory_for_tokens_gb = total_available_for_tokens_gb * safety_factor
    
    max_tokens_theoretical = int(safe_memory_for_tokens_gb / memory_per_token_gb)
    
    # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    token_options = [1024, 2048, 4096, 8192, 16384, 32768]
    optimal_tokens = max([t for t in token_options if t <= max_tokens_theoretical], default=1024)
    
    print(f"\nüßÆ –†–∞—Å—á–µ—Ç—ã:")
    print(f"  ‚Ä¢ –î–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤: {total_available_for_tokens_gb:.2f} GB")
    print(f"  ‚Ä¢ –° –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {safe_memory_for_tokens_gb:.2f} GB")
    print(f"  ‚Ä¢ –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–π –º–∞–∫—Å–∏–º—É–º: {max_tokens_theoretical:,} —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"  ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {optimal_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
    new_tokens_memory_gb = optimal_tokens * memory_per_token_gb
    total_memory_usage_gb = base_model_memory_gb + new_tokens_memory_gb
    final_utilization = (total_memory_usage_gb / total_memory_gb) * 100
    
    print(f"\nüìä –ü—Ä–æ–≥–Ω–æ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –ø—Ä–∏ {optimal_tokens:,} —Ç–æ–∫–µ–Ω–∞—Ö:")
    print(f"  ‚Ä¢ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {base_model_memory_gb:.2f} GB")
    print(f"  ‚Ä¢ KV cache: {new_tokens_memory_gb:.2f} GB")
    print(f"  ‚Ä¢ –û–±—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {total_memory_usage_gb:.2f} GB")
    print(f"  ‚Ä¢ –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU: {final_utilization:.1f}%")
    print(f"  ‚Ä¢ –°–≤–æ–±–æ–¥–Ω–æ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è: {total_memory_gb - total_memory_usage_gb:.2f} GB")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º
    improvement_factor = optimal_tokens / current_max_tokens
    
    print(f"\nüìà –£–ª—É—á—à–µ–Ω–∏—è:")
    print(f"  ‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –≤ {improvement_factor:.1f} —Ä–∞–∑")
    print(f"  ‚Ä¢ –° {current_max_tokens:,} –¥–æ {optimal_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"  ‚Ä¢ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å: {new_tokens_memory_gb - current_tokens_memory_gb:.2f} GB")
    
    return {
        'current_tokens': current_max_tokens,
        'recommended_tokens': optimal_tokens,
        'improvement_factor': improvement_factor,
        'memory_per_token_gb': memory_per_token_gb,
        'base_model_memory_gb': base_model_memory_gb,
        'new_tokens_memory_gb': new_tokens_memory_gb,
        'total_memory_usage_gb': total_memory_usage_gb,
        'final_utilization_percent': final_utilization,
        'theoretical_max': max_tokens_theoretical
    }

def create_restart_command(optimal_tokens):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏"""
    
    print(f"\nüîß –ö–û–ú–ê–ù–î–´ –î–õ–Ø –ü–ï–†–ï–ó–ê–ü–£–°–ö–ê –° –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ú–ò –¢–û–ö–ï–ù–ê–ú–ò")
    print("=" * 65)
    
    # –ö–æ–º–∞–Ω–¥–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    stop_commands = [
        "# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞",
        "docker-compose -f docker-compose-vllm.yml down",
        "",
        "# –ò–ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ –∏–º–µ–Ω–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞",
        "docker stop dots-ocr-vllm 2>/dev/null || true",
        "docker rm dots-ocr-vllm 2>/dev/null || true"
    ]
    
    # –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    start_command = f"""# –ó–∞–ø—É—Å–∫ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
docker run -d \\
  --name dots-ocr-vllm-optimized \\
  --gpus all \\
  -p 8000:8000 \\
  -v ~/.cache/huggingface:/root/.cache/huggingface \\
  -e CUDA_VISIBLE_DEVICES=0 \\
  vllm/vllm-openai:latest \\
  --model rednote-hilab/dots.ocr \\
  --host 0.0.0.0 \\
  --port 8000 \\
  --max-model-len {optimal_tokens['recommended_tokens']} \\
  --gpu-memory-utilization 0.90 \\
  --dtype float16 \\
  --trust-remote-code \\
  --disable-log-requests"""
    
    # Docker Compose –≤–µ—Ä—Å–∏—è
    docker_compose_optimized = f"""version: '3.8'

services:
  dots-ocr-optimized:
    image: vllm/vllm-openai:latest
    container_name: dots-ocr-vllm-optimized
    ports:
      - "8000:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - VLLM_WORKER_MULTIPROC_METHOD=spawn
    command: >
      --model rednote-hilab/dots.ocr
      --host 0.0.0.0
      --port 8000
      --max-model-len {optimal_tokens['recommended_tokens']}
      --gpu-memory-utilization 0.90
      --dtype float16
      --trust-remote-code
      --disable-log-requests
      --served-model-name rednote-hilab/dots.ocr
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
"""
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    with open("docker-compose-vllm-optimized.yml", "w", encoding="utf-8") as f:
        f.write(docker_compose_optimized)
    
    # –°–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
    restart_script = f"""#!/bin/bash
# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ dots.ocr vLLM —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏

echo "üîÑ –ü–ï–†–ï–ó–ê–ü–£–°–ö dots.ocr vLLM –° –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ú–ò –¢–û–ö–ï–ù–ê–ú–ò"
echo "üìä –ù–æ–≤—ã–π –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤: {optimal_tokens['recommended_tokens']:,}"
echo "üìà –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤ {optimal_tokens['improvement_factor']:.1f} —Ä–∞–∑"
echo "üíæ –û–∂–∏–¥–∞–µ–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {optimal_tokens['total_memory_usage_gb']:.2f} GB"

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
echo "üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞..."
docker-compose -f docker-compose-vllm.yml down 2>/dev/null || true
docker stop dots-ocr-vllm 2>/dev/null || true
docker rm dots-ocr-vllm 2>/dev/null || true

# –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è GPU –ø–∞–º—è—Ç–∏
echo "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è GPU –ø–∞–º—è—Ç–∏..."
sleep 5

# –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
echo "üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞..."
docker-compose -f docker-compose-vllm-optimized.yml up -d

# –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
echo "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã)..."
sleep 60

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
echo "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞..."
if curl -s http://localhost:8000/health >/dev/null; then
    echo "‚úÖ –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤!"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤—ã—Ö –ª–∏–º–∏—Ç–æ–≤
    echo "üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤..."
    curl -s http://localhost:8000/v1/models | python -c "
import sys, json
data = json.load(sys.stdin)
for model in data.get('data', []):
    print(f'üéØ –ú–æ–¥–µ–ª—å: {{model[\"id\"]}}')
    print(f'üìè –õ–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤: {{model.get(\"max_model_len\", \"–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ\"):,}}')
"
    
    echo "üéâ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!"
    echo "üí° –¢–µ–ø–µ—Ä—å dots.ocr –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ {optimal_tokens['recommended_tokens']:,} —Ç–æ–∫–µ–Ω–æ–≤"
else
    echo "‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"
    echo "üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: docker-compose -f docker-compose-vllm-optimized.yml logs"
fi
"""
    
    with open("restart_vllm_optimized.sh", "w", encoding="utf-8") as f:
        f.write(restart_script)
    
    # Windows batch –≤–µ—Ä—Å–∏—è
    batch_script = f"""@echo off
REM –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ dots.ocr vLLM —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏

echo üîÑ –ü–ï–†–ï–ó–ê–ü–£–°–ö dots.ocr vLLM –° –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ú–ò –¢–û–ö–ï–ù–ê–ú–ò
echo üìä –ù–æ–≤—ã–π –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤: {optimal_tokens['recommended_tokens']:,}
echo üìà –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤ {optimal_tokens['improvement_factor']:.1f} —Ä–∞–∑
echo üíæ –û–∂–∏–¥–∞–µ–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {optimal_tokens['total_memory_usage_gb']:.2f} GB

REM –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
echo üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞...
docker-compose -f docker-compose-vllm.yml down >nul 2>&1
docker stop dots-ocr-vllm >nul 2>&1
docker rm dots-ocr-vllm >nul 2>&1

REM –ü–∞—É–∑–∞ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è GPU –ø–∞–º—è—Ç–∏
echo ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è GPU –ø–∞–º—è—Ç–∏...
timeout /t 5 /nobreak >nul

REM –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
echo üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞...
docker-compose -f docker-compose-vllm-optimized.yml up -d

REM –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
echo ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã)...
timeout /t 60 /nobreak >nul

REM –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
echo üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞...
curl -s http://localhost:8000/health >nul
if %errorlevel% == 0 (
    echo ‚úÖ –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤!
    echo üéâ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!
    echo üí° –¢–µ–ø–µ—Ä—å dots.ocr –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ {optimal_tokens['recommended_tokens']:,} —Ç–æ–∫–µ–Ω–æ–≤
) else (
    echo ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞
    echo üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: docker-compose -f docker-compose-vllm-optimized.yml logs
)

pause
"""
    
    with open("restart_vllm_optimized.bat", "w", encoding="utf-8") as f:
        f.write(batch_script)
    
    print("‚úÖ –°–æ–∑–¥–∞–Ω—ã —Ñ–∞–π–ª—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
    print("  ‚Ä¢ docker-compose-vllm-optimized.yml")
    print("  ‚Ä¢ restart_vllm_optimized.sh (Linux/Mac)")
    print("  ‚Ä¢ restart_vllm_optimized.bat (Windows)")
    
    print(f"\nüöÄ –ö–û–ú–ê–ù–î–´ –î–õ–Ø –ü–ï–†–ï–ó–ê–ü–£–°–ö–ê:")
    print("  Linux/Mac:")
    print("    chmod +x restart_vllm_optimized.sh")
    print("    ./restart_vllm_optimized.sh")
    print("  Windows:")
    print("    restart_vllm_optimized.bat")
    print("  Docker Compose:")
    print("    docker-compose -f docker-compose-vllm-optimized.yml up -d")
    
    return {
        'docker_compose_file': 'docker-compose-vllm-optimized.yml',
        'restart_script_linux': 'restart_vllm_optimized.sh',
        'restart_script_windows': 'restart_vllm_optimized.bat'
    }

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üßÆ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –¢–û–ö–ï–ù–û–í –î–õ–Ø –ó–ê–ü–£–©–ï–ù–ù–û–ô dots.ocr vLLM")
    print("=" * 65)
    print(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 65)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ vLLM
    vllm_status = get_current_vllm_status()
    if not vllm_status:
        print("‚ùå vLLM —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
    current_max_tokens = 1024  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    for model in vllm_status.get("data", []):
        current_max_tokens = model.get("max_model_len", 1024)
        break
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU
    gpu_info = get_gpu_memory_info()
    if not gpu_info:
        print("‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU")
        return
    
    # –†–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
    optimal_tokens = calculate_optimal_tokens_for_running_model(gpu_info, current_max_tokens)
    if not optimal_tokens:
        print("‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã")
        return
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
    restart_info = create_restart_command(optimal_tokens)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    report = {
        'timestamp': datetime.now().isoformat(),
        'current_status': {
            'vllm_running': True,
            'current_max_tokens': current_max_tokens,
            'gpu_info': gpu_info
        },
        'optimization_results': optimal_tokens,
        'restart_files': restart_info,
        'summary': {
            'current_tokens': current_max_tokens,
            'recommended_tokens': optimal_tokens['recommended_tokens'],
            'improvement_factor': optimal_tokens['improvement_factor'],
            'memory_usage_gb': optimal_tokens['total_memory_usage_gb'],
            'gpu_utilization_percent': optimal_tokens['final_utilization_percent']
        }
    }
    
    with open("vllm_optimization_report.json", "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 65)
    print("üéâ –ê–ù–ê–õ–ò–ó –ò –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–´!")
    print("=" * 65)
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
    print(f"  ‚Ä¢ –¢–µ–∫—É—â–∏–π –ª–∏–º–∏—Ç: {current_max_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"  ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ª–∏–º–∏—Ç: {optimal_tokens['recommended_tokens']:,} —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"  ‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤ {optimal_tokens['improvement_factor']:.1f} —Ä–∞–∑")
    print(f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {optimal_tokens['total_memory_usage_gb']:.2f} GB")
    print(f"  ‚Ä¢ –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU: {optimal_tokens['final_utilization_percent']:.1f}%")
    
    if optimal_tokens['recommended_tokens'] > current_max_tokens:
        print(f"\nüöÄ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –ü–ï–†–ï–ó–ê–ü–£–°–¢–ò–¢–¨ –° –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ú–ò –¢–û–ö–ï–ù–ê–ú–ò")
        print(f"  –ö–æ–º–∞–Ω–¥–∞: ./restart_vllm_optimized.sh")
        print(f"  –û–∂–∏–¥–∞–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:")
        print(f"    ‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        print(f"    ‚Ä¢ –ë–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã")
        print(f"    ‚Ä¢ –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ OCR")
        print(f"    ‚Ä¢ –ù–µ—Ç –æ—à–∏–±–æ–∫ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤")
    else:
        print(f"\n‚úÖ –¢–ï–ö–£–©–ò–ï –ù–ê–°–¢–†–û–ô–ö–ò –£–ñ–ï –û–ü–¢–ò–ú–ê–õ–¨–ù–´")
        print(f"  –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
    
    print(f"\nüìÑ –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç: vllm_optimization_report.json")

if __name__ == "__main__":
    main()