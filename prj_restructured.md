**ДЕПАРТАМЕНТ ОБРАЗОВАНИЯ И НАУКИ ГОРОДА МОСКВЫ**

**ГОСУДАРСТВЕННОЕ БЮДЖЕТНОЕ ОБЩЕОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ ГОРОДА МОСКВЫ «ШКОЛА № 1474»**

# CHATVLMLLM - СИСТЕМА РАСПОЗНАВАНИЯ ДОКУМЕНТОВ НА БАЗЕ VISION-LANGUAGE МОДЕЛЕЙ

Участник:
Ученик 10 «Н» класса ГБОУ Школа №1474
Кареньких Владимир Олегович

Руководитель:
педагог ГБОУ Школа № 1474
Василенок Алиса Андреевна

**Москва, 2026**

---

## Оглавление

**Введение** ............................................................. 3
**Цель проекта** ......................................................... 3
**Актуальность** ......................................................... 4
**Проблематика** ......................................................... 4
**Задачи** ............................................................... 5
**Анализ существующих аналогов** ......................................... 6

**Глава I. Теоретические основы Vision-Language моделей** ............... 7
1.1. Основные принципы работы VLM моделей ............................... 7
1.2. Архитектура трансформеров для мультимодальных задач ................ 8
1.3. Функционал системы ChatVLMLLM ...................................... 9
1.4. Преимущества локального развертывания .............................. 10
1.5. Недостатки и ограничения ........................................... 11

**Глава II. Процесс разработки системы** ................................ 12
2.1. Исследование и выбор моделей ....................................... 12
2.2. Создание модульной архитектуры ..................................... 14
2.3. Разработка системы управления памятью GPU ......................... 16
2.4. Реализация веб-интерфейса на Streamlit ............................ 18
2.5. Создание REST API на FastAPI ....................................... 20
2.6. Разработка системы предобработки изображений ...................... 22
2.7. Реализация постобработки результатов OCR .......................... 24
2.8. Создание системы извлечения структурированных данных .............. 26
2.9. Интеграция моделей и тестирование .................................. 28
2.10. Оптимизация производительности для RTX 5070 Ti ................... 30
2.11. База данных и кеширование ......................................... 32

**Глава III. Тестирование и отладка системы** .......................... 34
3.1. Исправление ошибок распознавания текста ........................... 34
3.2. Отладка проблем с памятью GPU ...................................... 36
3.3. Устранение ошибок интерфейса ....................................... 38

**Заключение** ........................................................... 40
**Список используемых источников** ...................................... 41

---

## Введение

В эпоху цифровой трансформации автоматизация обработки документов становится критически важной задачей для организаций всех уровней. Ежедневно компании, государственные учреждения и образовательные организации обрабатывают тысячи документов различных форматов - от паспортов и водительских удостоверений до счетов и договоров.

Традиционные методы ручной обработки документов требуют значительных временных и человеческих ресурсов, при этом подвержены ошибкам и не масштабируются при росте объемов данных. Современные облачные решения для распознавания документов, хотя и обеспечивают высокую точность, создают серьезные риски утечки конфиденциальной информации.

Революционное развитие технологий искусственного интеллекта, особенно Vision-Language моделей (VLM), открывает новые возможности для создания интеллектуальных систем обработки документов с локальным развертыванием, обеспечивающих как высокую точность распознавания, так и полную конфиденциальность данных.

## Цель проекта

Разработать и реализовать систему автоматического распознавания и интеллектуального анализа документов ChatVLMLLM на базе современных Vision-Language моделей с полностью локальным развертыванием, обеспечивающую:

- Высокую точность OCR (не менее 88%)
- Автоматическое извлечение структурированных данных
- Полную конфиденциальность обработки информации
- Оптимальное использование доступных вычислительных ресурсов
- Простоту интеграции в существующие корпоративные системы
## Актуальность

По данным исследований IDC, объем неструктурированных данных в мире удваивается каждые два года, при этом до 80% корпоративной информации содержится в документах различных форматов. В России рынок систем распознавания документов оценивается в 2.5 млрд рублей и растет на 15-20% ежегодно.

Особую актуальность проект приобретает в контексте:

**Требований информационной безопасности:** Федеральный закон "О персональных данных" (152-ФЗ) и отраслевые стандарты требуют обеспечения конфиденциальности при обработке документов, содержащих персональные данные.

**Импортозамещения:** В условиях технологических ограничений критически важно иметь решения, основанные на открытых технологиях и не зависящие от зарубежных поставщиков.

**Цифровизации образования:** Школы и университеты нуждаются в эффективных инструментах для автоматизации документооборота при ограниченных бюджетах на IT-решения.

## Проблематика

Анализ существующих решений выявил ряд критических проблем:

**Проблемы конфиденциальности:** Большинство высокоточных решений (Google Cloud Vision API, Amazon Textract) требуют передачи документов во внешние облачные системы, что создает неприемлемые риски для организаций, работающих с конфиденциальной информацией.

**Экономические барьеры:** Коммерческие решения требуют значительных инвестиций (от $10,000 до $100,000+ в год), а облачные API взимают плату за каждый документ, что неэффективно для организаций с большими объемами.

**Технологические ограничения:** Традиционные OCR-системы распознают только "сырой" текст без понимания структуры документа и не способны адаптироваться к новым форматам без дополнительного программирования.

**Сложность внедрения:** Существующие решения требуют глубоких технических знаний и месяцы на настройку под специфические типы документов.
## Задачи

Для достижения поставленной цели определены следующие задачи:

**1. Исследовательские задачи:**
- Провести сравнительный анализ современных VLM моделей (Qwen2-VL, Qwen3-VL, GOT-OCR, dots.ocr, Phi-3.5 Vision)
- Выполнить бенчмаркинг производительности на различных типах документов
- Исследовать методы оптимизации для ограниченных вычислительных ресурсов

**2. Архитектурные задачи:**
- Спроектировать модульную архитектуру с унифицированным интерфейсом
- Реализовать систему управления памятью GPU с автоматической выгрузкой моделей
- Обеспечить масштабируемость для интеграции новых моделей

**3. Технические задачи разработки:**
- Создать веб-интерфейс на Streamlit для конечных пользователей
- Реализовать REST API на FastAPI для программной интеграции
- Разработать систему предобработки изображений и постобработки результатов

**4. Задачи оптимизации:**
- Адаптировать систему для GPU RTX 5070 Ti (12.82GB VRAM)
- Оптимизировать потребление памяти и время обработки
- Реализовать алгоритмы коррекции ошибок распознавания

**5. Задачи тестирования:**
- Провести тестирование на реальных документах (паспорта, водительские удостоверения, чеки)
- Измерить метрики точности и производительности
- Выполнить сравнительный анализ с коммерческими решениями

**6. Задачи локализации:**
- Реализовать полную русификацию интерфейсов
- Обеспечить соответствие российскому законодательству
- Адаптировать под российские типы документов
## Анализ существующих аналогов

**Коммерческие решения:**

*ABBYY FineReader Server* - ведущее российское решение для корпоративного OCR. Обеспечивает точность до 99%, поддерживает 190+ языков. Стоимость лицензии от 500,000 рублей в год. Недостатки: высокая стоимость, сложность настройки, ограниченные возможности понимания контекста документов.

*Microsoft Azure Cognitive Services* - облачное решение с высокой точностью (95-98%). Стоимость от $1.50 за 1000 документов. Недостатки: требует передачи данных в облако, зависимость от интернета, накопительная стоимость при больших объемах.

**Открытые решения:**

*Tesseract OCR* - классическая открытая OCR-система. Бесплатная, поддерживает 100+ языков. Точность 85-90% на качественных изображениях. Недостатки: не понимает структуру документов, требует значительной настройки, низкая точность на сложных документах.

*PaddleOCR* - современная открытая система от Baidu. Точность до 95%, поддержка 80+ языков. Недостатки: ограниченные возможности извлечения структурированных данных, требует технических знаний для интеграции.

**Сравнительный анализ:**

Существующие решения не обеспечивают оптимального сочетания высокой точности, конфиденциальности, экономической эффективности и простоты использования. Коммерческие решения слишком дороги для образовательных учреждений, облачные создают риски безопасности, а открытые требуют значительных технических ресурсов для достижения приемлемого качества.

Проект ChatVLMLLM призван устранить эти недостатки, предоставив решение, которое сочетает высокую точность современных VLM моделей с полной конфиденциальностью локального развертывания и простотой использования.
---

# Глава I. Теоретические основы Vision-Language моделей

## 1.1. Основные принципы работы VLM моделей

Vision-Language модели представляют собой революционный класс систем искусственного интеллекта, способных одновременно обрабатывать и понимать визуальную и текстовую информацию. В основе VLM лежит архитектура трансформеров, адаптированная для мультимодальных задач.

**Принцип мультимодального внимания:**
VLM модели используют механизм cross-attention для установления связей между визуальными и текстовыми элементами. Изображение разбивается на патчи (обычно 16x16 пикселей), каждый из которых обрабатывается как токен, аналогично словам в тексте. Это позволяет модели "видеть" связи между визуальными элементами и их текстовыми описаниями.

**Предобучение на больших датасетах:**
Современные VLM модели обучаются на миллиардах пар изображение-текст, что позволяет им развить глубокое понимание визуально-текстовых соответствий. Модели семейства Qwen обучались на датасетах объемом более 500 миллионов изображений с описаниями на 32 языках.

**Zero-shot и few-shot возможности:**
Благодаря обширному предобучению, VLM модели способны решать новые задачи без дополнительного обучения (zero-shot) или с минимальным количеством примеров (few-shot). Это критически важно для обработки документов различных форматов без необходимости создания специализированных датасетов.

## 1.2. Архитектура трансформеров для мультимодальных задач

**Визуальный энкодер:**
Обработка изображений осуществляется через Vision Transformer (ViT), который разбивает изображение на патчи и обрабатывает их как последовательность токенов. Каждый патч проходит через линейную проекцию и получает позиционное кодирование, что позволяет модели понимать пространственные отношения между элементами изображения.

**Текстовый энкодер:**
Текстовая информация обрабатывается стандартным трансформером с механизмом self-attention. Важной особенностью является использование многоязычных токенизаторов, обеспечивающих качественную работу с кириллическим текстом.

**Механизм слияния модальностей:**
Ключевым элементом архитектуры является cross-modal attention, позволяющий модели устанавливать соответствия между визуальными и текстовыми элементами. Это обеспечивает понимание того, какие части изображения соответствуют конкретным словам или фразам в тексте.
## 1.3. Функционал системы ChatVLMLLM

Система ChatVLMLLM предоставляет комплексный набор функций для автоматизации обработки документов:

**Режим OCR (Оптическое распознавание символов):**
- Извлечение текста из изображений документов с точностью до 95%
- Поддержка форматов JPG, PNG, BMP, TIFF
- Автоматическая коррекция типичных ошибок распознавания
- Сохранение форматирования и структуры текста

**Режим интеллектуального анализа документов:**
- Автоматическое определение типа документа (паспорт, водительское удостоверение, чек)
- Извлечение структурированных данных без предварительной настройки
- Валидация извлеченной информации по встроенным правилам
- Формирование отчетов о качестве распознавания

**Интерактивный чат с документами:**
- Возможность задавать вопросы о содержании документа на естественном языке
- Поиск конкретной информации в больших документах
- Сравнение данных между несколькими документами
- Генерация сводок и резюме документов

**Пакетная обработка:**
- Одновременная обработка множества документов
- Автоматическая сортировка по типам документов
- Экспорт результатов в различных форматах (JSON, CSV, XML)
- Мониторинг прогресса обработки в реальном времени

**Система управления качеством:**
- Автоматическая оценка качества исходного изображения
- Рекомендации по улучшению качества сканирования
- Детектирование и предупреждение о потенциальных ошибках
- Логирование всех операций для аудита

## 1.4. Преимущества локального развертывания

**Абсолютная конфиденциальность данных:**
Все операции обработки выполняются локально на оборудовании пользователя. Документы никогда не покидают периметр организации, что критически важно для банков, медицинских учреждений и государственных структур. Это обеспечивает полное соответствие требованиям 152-ФЗ "О персональных данных".

**Независимость от интернет-соединения:**
Система функционирует полностью автономно, не требуя постоянного подключения к интернету. Это особенно важно для организаций в отдаленных регионах или при работе с документами в условиях ограниченной связи.

**Экономическая эффективность:**
Отсутствие recurring платежей за облачные сервисы. После первоначальных инвестиций в оборудование система работает без дополнительных затрат на лицензирование или оплату за обработанные документы.

**Полный контроль над процессом:**
Возможность настройки системы под специфические требования организации, добавления новых типов документов, модификации алгоритмов обработки без зависимости от внешних поставщиков.

**Масштабируемость:**
Производительность системы ограничена только доступными вычислительными ресурсами. При необходимости можно добавить дополнительные GPU или развернуть систему на нескольких серверах.
## 1.5. Недостатки и ограничения

**Требования к вычислительным ресурсам:**
Современные VLM модели требуют мощных графических процессоров с большим объемом видеопамяти. Минимальные требования составляют 8GB VRAM, рекомендуемые - 12GB и более. Это может ограничить применение системы в организациях с устаревшим оборудованием.

**Время обработки:**
Локальная обработка занимает больше времени по сравнению с оптимизированными облачными решениями. Обработка одного документа может занимать от 5 до 20 секунд в зависимости от сложности и размера изображения.

**Сложность первоначальной настройки:**
Развертывание системы требует технических знаний в области машинного обучения, настройки CUDA окружения и управления зависимостями Python. Это может создать барьер для организаций без собственного IT-отдела.

**Ограниченная точность на документах низкого качества:**
Качество распознавания существенно зависит от качества исходного изображения. Документы с низким разрешением, артефактами сканирования или повреждениями могут обрабатываться с пониженной точностью.

**Потребление электроэнергии:**
Работа мощных GPU приводит к значительному потреблению электроэнергии (до 220W для RTX 5070 Ti), что может быть критично для организаций с ограниченными энергетическими ресурсами.

**Необходимость регулярных обновлений:**
Для поддержания высокого качества работы требуется регулярное обновление моделей и программного обеспечения, что может потребовать технической поддержки.

Несмотря на указанные ограничения, преимущества локального развертывания в большинстве случаев перевешивают недостатки, особенно для организаций с высокими требованиями к конфиденциальности данных.
---

# Глава II. Процесс разработки системы

## 2.1. Исследование и выбор моделей

Первым этапом разработки стало комплексное исследование доступных Vision-Language моделей с открытыми лицензиями. Критериями отбора служили: точность распознавания, требования к ресурсам, поддержка русского языка и активность разработки.

**Анализ модели Qwen2-VL-2B-Instruct:**
Модель размером 4.13 GB, разработанная Alibaba Cloud, показала отличные результаты на бенчмарках мультимодальных задач. Поддерживает изображения высокого разрешения до 28M пикселей, что критично для качественного OCR. Время загрузки на RTX 5070 Ti составляет 12.89 секунд, обработка документа - 5.64 секунды.

```python
# Пример инициализации модели Qwen2-VL
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
import torch

model = Qwen2VLForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2-VL-2B-Instruct",
    torch_dtype=torch.float16,
    device_map="auto"
)
processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-2B-Instruct")
```

**Исследование Qwen3-VL-2B-Instruct:**
Улучшенная версия с поддержкой 32 языков и расширенным контекстом до 256K токенов. Размер модели 3.97 GB. Особенностью является улучшенная обработка документов со сложной структурой и таблицами. Время обработки увеличено до 14.43 секунд из-за более сложной архитектуры.

**Анализ GOT-OCR-2.0:**
Специализированная OCR модель размером 2.1 GB, оптимизированная для извлечения текста. Показывает высокую скорость обработки (3.62 секунды), но требует дополнительной постобработки для коррекции ошибок кодировки при работе с кириллическим текстом.

**Тестирование dots.ocr:**
Модель для парсинга структурированных документов размером 5.67 GB. Несмотря на многообещающую концепцию, показала нестабильную работу с критическими ошибками при обработке. Время загрузки составляет 46.47 секунд, что неприемлемо для продуктивного использования.

**Оценка Phi-3.5-Vision-Instruct:**
Мультимодальная модель Microsoft размером 7.9 GB. Показала высокое потребление видеопамяти (7.7 GB) и нестабильную работу на тестовых документах. Время загрузки 17.4 секунды.

**Результаты сравнительного анализа:**
На основе тестирования для интеграции в систему были выбраны три модели: Qwen2-VL-2B как основная для универсальных задач, Qwen3-VL-2B для многоязычных документов и GOT-OCR-2.0 для быстрого извлечения текста с последующей постобработкой.
## 2.2. Создание модульной архитектуры

Архитектура системы спроектирована по принципам SOLID с четким разделением ответственности между компонентами. Основой служит паттерн "Стратегия" для работы с различными типами моделей.

**Базовый класс модели:**
```python
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
import torch
from PIL import Image

class BaseModel(ABC):
    def __init__(self, model_path: str, device: str = "auto"):
        self.model_path = model_path
        self.device = device
        self.model = None
        self.processor = None
        self.is_loaded = False
    
    @abstractmethod
    def load_model(self) -> None:
        """Загрузка модели в память"""
        pass
    
    @abstractmethod
    def process_image(self, image: Image.Image, prompt: str = "") -> Dict[str, Any]:
        """Обработка изображения и возврат результатов"""
        pass
    
    def unload_model(self) -> None:
        """Выгрузка модели из памяти"""
        if self.model is not None:
            del self.model
            del self.processor
            torch.cuda.empty_cache()
            self.is_loaded = False
```

**Менеджер моделей:**
Центральный компонент для управления жизненным циклом моделей, обеспечивающий автоматическую загрузку и выгрузку в зависимости от доступной памяти.

```python
class ModelManager:
    def __init__(self, max_memory_gb: float = 10.0):
        self.models: Dict[str, BaseModel] = {}
        self.loaded_models: Dict[str, BaseModel] = {}
        self.max_memory_gb = max_memory_gb
        
    def register_model(self, name: str, model: BaseModel) -> None:
        """Регистрация модели в менеджере"""
        self.models[name] = model
        
    def get_model(self, name: str) -> BaseModel:
        """Получение модели с автоматической загрузкой"""
        if name not in self.models:
            raise ValueError(f"Model {name} not registered")
            
        model = self.models[name]
        if not model.is_loaded:
            self._ensure_memory_available()
            model.load_model()
            self.loaded_models[name] = model
            
        return model
    
    def _ensure_memory_available(self) -> None:
        """Освобождение памяти при необходимости"""
        current_memory = torch.cuda.memory_allocated() / 1024**3
        if current_memory > self.max_memory_gb:
            # Выгружаем наименее используемые модели
            self._unload_least_used_models()
```

**Фабрика моделей:**
Реализует паттерн "Фабричный метод" для создания экземпляров различных типов моделей.

```python
class ModelFactory:
    @staticmethod
    def create_model(model_type: str, model_path: str, **kwargs) -> BaseModel:
        if model_type == "qwen_vl":
            return QwenVLModel(model_path, **kwargs)
        elif model_type == "got_ocr":
            return GOTOCRModel(model_path, **kwargs)
        elif model_type == "dots_ocr":
            return DotsOCRModel(model_path, **kwargs)
        else:
            raise ValueError(f"Unknown model type: {model_type}")
```
## 2.3. Разработка системы управления памятью GPU

Эффективное управление видеопамятью критически важно для стабильной работы системы с несколькими большими моделями на ограниченных ресурсах.

**Мониторинг использования памяти:**
```python
import torch
import psutil
from typing import Dict, Tuple

class MemoryManager:
    def __init__(self):
        self.memory_threshold = 0.85  # 85% от доступной памяти
        
    def get_gpu_memory_info(self) -> Dict[str, float]:
        """Получение информации о состоянии GPU памяти"""
        if not torch.cuda.is_available():
            return {"total": 0, "used": 0, "free": 0}
            
        total = torch.cuda.get_device_properties(0).total_memory / 1024**3
        allocated = torch.cuda.memory_allocated() / 1024**3
        cached = torch.cuda.memory_reserved() / 1024**3
        free = total - cached
        
        return {
            "total": total,
            "allocated": allocated,
            "cached": cached,
            "free": free,
            "utilization": cached / total
        }
    
    def is_memory_available(self, required_gb: float) -> bool:
        """Проверка доступности требуемого объема памяти"""
        memory_info = self.get_gpu_memory_info()
        return memory_info["free"] >= required_gb
    
    def cleanup_memory(self) -> None:
        """Принудительная очистка кеша GPU"""
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
```

**Стратегия "ленивой" загрузки:**
Модели загружаются в память только при первом обращении и автоматически выгружаются при нехватке ресурсов.

```python
class LazyModelLoader:
    def __init__(self, memory_manager: MemoryManager):
        self.memory_manager = memory_manager
        self.model_memory_requirements = {
            "qwen_vl_2b": 4.7,
            "qwen3_vl_2b": 4.4,
            "got_ocr_hf": 1.1,
            "dots_ocr": 8.0,
            "phi3_vision": 7.7
        }
        
    def load_model_with_memory_check(self, model_name: str, model: BaseModel) -> bool:
        """Загрузка модели с проверкой доступной памяти"""
        required_memory = self.model_memory_requirements.get(model_name, 5.0)
        
        if not self.memory_manager.is_memory_available(required_memory):
            # Пытаемся освободить память
            self._free_memory_for_model(required_memory)
            
        if self.memory_manager.is_memory_available(required_memory):
            model.load_model()
            return True
        else:
            raise RuntimeError(f"Insufficient GPU memory for model {model_name}")
    
    def _free_memory_for_model(self, required_gb: float) -> None:
        """Освобождение памяти для загрузки новой модели"""
        # Выгружаем модели в порядке приоритета
        for model_name in self._get_unload_priority():
            if model_name in self.loaded_models:
                self.loaded_models[model_name].unload_model()
                del self.loaded_models[model_name]
                self.memory_manager.cleanup_memory()
                
                if self.memory_manager.is_memory_available(required_gb):
                    break
```

**Оптимизация точности вычислений:**
Использование fp16 вместо fp32 снижает потребление памяти на 50% при минимальной потере точности.

```python
def optimize_model_precision(model, use_fp16: bool = True):
    """Оптимизация точности модели для экономии памяти"""
    if use_fp16 and torch.cuda.is_available():
        model = model.half()  # Конвертация в fp16
        torch.backends.cudnn.benchmark = True  # Оптимизация cuDNN
    return model
```