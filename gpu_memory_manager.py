#!/usr/bin/env python3
"""
–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ GPU –ø–∞–º—è—Ç—å—é –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å vLLM
"""

import subprocess
import time
import psutil
import os

def get_gpu_info():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU"""
    try:
        result = subprocess.run([
            "nvidia-smi", 
            "--query-gpu=index,name,memory.total,memory.free,memory.used,utilization.gpu",
            "--format=csv,noheader,nounits"
        ], capture_output=True, text=True, check=True)
        
        lines = result.stdout.strip().split('\n')
        gpus = []
        
        for line in lines:
            parts = [p.strip() for p in line.split(',')]
            if len(parts) >= 6:
                gpus.append({
                    'index': int(parts[0]),
                    'name': parts[1],
                    'total_mb': int(parts[2]),
                    'free_mb': int(parts[3]),
                    'used_mb': int(parts[4]),
                    'utilization': int(parts[5])
                })
        
        return gpus
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU: {e}")
        return []

def get_gpu_processes():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏—Ö GPU"""
    try:
        result = subprocess.run([
            "nvidia-smi", 
            "--query-compute-apps=pid,process_name,used_memory",
            "--format=csv,noheader,nounits"
        ], capture_output=True, text=True, check=True)
        
        lines = result.stdout.strip().split('\n')
        processes = []
        
        for line in lines:
            if line.strip():
                parts = [p.strip() for p in line.split(',')]
                if len(parts) >= 3:
                    processes.append({
                        'pid': int(parts[0]),
                        'name': parts[1],
                        'memory_mb': int(parts[2])
                    })
        
        return processes
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è GPU –ø—Ä–æ—Ü–µ—Å—Å–æ–≤: {e}")
        return []

def kill_gpu_processes(exclude_pids=None):
    """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏—Ö GPU"""
    if exclude_pids is None:
        exclude_pids = []
    
    processes = get_gpu_processes()
    killed = []
    
    for proc in processes:
        pid = proc['pid']
        if pid in exclude_pids:
            continue
            
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if psutil.pid_exists(pid):
                process = psutil.Process(pid)
                process_name = process.name()
                
                print(f"üî™ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞: {process_name} (PID: {pid}, GPU –ø–∞–º—è—Ç—å: {proc['memory_mb']} MB)")
                
                # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –º—è–≥–∫–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
                process.terminate()
                time.sleep(2)
                
                # –ï—Å–ª–∏ –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
                if process.is_running():
                    process.kill()
                    time.sleep(1)
                
                killed.append(proc)
                
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å {pid}: {e}")
    
    return killed

def cleanup_docker():
    """–û—á–∏—Å—Ç–∫–∞ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –∏ —Ä–µ—Å—É—Ä—Å–æ–≤"""
    print("üê≥ –û—á–∏—Å—Ç–∫–∞ Docker —Ä–µ—Å—É—Ä—Å–æ–≤...")
    
    commands = [
        "docker stop $(docker ps -aq) 2>/dev/null || true",
        "docker system prune -f",
        "docker volume prune -f",
        "docker network prune -f"
    ]
    
    for cmd in commands:
        try:
            subprocess.run(cmd, shell=True, check=False, capture_output=True)
        except:
            pass

def clear_cuda_cache():
    """–û—á–∏—Å—Ç–∫–∞ CUDA –∫–µ—à–∞"""
    print("üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ CUDA –∫–µ—à–∞...")
    
    cleanup_script = """
import torch
import gc

if torch.cuda.is_available():
    # –û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞ –≤—Å–µ—Ö GPU
    for i in range(torch.cuda.device_count()):
        with torch.cuda.device(i):
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
    
    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞
    gc.collect()
    
    print(f"CUDA –∫–µ—à –æ—á–∏—â–µ–Ω –¥–ª—è {torch.cuda.device_count()} GPU")
else:
    print("CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
"""
    
    try:
        result = subprocess.run(
            ["python", "-c", cleanup_script], 
            capture_output=True, text=True, check=True
        )
        print(result.stdout)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ CUDA –∫–µ—à–∞: {e}")

def restart_wsl():
    """–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ WSL (—Ç–æ–ª—å–∫–æ –¥–ª—è Windows)"""
    if os.name == 'nt':  # Windows
        print("üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ WSL...")
        try:
            subprocess.run(["wsl", "--shutdown"], check=True)
            time.sleep(5)
            print("‚úÖ WSL –ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ WSL: {e}")
    else:
        print("‚ÑπÔ∏è –ù–µ Windows —Å–∏—Å—Ç–µ–º–∞, –ø—Ä–æ–ø—É—Å–∫ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ WSL")

def display_gpu_status():
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ GPU"""
    print("\nüìä –°–¢–ê–¢–£–° GPU")
    print("=" * 50)
    
    gpus = get_gpu_info()
    if not gpus:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU")
        return
    
    for gpu in gpus:
        print(f"üéÆ GPU {gpu['index']}: {gpu['name']}")
        print(f"   üíæ –ü–∞–º—è—Ç—å: {gpu['used_mb']}/{gpu['total_mb']} MB ({gpu['free_mb']} MB —Å–≤–æ–±–æ–¥–Ω–æ)")
        print(f"   üìà –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è: {gpu['utilization']}%")
        
        # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
        memory_percent = (gpu['used_mb'] / gpu['total_mb']) * 100
        print(f"   üìä –ü–∞–º—è—Ç—å: {memory_percent:.1f}% –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if gpu['free_mb'] < 6000:  # –ú–µ–Ω—å—à–µ 6GB —Å–≤–æ–±–æ–¥–Ω–æ
            print(f"   ‚ö†Ô∏è –ú–∞–ª–æ —Å–≤–æ–±–æ–¥–Ω–æ–π –ø–∞–º—è—Ç–∏ –¥–ª—è dots.ocr")
        else:
            print(f"   ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è dots.ocr")
    
    # –ü—Ä–æ—Ü–µ—Å—Å—ã –Ω–∞ GPU
    processes = get_gpu_processes()
    if processes:
        print(f"\nüîÑ –ü–†–û–¶–ï–°–°–´ –ù–ê GPU ({len(processes)}):")
        for proc in processes:
            print(f"   ‚Ä¢ PID {proc['pid']}: {proc['name']} ({proc['memory_mb']} MB)")
    else:
        print("\n‚úÖ –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –Ω–∞ GPU")

def recommend_vllm_settings():
    """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ vLLM"""
    gpus = get_gpu_info()
    if not gpus:
        return
    
    gpu = gpus[0]  # –ü–µ—Ä–≤–∞—è GPU
    free_gb = gpu['free_mb'] / 1024
    total_gb = gpu['total_mb'] / 1024
    
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø VLLM")
    print("=" * 30)
    
    if free_gb < 6:
        print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è dots.ocr —á–µ—Ä–µ–∑ vLLM")
        print("üîß –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:")
        print("   1. –û—á–∏—Å—Ç–∏—Ç—å GPU –ø–∞–º—è—Ç—å (—ç—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç)")
        print("   2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å transformers —Å 8-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π")
        print("   3. –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ –±–æ–ª–µ–µ –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å")
        
    elif free_gb < 8:
        gpu_util = min(0.4, free_gb / total_gb * 0.8)
        print(f"‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å, –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
        print(f"   --gpu-memory-utilization {gpu_util:.2f}")
        print(f"   --max-model-len 1024")
        print(f"   --max-num-seqs 1")
        print(f"   --dtype bfloat16")
        
    else:
        gpu_util = min(0.7, free_gb / total_gb * 0.9)
        print(f"‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏, –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
        print(f"   --gpu-memory-utilization {gpu_util:.2f}")
        print(f"   --max-model-len 2048")
        print(f"   --max-num-seqs 4")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üõ†Ô∏è –£–ü–†–ê–í–õ–ï–ù–ò–ï GPU –ü–ê–ú–Ø–¢–¨–Æ")
    print("=" * 30)
    
    while True:
        print("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:")
        print("1. üìä –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å GPU")
        print("2. üßπ –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏")
        print("3. üî™ –ó–∞–≤–µ—Ä—à–∏—Ç—å GPU –ø—Ä–æ—Ü–µ—Å—Å—ã")
        print("4. üê≥ –û—á–∏—Å—Ç–∏—Ç—å Docker")
        print("5. üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å CUDA –∫–µ—à")
        print("6. üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å WSL")
        print("7. üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è vLLM")
        print("0. ‚ùå –í—ã—Ö–æ–¥")
        
        choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä: ").strip()
        
        if choice == "1":
            display_gpu_status()
            
        elif choice == "2":
            print("\nüßπ –ü–û–õ–ù–ê–Ø –û–ß–ò–°–¢–ö–ê GPU –ü–ê–ú–Ø–¢–ò")
            print("=" * 35)
            
            # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ GPU –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
            killed = kill_gpu_processes()
            if killed:
                print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ {len(killed)} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤")
            
            # –û—á–∏—Å—Ç–∫–∞ Docker
            cleanup_docker()
            
            # –û—á–∏—Å—Ç–∫–∞ CUDA –∫–µ—à–∞
            clear_cuda_cache()
            
            time.sleep(3)
            display_gpu_status()
            
        elif choice == "3":
            processes = get_gpu_processes()
            if processes:
                print(f"\nüî™ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ {len(processes)} GPU –ø—Ä–æ—Ü–µ—Å—Å–æ–≤...")
                killed = kill_gpu_processes()
                print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ {len(killed)} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤")
            else:
                print("‚úÖ –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö GPU –ø—Ä–æ—Ü–µ—Å—Å–æ–≤")
                
        elif choice == "4":
            cleanup_docker()
            print("‚úÖ Docker —Ä–µ—Å—É—Ä—Å—ã –æ—á–∏—â–µ–Ω—ã")
            
        elif choice == "5":
            clear_cuda_cache()
            
        elif choice == "6":
            restart_wsl()
            
        elif choice == "7":
            recommend_vllm_settings()
            
        elif choice == "0":
            break
            
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")

if __name__ == "__main__":
    main()