#!/usr/bin/env python3
"""–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π HuggingFace –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏."""

import os
import json
from pathlib import Path
from transformers import AutoConfig
import yaml

def get_cache_dir():
    """–ü–æ–ª—É—á–∏—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∫–µ—à–∞ HuggingFace."""
    return Path.home() / ".cache" / "huggingface" / "hub"

def analyze_model(model_path):
    """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏."""
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config_path = model_path / "config.json"
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            model_type = config.get('model_type', 'unknown')
            architectures = config.get('architectures', [])
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –º–æ–¥–µ–ª—å—é –º–∞—à–∏–Ω–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è
            is_vlm = any(arch for arch in architectures if any(keyword in arch.lower() 
                        for keyword in ['vision', 'vlm', 'multimodal', 'qwen', 'phi', 'idefics', 'vila']))
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ OCR –º–æ–¥–µ–ª—å—é
            is_ocr = any(keyword in str(model_path).lower() 
                        for keyword in ['ocr', 'got', 'dots'])
            
            return {
                'model_type': model_type,
                'architectures': architectures,
                'is_vlm': is_vlm,
                'is_ocr': is_ocr,
                'config': config
            }
    except Exception as e:
        return {'error': str(e)}
    
    return {'error': '–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}

def get_model_size(model_path):
    """–í—ã—á–∏—Å–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ –≤ –ì–ë."""
    total_size = 0
    for root, dirs, files in os.walk(model_path):
        for file in files:
            file_path = os.path.join(root, file)
            if os.path.exists(file_path):
                total_size += os.path.getsize(file_path)
    return total_size / (1024**3)  # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –ì–ë

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("üîç –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π HuggingFace...")
    print("=" * 60)
    
    cache_dir = get_cache_dir()
    if not cache_dir.exists():
        print("‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∫–µ—à–∞ HuggingFace –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return
    
    # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –º–æ–¥–µ–ª–µ–π
    model_dirs = [d for d in cache_dir.iterdir() if d.is_dir() and d.name.startswith('models--')]
    
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(model_dirs)} –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
    print()
    
    vlm_models = []
    ocr_models = []
    other_models = []
    total_size = 0
    
    for model_dir in sorted(model_dirs):
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏
        model_name = model_dir.name.replace('models--', '').replace('--', '/')
        
        # –ü–æ–∏—Å–∫ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏ (–≤ —Å–Ω–∏–º–∫–∞—Ö)
        snapshots_dir = model_dir / "snapshots"
        if not snapshots_dir.exists():
            continue
            
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–Ω–∏–º–∫–∞
        snapshot_dirs = [d for d in snapshots_dir.iterdir() if d.is_dir()]
        if not snapshot_dirs:
            continue
            
        latest_snapshot = max(snapshot_dirs, key=lambda x: x.stat().st_mtime)
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞
        size_gb = get_model_size(model_dir)
        total_size += size_gb
        
        # –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏
        analysis = analyze_model(latest_snapshot)
        
        model_info = {
            'name': model_name,
            'path': str(model_dir),
            'size_gb': round(size_gb, 2),
            'analysis': analysis
        }
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
        if analysis.get('is_vlm'):
            vlm_models.append(model_info)
        elif analysis.get('is_ocr'):
            ocr_models.append(model_info)
        else:
            other_models.append(model_info)
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("ü§ñ –ú–û–î–ï–õ–ò –ú–ê–®–ò–ù–ù–û–ì–û –ó–†–ï–ù–ò–Ø (VLM)")
    print("-" * 40)
    for model in vlm_models:
        print(f"üìä {model['name']}")
        print(f"   –†–∞–∑–º–µ—Ä: {model['size_gb']} –ì–ë")
        if 'architectures' in model['analysis']:
            print(f"   –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {', '.join(model['analysis']['architectures'])}")
        print(f"   –¢–∏–ø: {model['analysis'].get('model_type', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        print()
    
    print("üîç OCR –ú–û–î–ï–õ–ò")
    print("-" * 40)
    for model in ocr_models:
        print(f"üìä {model['name']}")
        print(f"   –†–∞–∑–º–µ—Ä: {model['size_gb']} –ì–ë")
        if 'architectures' in model['analysis']:
            print(f"   –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {', '.join(model['analysis']['architectures'])}")
        print(f"   –¢–∏–ø: {model['analysis'].get('model_type', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        print()
    
    print("üì¶ –î–†–£–ì–ò–ï –ú–û–î–ï–õ–ò")
    print("-" * 40)
    for model in other_models:
        print(f"üìä {model['name']}")
        print(f"   –†–∞–∑–º–µ—Ä: {model['size_gb']} –ì–ë")
        if 'architectures' in model['analysis']:
            print(f"   –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {', '.join(model['analysis']['architectures'])}")
        print(f"   –¢–∏–ø: {model['analysis'].get('model_type', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        print()
    
    # –°–≤–æ–¥–∫–∞
    print("üìà –°–í–û–î–ö–ê")
    print("-" * 40)
    print(f"–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {len(model_dirs)}")
    print(f"VLM –º–æ–¥–µ–ª–∏: {len(vlm_models)}")
    print(f"OCR –º–æ–¥–µ–ª–∏: {len(ocr_models)}")
    print(f"–î—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏: {len(other_models)}")
    print(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–µ—à–∞: {round(total_size, 2)} –ì–ë")
    print()
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ò–ù–¢–ï–ì–†–ê–¶–ò–ò")
    print("-" * 40)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –∫–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    current_config_path = Path("config.yaml")
    if current_config_path.exists():
        with open(current_config_path, 'r', encoding='utf-8') as f:
            current_config = yaml.safe_load(f)
        
        current_models = set(current_config.get('models', {}).keys())
        
        print("üîß –ú–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ config.yaml:")
        
        for model in vlm_models + ocr_models:
            model_key = model['name'].lower().replace('/', '_').replace('-', '_')
            if model_key not in current_models:
                print(f"   + {model['name']} ({model['size_gb']} –ì–ë)")
                print(f"     –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π –∫–ª—é—á: {model_key}")
        
        print()
    
    print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")

if __name__ == "__main__":
    main()