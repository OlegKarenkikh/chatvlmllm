{
  "timestamp": "2026-01-24T18:22:12.501670",
  "server_url": "http://localhost:8000",
  "model": "rednote-hilab/dots.ocr",
  "total_documents": 7,
  "results": [
    {
      "file": "01_simple_text.png",
      "file_size_kb": 49.4580078125,
      "tests": [
        {
          "prompt": "Extract all text from this image",
          "processing_time": 0.02,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Transcribe all text content from this document",
          "processing_time": 0.0,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 15 input tokens (2000 > 1024 - 15). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Read and extract all visible text from this image",
          "processing_time": 0.02,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 16 input tokens (2000 > 1024 - 16). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Convert this image to text format",
          "processing_time": 0.02,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        }
      ]
    },
    {
      "file": "02_table.png",
      "file_size_kb": 38.248046875,
      "tests": [
        {
          "prompt": "Extract all text from this image",
          "processing_time": 0.03,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Transcribe all text content from this document",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 15 input tokens (2000 > 1024 - 15). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Read and extract all visible text from this image",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 16 input tokens (2000 > 1024 - 16). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Convert this image to text format",
          "processing_time": 0.02,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        }
      ]
    },
    {
      "file": "03_multicolumn.png",
      "file_size_kb": 63.0810546875,
      "tests": [
        {
          "prompt": "Extract all text from this image",
          "processing_time": 0.04,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Transcribe all text content from this document",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 15 input tokens (2000 > 1024 - 15). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Read and extract all visible text from this image",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 16 input tokens (2000 > 1024 - 16). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Convert this image to text format",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        }
      ]
    },
    {
      "file": "04_numbers.png",
      "file_size_kb": 79.859375,
      "tests": [
        {
          "prompt": "Extract all text from this image",
          "processing_time": 0.03,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Transcribe all text content from this document",
          "processing_time": 0.0,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 15 input tokens (2000 > 1024 - 15). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Read and extract all visible text from this image",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 16 input tokens (2000 > 1024 - 16). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Convert this image to text format",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        }
      ]
    },
    {
      "file": "05_mixed.png",
      "file_size_kb": 81.2333984375,
      "tests": [
        {
          "prompt": "Extract all text from this image",
          "processing_time": 0.03,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Transcribe all text content from this document",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 15 input tokens (2000 > 1024 - 15). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Read and extract all visible text from this image",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 16 input tokens (2000 > 1024 - 16). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Convert this image to text format",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        }
      ]
    },
    {
      "file": "06_low_quality.png",
      "file_size_kb": 39.666015625,
      "tests": [
        {
          "prompt": "Extract all text from this image",
          "processing_time": 0.04,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Transcribe all text content from this document",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 15 input tokens (2000 > 1024 - 15). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Read and extract all visible text from this image",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 16 input tokens (2000 > 1024 - 16). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Convert this image to text format",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        }
      ]
    },
    {
      "file": "07_multi_size.png",
      "file_size_kb": 37.9052734375,
      "tests": [
        {
          "prompt": "Extract all text from this image",
          "processing_time": 0.02,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Transcribe all text content from this document",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 15 input tokens (2000 > 1024 - 15). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Read and extract all visible text from this image",
          "processing_time": 0.01,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 16 input tokens (2000 > 1024 - 16). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        },
        {
          "prompt": "Convert this image to text format",
          "processing_time": 0.0,
          "success": false,
          "text_length": 0,
          "word_count": 0,
          "error": "HTTP 400: {\"error\":{\"message\":\"'max_tokens' or 'max_completion_tokens' is too large: 2000. This model's maximum context length is 1024 tokens and your request has 13 input tokens (2000 > 1024 - 13). (parameter=max_tokens, value=2000) None\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}}"
        }
      ]
    }
  ]
}